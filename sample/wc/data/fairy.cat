
require "thread"

END_OF_STREAM

require "deep-connect/deep-connect.rb"
#DeepConnect::Organizer.immutable_classes.push Array

#require "backend/job-interpriter"
#require "backend/scheduler"

require "share/conf"
require "share/pool-dictionary"
require "share/stdout"
require "share/log"

module Fairy

  class Controller

    EXPORTS = []
    def Controller.def_export(obj, name = nil)
      unless name
	if obj.kind_of?(Class)
	  if /Fairy::(.*)$/ =~ obj.name
	    name = $1
	  else
	    name = obj.name
	  end
	else
	  raise "クラス以外を登録するときにはサービス名が必要です(%{obj})"
	end
      end

      EXPORTS.push [name, obj]
    end
    
    def Controller.start(id, master_port)
      controller = Controller.new(id)
      controller.start(master_port)
    end

    def initialize(id)
      @id = id

      @deepconnect = nil

      @master_deepspace = nil
      @master = nil

      @client = nil

      @stdout_mutex = Mutex.new

      @services = {}

      # processor -> no of reserve 
      @reserves = {}
      @reserves_mutex = Mutex.new
      @reserves_cv = ConditionVariable.new

      # bjob -> [processor, ...]
      @bjob2processors = {}
      @bjob2processors_mutex = Mutex.new
      @bjob2processors_cv = ConditionVariable.new

      @pool_dict = PoolDictionary.new

    end

    attr_reader :id

#    PROCESS_LIFE_MANAGE_INTERVAL = 60
#    PROCESS_LIFE_MANAGE_INTERVAL = 10
#    PROCESS_LIFE_MANAGE_INTERVAL = 1
    PROCESS_LIFE_MANAGE_INTERVAL = nil

    def start(master_port, service=0)
      @deepconnect = DeepConnect.start(service)
      @deepconnect.export("Controller", self)

      @deepconnect.when_disconnected do |deepspace, opts|
	when_disconnected(deepspace, opts)
      end

      for name, obj in EXPORTS
	export(name, obj)
      end

      @master_deepspace = @deepconnect.open_deepspace("localhost", master_port)
      @master = @master_deepspace.import("Master")
      @logger = @master.logger
      Log.type = "CONT"
      Log.pid = id
      Log.logger = @logger
      Log::info(self, "Controller Service Start")

      @master.register_controller(self)


      if PROCESS_LIFE_MANAGE_INTERVAL
	Thread.start do
	  start_process_life_manage
	end
	nil
      end
    end

    def connect(client)
      @client = client
      
      $stdout = Stdout.new(@client)
    end

    def terminate
      # clientが終了したときの終了処理
      # master から呼ばれる
      processors = @reserves.keys
      processors.each do |p| 
	begin
	  p.node.terminate_processor(p)
	rescue
#	  p $!, $@
	end
      end

      Thread.start do
	sleep 0.1
	@deepconnect.stop
	Process.exit(0)
      end
      nil
    end

    def when_disconnected(deepspace, opts)
      if deepspace == @client.deep_space
	Log::info(self, "CONTROLLER: disconnected: Start termination")
	# クライアントがおなくなりになったら, こっちも死ぬよ
	@master.terminate_controller(self)
      end
    end

    # 
    # clent interface
    #
    def export(service, obj)
      @services[service] = obj
    end

    def import(service)
      @services[service]
    end

    #
    # processor methods
    #
    # reserve してから njob 割り当てを行う
    def reserve_processor(processor, &block)
      @reserves_mutex.synchronize do
	begin
	  return nil unless @reserves[processor]
	rescue SessionServiceStopped
	  # processor は 終了している可能性がある
	  return nil
	end
	@reserves[processor] += 1
      end
      begin
	yield processor
	processor
      ensure
	@reserves_mutex.synchronize do
	  @reserves[processor] -= 1
	end
      end
    end

    def create_processor(node, bjob, &block)
      processor = node.create_processor
      processor.set_stdout(self)
      @reserves_mutex.synchronize do
	@reserves[processor] = 1
      end
      begin
	register_processor(bjob, processor)
	yield processor
	processor
      ensure
	@reserves_mutex.synchronize do
	  @reserves[processor] -= 1
	end
      end
    end

    def register_processor(bjob, processor)
      @bjob2processors_mutex.synchronize do
	@bjob2processors[bjob] = [] unless @bjob2processors[bjob]
	unless @bjob2processors[bjob].include?(processor)
	  @bjob2processors[bjob].push processor
	end
	@bjob2processors_cv.broadcast
      end
      processor
    end

    def assign_inputtable_processor(bjob, input_bjob, input_njob, input_export, &block)
      case input_bjob
      when BGroupBy
	assign_processor(bjob, :NEW_PROCESSOR_N, input_bjob, &block)
#	assign_processor(bjob, :NEW_PROCESSOR, &block)
      when BSplitter
	assign_processor(bjob, :NEW_PROCESSOR, &block)
      else
	assign_processor(bjob, :SAME_PROCESSOR, input_njob.processor, &block)
      end
    end

    # Processor 関連メソッド
    # Policy: :SAME_PROCESSOR, :NEW_PROCESSOR, :INPUT, MUST_BE_SAME_PROCESSOR
    def assign_processor(bjob, policy, *opts, &block)
      case policy
      when :INPUT
	assign_input_processor(bjob, opts[0], &block)
      when :SAME_PROCESSOR_OBJ
	assign_same_obj_processor(bjob, opts[0], &block)
      when :SAME_PROCESSOR, :MUST_BE_SAME_PROCESSOR
	processor = opts[0]
	assign_same_processor(bjob, processor, &block)
      when :NEW_PROCESSOR
	assign_new_processor(bjob, &block)
      when :NEW_PROCESSOR_N
	input_bjob = opts[0]
	assign_new_processor_n(bjob, input_bjob, &block)
      else
	raise "未サポートのポリシー: #{policy}"
      end
    end

    def assign_input_processor(bjob, host, &block)
      node = @master.node(host)
      unless node
	raise "#{host} のホスト上でnodeが立ち上がっていません"
      end

      create_processor(node, bjob, &block)
    end

    def assign_same_obj_processor(bjob, obj, &block)
      processor = nil
      @reserves_mutex.synchronize do
	@reserves.each_key do |p| 
	  if p.deep_space == obj.deep_space
	    processor = p
	    break
	  end
	end
      end
      raise "#{obj} の存在するプロセッサは存在しません" unless processor

      ret = reserve_processor(processor) {
	register_processor(bjob, processor)
	yield processor
      }
      
      raise "#{obj} の存在するプロセッサは存在しません" unless ret
    end

    def assign_same_processor(bjob, processor, &block)
      ret = reserve_processor(processor) {|processor|
	register_processor(bjob, processor)
	yield processor
	processor}

      unless ret
	# プロセッサが終了していたとき(ほとんどあり得ないけど)
	assign_new_processor(bjob, &block)
      end
    end

    def assign_new_processor(bjob, &block)
      node = @master.leisured_node
      create_processor(node, bjob, &block)
    end

    # まあ, 大体n個になるかなぁ... 
    # input_bjobのプロセスも動的に割り当てられるので...
    # 最終的には 大体そうなるということで....
    def assign_new_processor_n(bjob, input_bjob, &block)
      no_i = 0
      @bjob2processors_mutex.synchronize do
 	while !@bjob2processors[input_bjob]
 	  @bjob2processors_cv.wait(@bjob2processors_mutex)
 	end
	if i_processors = @bjob2processors[input_bjob]
	  no_i = i_processors.size
	end
      end

      no = 0
      if processors = @bjob2processors[bjob]
	no = processors.size
      end
      if no_i > no
	node = @master.leisured_node
	create_processor(node, bjob, &block)
      else
	leisured_processor = nil
	min = nil
	for processor in @bjob2processors[bjob].dup
	  # これだと頭から割り当てられる... 
	  # けど取りあえずということで.
	  
	  n = processor.no_njobs
	  if !min or min > n
	    min = n
	    leisured_processor = processor
	  end
	end
	ret = reserve_processor(leisured_processor) {|processor|
	  register_processor(bjob, processor)
	  yield processor
	}
	unless ret
	  # プロセッサが終了していたとき. もうちょっとどうにかしたい気もする
	  assign_new_processor(bjob, &block)
	end
      end
    end

    def terminate_processor
      deresister_processor(processor)
      @master.deregister_processor(processor)
      @node.deregister_processor(processor)
      @node.terminate_processor
    end

    def start_process_life_manage
      loop do
	sleep PROCESS_LIFE_MANAGE_INTERVAL
	processors = @reserves_mutex.synchronize{@reserves.keys}
	for p in processors
	  kill = false
	  @reserves_mutex.synchronize do
#  	    for q, r in @reserves
#  	      puts "#{q.id} =>#{r}"
#  	    end
	    if @reserves[p] == 0 && p.life_out_life_span?
	      Log::debug self, "Kill #{p.inspectx}"
	      kill = true
	      @reserves.delete(p)
	      @bjob2processors_mutex.synchronize do
		# @bjob2processors から p を削除する必要あるか?
	      end
	    end
	  end
	  if kill
	    p.node.terminate_processor(p)
	  end
	end
      end
    end

    # exception handling
    def handle_exception(exp)
      Thread.start do
	begin
	  @client.handle_exception(exp)
	rescue
	end
      end
      nil
    end

    # stdout
    def stdout_write(str)
      $stdout.replace_stdout do
	$stdout.write(str)
      end
    end

    # pool variable
    def pool_dict
      @pool_dict
    end

    def def_pool_variable(vname, value = nil)
      # value が Hash で キー :block をもっていたら block と見なす.
      if value.__deep_connect_reference? && value.kind_of?(Hash) && value[:block]
	p = Context.create_proc(self, value[:block])
	value = p.call 
      end
      @pool_dict.def_variable(vname, value)
    end

    def pool_variable(vname, *value)
      if value.empty?
	@pool_dict[vname]
      else
	@pool_dict[vname] = value.first
      end
    end

    class Context
      def self.create_proc(controller, source)
	context = new(controller)
	context.create_proc(source)
      end
      
      def initialize(controller)
	@Pool = controller.pool_dict
      end

      def create_proc(source)
	eval("proc{#{source}}", binding)
      end
    end

  end
end

require "backend/addins"

require "thread"
require "deep-connect/deep-connect.rb"

require "share/conf"

#DeepConnect::Organizer.immutable_classes.push Array


module Fairy

  class Fairy

    def initialize(master_host = CONF.MASTER_HOST, 
		   master_port = CONF.MASTER_PORT)
      @name2backend_class = {}

      @deep_connect = DeepConnect.start(0)
      @master_deepspace = @deep_connect.open_deepspace(master_host, master_port)
      @master = @master_deepspace.import("Master")

      @controller = @master.assgin_controller
      @controller.connect(self)

      @stdout_mutex = Mutex.new
    end

    attr_reader :controller

    def name2backend_class(backend_class_name)
      if klass = @name2backend_class[backend_class_name]
	return klass 
      end
      
      if klass =  @controller.import(backend_class_name)
	@name2backend_class[backend_class_name] = klass
      end
      klass
    end

    # pool variables
    def def_pool_variable(vname, value = nil)
      @controller.def_pool_variable(vname, value)
    end

    def pool_variable(vname, *value)
      @controller.pool_variable(vname, *value)
    end

    # exception handling
    def handle_exception(exp)
      local_exp = nil
      begin
	local_exp = exp.dc_deep_copy
      rescue
	raise exp
      end
      Thread.main.raise local_exp
      nil
    end

    # debug print
    def stdout_write(str)
      @stdout_mutex.synchronize do
	$stdout.write(str)
      end
    end

    # external module loading
    def self.def_fairy_interface(mod)
      include mod
    end
  end

  def def_fairy_interface(mod)
    ::Fairy::Fairy.instance_eval{include mod}
  end
  module_function :def_fairy_interface

end

require "job/job"
require "job/input"

require "job/addins"



module Fairy
  class Logger

    LOG_FILE = CONF.LOG_FILE

    FLUSH_INTERVAL = CONF.LOG_FLUSH_INTERVAL

    def initialize(path = LOG_FILE)
      @log_out = File.open(LOG_FILE, "a+")
      
      @mutex = Mutex.new
      @buffered = false

      start_flusher
    end

    def start_flusher
      Thread.start do
	loop do
	  sleep FLUSH_INTERVAL
	  @mutex.synchronize do
	    if @buffered
	      @log_out.flush
	      @buffered = false
	    end
	  end
	end
      end
    end

    def message(message)
      @mutex.synchronize do
	@log_out.puts message
	@buffered = true
      end
    end
  end
end

require "thread"
require "resolv"
require "ipaddr"

require "deep-connect/deep-connect"
#DeepConnect::Organizer.immutable_classes.push Array

require "share/conf"
require "logger"
require "share/log"

module Fairy

  class Master
    def initialize

#       @clients = {}
#       @clients_mutex = Mutex.new
#       @clients_cv = ConditionVariable.new

      @controller_seq = -1
      @controller_seq_mutex = Mutex.new

      @controllers = {}
      @controllers_mutex = Mutex.new
      @controllers_cv = ConditionVariable.new

#      @clientds2controller = {}

      @nodes = {}
      @nodes_mutex = Mutex.new

      @no_of_processors = {}
      @no_of_processors_mutex = Mutex.new
    end

    attr_reader :logger
    
    def start(service)
      @deepconnect = DeepConnect.start(service)
      @deepconnect.export("Master", self)

      @logger = Logger.new
      Log.logger = @logger
      Log.type = "MAST"

      @deepconnect.when_disconnected do |deepspace, opts|
	when_disconnected(deepspace, opts)
      end

      Log.info(self, "Master Service Start")
    end

    def when_disconnected(deepspace, opts)
      Log::info self, "MASTER: disconnected: Start termination"
#       @controllers_mutex.synchronize do
# 	if c = @controllers.find{|c| c.deep_space == deepspace}
# 	  when_disconnected_controller(c, deepspace, opts)
# 	end
#       end

      # node
    end

    # Controller 関連メソッド

    def controller_next_id
      @controller_seq_mutex.synchronize do
	@controller_seq += 1
      end
    end

    def assgin_controller

#       @clients_mutex.synchronize do
# 	@clients[fairy.deep_space] = fairy
#       end

      @controllers_mutex.synchronize do
	controller_id = controller_next_id
	Process.fork do
	  exec(CONF.RUBY_BIN, CONF.CONTROLLER_BIN,
	       "--master", @deepconnect.local_id.to_s, 
	       "--id", controller_id.to_s)
	end
	while !@controllers[controller_id]
	  @controllers_cv.wait(@controllers_mutex)
	end
#	@clientds2controller[fairy.deep_space] = @controllers[controller_id]
	@controllers[controller_id]
      end
    end

    def register_controller(controller)
      @controllers_mutex.synchronize do
	@controllers[controller.id] = controller
	@controllers_cv.broadcast
      end
    end

    def terminate_controller(controller)
      @controllers_mutex.synchronize do
	@controllers.delete(controller)
	@controllers_cv.broadcast
      end
      
      begin
	controller.terminate
	Process.wait
      rescue
	p $!, $@
      end
    end

    #
    def set_no_of_processors(node, no)
      @no_of_processors_mutex.synchronize do
	@no_of_processors[node] = no
      end
    end

    def leisured_node
      min_node = nil
      min_no_processor = nil
      for uuid, node in @nodes.dup
#	no = nil
#	@no_of_processors_mutex.synchronize do
	no = @no_of_processors[node]
#	end
	if !min_no_processor or min_no_processor > no
	  min_no_processor = no
	  min_node = node
	end
      end
      min_node
    end

    # Node 関連メソッド
    def register_node(node)
      @nodes_mutex.synchronize do
	@no_of_processors[node] = 0
	
	addr = node.deep_space.peer_uuid[0]
	@nodes[addr] = node
	Log::info self, "Node added: #{addr}->#{node}"
	node.addr = addr
      end
    end

    IPADDR_REGEXP = /::ffff:([0-9]+\.){3}[0-9]+|[0-9a-f]+:([0-9a-f]*:)[0-9a-f]*/

    def node(host)
#puts "HOST: #{host}"
      unless IPADDR_REGEXP =~ host
	addr = Resolv.getaddress(host)
	ipaddr = IPAddr.new(addr)
	ipaddr = ipaddr.ipv4_mapped if ipaddr.ipv4?
	host = ipaddr.to_s
      end
      
      node = nil
      @nodes_mutex.synchronize do
	node = @nodes[host]
      end
      node
    end

    def Master.start(service)
      master = Master.new
      master.start(service)
    end
  end
end

#require "monitor"

require "deep-connect/deep-connect"

require "share/conf"
require "share/log"

#DeepConnect::Organizer.immutable_classes.push Array

module Fairy
  class Node

    def initialize
      @addr = nil
      @logger = nil

      @processor_seq = -1
      @processor_seq_mutex = Mutex.new

      @processors = []
      @processors_mutex = Mutex.new
      @processors_cv = ConditionVariable.new
    end

    attr_accessor :addr
    attr_reader :logger
    
#     def processors_dup
#       @processors.synchronize do
# 	@processors.dup
#       end
#     end

    def start(master_host, master_port, service=0)
      @deepconnect = DeepConnect.start(service)
      @deepconnect.export("Node", self)

      @master_deepspace = @deepconnect.open_deepspace(master_host, master_port)
      @master = @master_deepspace.import("Master")
      @logger = @master.logger
      Log.type = "NODE"
      Log.logger = @logger
      Log.info(self, "Node Service Start")

      @master.register_node(self)
    end

    def processor_next_id
      @processor_seq_mutex.synchronize do
	@processor_seq += 1
      end
    end

    def create_processor
      proc = nil
      @processors_mutex.synchronize do
	processor_id = processor_next_id
#	Process.spawn("test/testn.rb", 
#		      "--controller", @deepconnect.local_id, 
#		      "--id", processor_id.to_s)
	pid = Process.fork{
	  Process.fork{
	    exec(CONF.RUBY_BIN, CONF.PROCESSOR_BIN,
		 "--node", @deepconnect.local_id.to_s, 
		 "--id", processor_id.to_s)
	  }
	}
	Process.wait pid
	while !@processors[processor_id]
	  @processors_cv.wait(@processors_mutex)
	end
	@master.set_no_of_processors(self, @processors.size)
	@processors[processor_id]
      end
    end

    def terminate_processor(processor)
      deregister_processor(processor)
      begin
	processor.terminate
      rescue
      end
# forkの仕組みが変わった.
#      Process.wait
    end

    def register_processor(processor)
#      @processors.synchronize do
      @processors_mutex.synchronize do
	@processors[processor.id] = processor
	processor.addr = @addr

	@processors_cv.broadcast
     end
    end

    def deregister_processor(processor)
#      @processors.synchronize do
      @processors_mutex.synchronize do
	@processors.delete(processor.id)
	@master.set_no_of_processors(self, @processors.size)

	@processors_cv.broadcast
      end
    end

      
    def Node.start(master_host, master_port)
      node = Node.new
      node.start(master_host, master_port)
    end
  end
end

require "deep-connect/deep-connect"

require "share/conf"
require "share/stdout"
require "share/log"

#DeepConnect::Organizer.immutable_classes.push Array

# require "node/nfile"
# require "node/n-local-file-input"
# require "node/n-input-iota"
# require "node/n-there"

# require "node/n-file-output"
# require "node/n-local-file-output"

# require "node/nhere"
# require "node/n-each-element-mapper"
# require "node/n-each-element-selector"
# require "node/n-each-substream-mapper"
# require "node/n-group-by"
# require "node/n-zipper"
# require "node/n-splitter"
# require "node/n-barrier"

module Fairy

  class Processor

    EXPORTS = []
    def Processor.def_export(obj, name = nil)
      unless name
	if obj.kind_of?(Class)
	  if /Fairy::(.*)$/ =~ obj.name
	    name = $1
	  else
	    name = obj.name
	  end
	else
	  raise "クラス以外を登録するときにはサービス名が必要です(%{obj})"
	end
      end

      EXPORTS.push [name, obj]
    end

    def initialize(id)
      @id = id
      @reserve = 0

      @services = {}

      @njobs = []

      init_varray_feature
      init_njob_status_feature
    end

    attr_reader :id
    attr_reader :njobs

    def start(node_port, service=0)
      @addr = nil

      @deepconnect = DeepConnect.start(service)
      @deepconnect.register_service("Processor", self)

      for name, obj in EXPORTS
	export(name, obj)
      end

      @node_deepspace = @deepconnect.open_deepspace("localhost", node_port)
      @node = @node_deepspace.import("Node")
      @logger = @node.logger
      Log.type = "PROC"
      Log.pid =id
      Log.logger = @logger
      Log::info self, "Processor Service Start"

      @node.register_processor(self)
    end

    def terminate
      # clientが終了したときの終了処理
      Thread.start do
	# このメソッドが戻るまで待つ
	sleep 0.1
	@deepconnect.stop
	Process.exit(0)
      end
      nil
    end

    attr_accessor :addr
    attr_reader :node

    def set_stdout(peer)
      $stdout = Stdout.new(peer)
    end

    def node
      @node
    end

    def export(service, obj)
      @services[service] = obj
    end

    def import(service)
      svs = @services[service]
      unless svs
	raise "サービス(#{service})が登録されていません"
      end
      svs
    end

    def no_njobs
      @njobs.size
    end

    def create_njob(njob_class_name, bjob, opts, *rests)
      klass = import(njob_class_name)
      njob = klass.new(self, bjob, opts, *rests)
      @njobs.push njob
      Log.debug(self, "Njob number of %d", @njobs.size)
      njob
    end
    DeepConnect.def_method_spec(self, "REF create_njob(VAL, REF, VAL, *VAL)")

    
    LIMIT_PROCESS_SIZE = 100  #kbyte
    def life_out_life_span?
#       puts "LOLS: #{inspectx}"
#       puts "njob: #{all_njob_finished?}"
#       unless all_njob_finished? 
# 	for njob, status in @njob_status
# 	  puts "#{njob.class} => #{status}"
# 	end
#       end

#       puts "varry: #{exist_varray_elements?}"

      return false unless all_njob_finished?
      return false if exist_varray_elements?

      # 取りあえず
      vsz = `ps -ovsz h#{Process.pid}`.to_i
#puts "vsz: #{vsz}, #{LIMIT_PROCESS_SIZE > vsz}"

      LIMIT_PROCESS_SIZE < vsz
    end

    #
    # varray management
    #
    def init_varray_feature
      @varray_elements = {}
      @varray_elements_mutex = Mutex.new
    end

    def exist_varray_elements?
      @varray_elements_mutex.synchronize do
	!@varray_elements.empty?
      end
    end

    def register_varray_element(array)
      @varray_elements_mutex.synchronize do
	@varray_elements[array.object_id] = array.object_id
      end
      ObjectSpace.define_finalizer(array, deregister_varray_element_proc)
    end

    def deregister_varray_element_proc
      proc do |oid|
	@varray_elements_mutex.synchronize do
	  @varray_elements.delete(oid)
	end
      end
    end

    #
    # njob status management
    #
    def init_njob_status_feature
      @njob_status = {}
      @njob_status_mutex = Mutex.new
      @njob_status_cv = ConditionVariable.new
    end

    def all_njob_finished?
      @njob_status_mutex.synchronize do
	for node, status in @njob_status
	  return false if status != :ST_FINISH
	end
      end
      true
    end

    def update_status(node, st)
      @njob_status_mutex.synchronize do
	@njob_status[node] = st
	@njob_status_cv.broadcast
      end
    end

    def inspectx
      "#<#{self.class}: #{id} [#{@njobs.collect{|n| n.class.name}.join(" ")}]>"
    end

  end

  def Processor.start(id, node_port)
    processor = Processor.new(id)
    processor.start(node_port)
  end

end

require "node/addins"
#
# Don't modified this file.
# This file is auto generation. 
#
module Fairy
    Version = "0.2.6-022"
end



backend_dir = File.dirname(__FILE__)
for backend in Dir.glob("#{backend_dir}/*.rb")
  next if backend == __FILE__

#  puts "require #{backend}"
  require backend
end


# require "backend/bfile"
# require "backend/b-local-file-input"
# require "backend/b-input-iota"
# require "backend/b-there"

# require "backend/b-file-output"
# require "backend/b-local-file-output"
# require "backend/bhere"

# require "backend/b-each-element-mapper"
# require "backend/b-each-substream-mapper"
# require "backend/b-each-element-selector"
# require "backend/b-group-by"
# require "backend/b-zipper"
# require "backend/b-splitter"
# require "backend/b-shuffle"
# require "backend/b-barrier"



module Fairy

  class Atom
    def initialize(receiver, message, *args)
      @receiver = receiver
      @message = message
      @args = args
    end

    attr_reader :receiver, :message, :args
    
  end
end

  
require "forwardable"

require "deep-connect/deep-connect"

require "backend/bjob"
require "backend/b-inputtable"

require "share/block-source"

module Fairy
  class BBarrier<BFilter
    extend Forwardable

    Controller.def_export self

#    include BInputtable

#    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL)")

    def initialize(controller, opts)
      super
      for k, val in opts
	case k
	when :mode
	  @mode = BBarrierMode.create(self, val, opts)
	when :cond
	  @cond = BBarrierCond.create(self, val, opts)
	when :buffer
	  @buffer = BBarrierBuffer.create(self, val, opts)
	else
	end
      end
    end

    def each_export(&block)
      @mode.wait_exportable
      @buffer.each_export(&block)
    end

    def_delegator :@mode, :wait_export

    def_delegator :@cond, :wait_cond

    def_delegator :@buffer, :input=
    def_delegator :@buffer, :output=

    def_delegator :@buffer, :node_arrived?
    def_delegator :@buffer, :data_arrived?
    def_delegator :@buffer, :all_data_imported?

    #
    module Factory
      def self.extended(mod)
	mod.init_fact
      end

      def init_fact
	@ModeName2Class = {}
      end
      
      def create(bbarrier, mode, *opts)
	klass = @ModeName2Class[mode]
	raise "そのモードはありません#{mode}" unless klass
	
	mode = klass.new(bbarrier, mode, *opts)
      end

      def register_mode(mode, klass)
	@ModeName2Class[mode] = klass
      end

    end

    module Mode
      def initialize(bbarrier, mode, *opts)
	@bbarrier = bbarrier
	@mode = mode
#	Log::debug self, self.class.superclass.name
	begin
	  super(*opts)
	rescue
	  # ちょっとイマイチか...
	  super()
	  @opts = opts.first
	end
      end
    end
    
    #
    class BBarrierMode
      extend Factory
      include Mode

      def initialize(bbarrier, mode, *opts)
	super
	@opts = opts
      end

    end

    class BBarrierNodeCreationMode<BBarrierMode
      BBarrierMode.register_mode(:NODE_CREATION, self)

      def wait_exportable
	@bbarrier.wait_cond
      end

      def wait_export
	true
      end

    end

    class BBarrierStreamMode<BBarrierMode
      BBarrierMode.register_mode(:STREAM, self)

      def wait_exportable
	true
      end

      def wait_export
	@bbarrier.wait_cond
      end

    end

    #
    class BBarrierCond
      extend Factory
      include Mode
      
      def self.create(bbarrier, mode, opts=nil)
	if mode.kind_of?(BlockSource)
	  opts[:BLOCK_SOURCE] = mode
	  super(bbarrier, :BLOCK_COND, opts)
	else
	  super(bbarrier, mode, opts)
	end
      end

      def wait_cond
	raise "まだできていません"
      end

    end

    class BBarrierNodeArrivedCond<BBarrierCond
      BBarrierCond.register_mode(:NODE_ARRIVED, self)

      def wait_cond
	@bbarrier.node_arrived?
      end

    end

    class BBarrierDataArrivedCond<BBarrierCond
      BBarrierCond.register_mode(:DATA_ARRIVED, self)

      def wait_cond
	@bbarrier.data_arrived?
      end

    end

    class BBarrierAllDataCond<BBarrierCond
      BBarrierCond.register_mode(:ALL_DATA, self)

      def wait_cond
	@bbarrier.all_data_imported?
      end
    end

    class BBarrierBlockCond<BBarrierCond
      BBarrierCond.register_mode(:BLOCK_COND, self)

      def initialize(bbarrier, mode, opts)
	super(bbarrier, mode, opts)

	if @opts[:BEGIN]
	  bs = BScript.new(@opts[:BEGIN], 
			   @bbarrier.instance_eval{@context}, 
			   @bbarrier)
	  bs.evaluate
	end
	@block_source = @opts[:BLOCK_SOURCE]
	@block = BBlock.new(@block_source, 
			    @bbarrier.instance_eval{@context}, 
			    @bbarrier)
	# @opts[:END] は未サポート
      end

      def wait_cond
	@block.call
      end
    end

    #
    class BBarrierBuffer<BFilter
      extend Factory
      include Mode
    end

    class BBarrierMemoryBuffer<BBarrierBuffer
      BBarrierBuffer.register_mode(:MEMORY, self)

      def initialize(bbarrier, mode, opts=nil)
	super(bbarrier, mode, bbarrier.instance_eval{@controller}, opts)
      end

      def node_arrived?
	number_of_nodes
      end

      def data_arrived?
	@nodes_status_mutex.synchronize do
	  while !all_node_data_arrived?
	    @nodes_status_cv.wait(@nodes_status_mutex)
	  end
	end
	true
      end

      def all_data_imported?
	@nodes_status_mutex.synchronize do
	  while !all_node_data_imported?
	    @nodes_status_cv.wait(@nodes_status_mutex)
	  end
	end
	true
      end

      def node_class_name
	"NBarrierMemoryBuffer"
      end

      def wait_export
	@bbarrier.wait_export
      end

      def all_node_data_arrived?
	return false unless @number_of_nodes

	data_arrived = true
	each_node(:exist_only) do |node|
	  st = @nodes_status[node]
	  data_arrived &&= [:ST_ACTIVATE, :ST_FINISH, :ST_EXPORT_FINISH, :ST_WAIT_EXPORT_FINISH].include?(st)
	end
	data_arrived
      end

      def all_node_data_imported?
	return false unless @number_of_nodes

	all_data_imported = true
	each_node(:exist_only) do |node|
	  st = @nodes_status[node]
	  s = [:ST_FINISH, :ST_EXPORT_FINISH, :ST_WAIT_EXPORT_FINISH].include?(st)
	  all_data_imported &&= [:ST_FINISH, :ST_EXPORT_FINISH, :ST_WAIT_EXPORT_FINISH].include?(st)
	end
	all_data_imported
      end

    end

    class BBarrierFileBuffer<BBarrierBuffer
      BBarrierBuffer.register_mode(:FILE, self)

      def node_class_name
	"NBarrier::NBarrierFileBuffer"
      end
    end

  end
end




require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BEachElementMapper<BFilter
    Controller.def_export self

    def initialize(controller, opts, block_source)
      super
      @block_source = block_source
    end

    def node_class_name
      "NEachElementMapper"
    end

    def njob_creation_params
      [@block_source]
    end
  end
end

require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BEachElementSelector<BFilter
    Controller.def_export self

    def initialize(controller, opts, block_source)
      super
      @block_source = block_source
    end

    def node_class_name
      "NEachElementSelector"
    end

    def njob_creation_params
      [@block_source]
    end

  end
end

require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BEachSubStreamMapper<BFilter
    Controller.def_export self

    def initialize(controller, opts, block_source)
      super
      @block_source = block_source
    end

    def node_class_name
      "NEachSubStreamMapper"
    end

    def njob_creation_params
      [@block_source]
    end
  end
end

require "controller"
require "backend/boutput"

module Fairy
  class BFileOutput<BOutput
    Controller.def_export self

    def initialize(controller, opts)
      super
      @vfile = nil
    end

    def output(vf)
      @vfile = vf
    end

    def node_class_name
      "NFileOutput"
    end

    def njob_creation_params
      [@vfile]
    end

    def create_nodes
      no = 0
      input_processors = {}
      @input.each_export do |input_export, input_njob|
	if njob = input_processors[input_njob.processor]
	  njob.add_input(input_export)
	else
	  njob = create_and_add_node(input_export, input_njob)
	  input_processors[njob.processor] = njob
	  no += 1
	end
      end
      for p, njob in input_processors
	njob.add_input(nil)
      end
      self.number_of_nodes = no
    end


    def wait_all_output_finished
      while !all_node_outputted?
	@nodes_status_mutex.synchronize do
	  @nodes_status_cv.wait(@nodes_status_mutex)
	end
      end
    end

    def all_node_outputted?
      return false unless @number_of_nodes

      all_outputted = true
      each_node(:exist_only) do |node|
	st = @nodes_status[node]
	all_imported &= [:ST_FINISH, :ST_OUTPUT_FINISH].include?(st)
      end
      all_outputted
    end

  end
end

require "backend/bjob"
require "backend/b-inputtable"

module Fairy
  class BFilter<BJob
    include BInputtable

    def node_class
      raise "Node Classが定義されていません"
    end

     def input=(input)
       input.output = @input
       super
     end
#    attr_reader :input

    def output=(output)
      @output = output
    end
  end
end

require "forwardable"

require "deep-connect/deep-connect"

require "backend/b-filter"

module Fairy
  class BFind<BFilter
    extend Forwardable

    Controller.def_export self

    def initialize(controller, opts, block_source)
      super

      @block_source = block_source

      @blocal_find = BLocalFind.new(controller, opts, block_source)
      @bfind_result = BFindResult.new(controller, opts, self)

    end

    def_delegator :@bfind_result, :value
    def_delegator :@bfind_result, :output=
    def_delegator :@bfind_result, :each_export

    def input=(input)
      @blocal_find.input = input
      @bfind_result.input = @blocal_find
    end

    def update_find
#      @blocal_find.find_break
      @blocal_find.break_running
    end

    class BLocalFind<BFilter
      def initialize(controller, opts, block_source)
	super
	@block_source = block_source
      end

      def node_class_name
	"NLocalFind"
      end

      def njob_creation_params
	[@block_source]
      end
      
      def each_export(&block)
	no = 0
	first_node = nil
	each_node do |node|
	  no += 1
	  if first_node
	    node.export.output = first_node.export.output
	  else
	    first_node = node
	    block.call node.export, node
	  end
	end
	first_node.export.output_no_import = no
      end

#       def find_break
# 	# create node 中ならそれをとめる
# 	break_create_node
# 	# 各tasklettをとめる
# 	each_node do |tasklet|
# 	  tasklet.find_break
# 	end
#       end

    end

    class BFindResult<BFilter
      def initialize(controller, opts, bfind)
	super
	@bfind = bfind

	@find_mutex = Mutex.new
	@findp = false
      end

      def node_class_name
	"NFindResult"
      end

      def njob_creation_params
	[]
      end

      def value
	each_node{|node| return node.value}
      end

      def update_find
	@find_mutex.synchronize do
	  if !@findp
	    @findp = true
	    @bfind.update_find
	  end
	end
      end
    end
  end
end

require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BGroupBy<BFilter
    Controller.def_export self

    def initialize(controller, opts, block_source)
      super
      @block_source = block_source

      @no_of_exports = 0
      @exports = {}
      @exports_mutex = Mutex.new
      @exports_cv = ConditionVariable.new

      @exports_queue = Queue.new
    end

    def start_create_nodes
      super

      start_watch_all_node_imported
    end

    def each_export(&block)
      while pair = @exports_queue.pop
	block.call pair
      end
    end

    def add_exports(key, export, njob)
      @exports_mutex.synchronize do
	export.no = @no_of_exports
	@no_of_exports += 1
	if exports = @exports[key]
	  export.output=exports.first.output
	  exports.push export
	else
	  @exports[key] = [export]
	  @exports_queue.push [export, njob]
	end
      end
    end

    def update_exports(key, export, njob)
      add_exports(key, export, njob)
    end

    def node_class_name
      "NGroupBy"
    end

    def njob_creation_params
      [@block_source]
    end

    def start_watch_all_node_imported
      Thread.start do
	@nodes_status_mutex.synchronize do
	  while !all_node_imported?
	    @nodes_status_cv.wait(@nodes_status_mutex)
	  end
	end
	@exports_queue.push nil
	for key, exports in @exports
	  exports.first.output_no_import = exports.size
	end
      end
      nil
    end

    def all_node_imported?
      # すべてのnjobがそろったか?
      return false unless @nodes_mutex.synchronize{@number_of_nodes}

      each_node(:exist_only) do |node|
	st = @nodes_status[node]
	unless [:ST_FINISH, :ST_EXPORT_FINISH, :ST_WAIT_EXPORT_FINISH].include?(st)
	  return false
	end
      end
      true
    end
  end

  class BMGroupBy<BGroupBy
    Controller.def_export self

    def node_class_name
      "NMGroupBy"
    end
  end


end
require "forwardable"

require "deep-connect/deep-connect"

require "backend/b-filter"

module Fairy
  class BInject<BFilter
    extend Forwardable

    Controller.def_export self

    def initialize(controller, opts, block_source)
      super

      @block_source = block_source

      @blocal_inject = BLocalInject.new(controller, opts, block_source)
      @bwide_inject = BWideInject.new(controller, opts, block_source)

    end

    def_delegator :@bwide_inject, :value
    def_delegator :@bwide_inject, :output=
    def_delegator :@bwide_inject, :each_export

    def input=(input)
      @blocal_inject.input = input
      @bwide_inject.input = @blocal_inject
    end

    class BLocalInject<BFilter
      def initialize(controller, opts, block_source)
	super
	@block_source = block_source
      end

      def node_class_name
	"NLocalInject"
      end

      def njob_creation_params
	[@block_source]
      end
      
      def each_export(&block)

	no = 0
	first_node = nil
	each_node do |node|
	  no += 1
	  if first_node
	    node.export.output = first_node.export.output
	  else
	    first_node = node
	    block.call node.export, node
	  end
	end
	first_node.export.output_no_import = no
      end

    end

    class BWideInject<BFilter
      def initialize(controller, opts, block_source)
	super
	@block_source = block_source
      end

      def node_class_name
	"NWideInject"
      end

      def njob_creation_params
	[@block_source]
      end

      def value
	each_node{|node| return node.value}
      end
    end
  end
end


module Fairy

  class BIota<BInput
    Controller.def_export self

    def initialize(controller, opts, last)
      super
      @last = last - 1
    end

    def node_class_name
      "NIota"
    end

    def create_and_start_nodes
      begin
	offset = 0
	offset = @opts[:offset] if @opts[:offset]
	split_no = @opts[:SPLIT_NO]

	first = offset
	no = 0
	split_no.times do
	  @create_node_mutex.synchronize do
	    no += 1
	    Log::debug self, "NO: #{no}"
	    last = [first + @last.div(split_no), @last].min
	    @controller.assign_processor(self, :NEW_PROCESSOR) do |processor|
	      njob = create_node(processor, first, last)
	      njob.start
	      first = last + 1
	    end
	  end
	  sleep 0.1
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      ensure
	self.number_of_nodes = no
      end
    end
  end
end

module Fairy

  class BInputVArray<BInput
    Controller.def_export self

    def initialize(controller, opts, varray)
      super
      @varray = varray
    end

    def node_class_name
      "NInputVArray"
    end

    def create_and_start_nodes
      begin
	no = 0
	@varray.arrays_size.times do 
	  @create_node_mutex.synchronize do
	    subarray = @varray.arrays_at(no)
	    @controller.assign_processor(self, 
					 :SAME_PROCESSOR_OBJ, 
					 subarray) do |processor|
	      njob = create_node(processor, subarray)
	      njob.start
	      no +=1
	    end
	  end
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      ensure
	self.number_of_nodes = no
      end
    end
  end
end

require "share/exceptions"

module Fairy
  module BInputtable

    def initialize(*rests)
      super
      @input = nil

      @create_node_thread = nil
      @create_node_mutex = Mutex.new
    end

    def input=(input)
      @input = input
#      input.output = @input

      start_create_nodes
    end

    attr_reader :input

    def start_create_nodes
      Log::debug self, "START_CREATE_NODES: #{self}"
      @create_node_thread = Thread.start{
	create_nodes
      }
      nil
    end

    def create_nodes
      begin
	no = 0
	@input.each_export do |export, node|
	  @create_node_mutex.synchronize do
	    create_and_add_node(export, node)
	    no += 1
	  end
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "CAUGHT EXCEPTION: BreakCreateNode: #{self}" 
      ensure
	Log::debug self, "CREATE_NODES: #{self}.number_of_nodes=#{no}"
	self.number_of_nodes = no
      end
    end

    def create_and_add_node(input_export, input_node)
      node = nil
      @controller.assign_inputtable_processor(self, 
					      @input, 
					      input_node, 
					      input_export) do |processor|
	node = create_node(processor)
      end
      node.input= input_export
      input_export.output = node.import
      node
    end

    def break_running(njob = nil)
      super
      Thread.start{@input.break_running}
    end
  end
end
require "uri"

require "backend/binput"
require "share/vfile"

module Fairy
  class BLFileInput<BInput
    Controller.def_export self

#    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL)")

    def BLFileInput.open(controller, opts = nil)
      blfileinput = BFile.new(controller, opts)
      blfileinput.open(descripter)
      blfileinput
    end

    def initialize(controller, opts = nil)
      super
    end

    def node_class_name
      "NLFileInput"
    end

    def start(job)
      @job = job
      super()
    end

    def create_and_start_nodes
      if @opts[:split_size]
	create_and_start_nodes_split
      else
	create_and_start_nodes1
      end
    end

    def create_and_start_nodes1
      begin
	no = 0
	@create_node_mutex.synchronize do
	  nlfileinput = nil
	  @controller.assign_new_processor(self) do |processor|
	    nlfileinput = create_node(processor)
	  end
	  no = 1
	  Thread.start do
	    @job.open do |io|
	      nlfileinput.open(io)
	      wait_input_finished(nlfileinput)
	    end
	  end
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      ensure
	self.number_of_nodes = no
      end
      nil
    end

    def create_and_start_nodes_split
      begin
	no_nodes = 0
	@job.split_opens(@opts[:split_size]) do |io|
	  @create_node_mutex.synchronize do
	    no_nodes += 1
	    nlfileinput = nil
	    @controller.assign_new_processor(self) do |processor|
	      nlfileinput = create_node(processor)
	    end
	    Thread.start(nlfileinput) do |nlfi|
	      begin
		nlfi.open(io)
		wait_input_finished(nlfi)
	      ensure
		io.close
	      end
	    end
	  end
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      ensure
	self.number_of_nodes = no_nodes
      end
    end

    def wait_input_finished(njob)
      while !njob_input_finished?(njob)
	@nodes_status_mutex.synchronize do
	  @nodes_status_cv.wait(@nodes_status_mutex)
	end
      end
    end

    def njob_input_finished?(njob)
      return false
      st = @nodes_status[njob]
      [:ST_WAIT_EXPORT_FINISH, :ST_EXPORT_FINISH, :ST_FINISH, :ST_OUTPUT_FINISH].include?(st)
    end

  end
end

require "backend/boutput"

module Fairy
  class BLFileOutput<BOutput
    Controller.def_export(self)

    def initialize(controller, opts=nil)
      @imports = Queue.new
      super
    end

    def output(job)
      @job = job
    end

    def node_class_name
      "NLFileOutput"
    end

    def create_nodes
      no = 0
      input_processors = {}
      @input.each_export do |input_export, input_njob|
	if njob = input_processors[input_njob.processor]
	  njob.add_input(input_export)
	else
	  njob = create_and_add_node(input_export, input_njob)
	  input_processors[njob.processor] = njob
	  no += 1

	  import = Import.new
	  @imports.push import
	  njob.export.output = import
	  import.no_import = 1
	end
      end
      for p, njob in input_processors
	njob.add_input(nil)
      end
      self.number_of_nodes = no

      @imports.push nil
    end

    def each(&block)
      while import = @imports.pop
	import.each do |e|
	  block.call e
	end
      end
    end

    def wait_all_output_finished
      while !all_node_outputted?
	@nodes_status_mutex.synchronize do
	  @nodes_status_cv.wait(@nodes_status_mutex)
	end
      end
    end

    def all_node_outputted?
      return false unless @number_of_nodes

      all_outputted = true
      each_node(:exist_only) do |node|
	st = @nodes_status[node]
	all_outputted &= [:ST_FINISH, :ST_OUTPUT_FINISH].include?(st)
      end
      all_outputted
    end

  end
end

require "controller"
require "backend/boutput"

require "share/varray"

module Fairy
  class BOutputVArray<BOutput
    Controller.def_export self

    def initialize(controller, opts)
      super
      @varray = VArray.new

      @node_id = 0
    end

    attr_reader :varray

    def node_class_name
      "NOutputVArray"
    end

    def njob_creation_params
      @node_id += 1
      [@node_id-1]
#      []
    end

    def number_of_nodes=(no_nodes)
      super
      ary = Array.new(no_nodes)
      @varray.set_arrays(ary)
    end

    def wait_all_output_finished
      @nodes_status_mutex.synchronize do
	while !all_node_outputted?
	  @nodes_status_cv.wait(@nodes_status_mutex)
	end
      end
    end

    def all_node_outputted?
      return false unless @nodes_mutex.synchronize{@number_of_nodes}

      each_node(:exist_only) do |node|
	st = @nodes_status[node]
	return false unless [:ST_FINISH, :ST_OUTPUT_FINISH].include?(st)
      end
      true
    end

  end
end

require "delegate"

require "backend/bjob"

module Fairy
  class BShuffle<BFilter
    Controller.def_export self

#    include BInputtable

    def initialize(controller, opts, block_source)
      super
#      @block = @context.create_proc(@block_source.source)

      @input2node = {}
      @input_queue = PortQueue.new
      @output_queue = PortQueue.new

      @block_source = block_source
      @begin_block_source = nil
      if @opts[:BEGIN]
	@begin_block_source = @opts[:BEGIN]
      end
      @end_block_source = nil
      if @opts[:END]
	@end_block_source = @opts[:END]
      end

    end

    def input=(input)
      @input = input
      start_get_exports
      start
    end

    def start_get_exports
      Thread.start do
	@input.each_export do |export, node|
	  @input2node[export] = node
	  @input_queue.push export
	end
	@input_queue.push nil
      end
    end

    def start
      Thread.start do
	if @begin_block_source
	  bsource = BScript.new(@begin_block_source, @context, self)
	  bsource.evaluate
	end
	@block = BBlock.new(@block_source, @context, self)
	begin
	  @block.call(@input_queue, @output_queue)
	  @output_queue.push nil
	ensure
	  if @end_block_source
	    bsource = BSource.new(@end_block_source, @context, self)
	    bsource.evaluate
	  end
	end
      end
      nil
    end

    def each_export(&block)
      for exp in @output_queue
	node = @input2node[exp]
	block.call exp, node
      end
    end

    class PortQueue<DelegateClass(Queue)
      include Enumerable

      def initialize
	super(Queue.new)
      end

      def each
	while e = pop
	  yield e
	end
      end
    end
  end
end

require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BSplitter<BFilter
    Controller.def_export self

#    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL, VAL)")

    def initialize(controller, opts, n)
      super
      @no_split = n

      @no_of_exports = 0

#       @exports = []
#       @exports_mutex = Mutex.new
#       @exports_cv = ConditionVariable.new

#       @exports_queue = Queue.new
    end

    def start_create_nodes
      super

    end

    def each_export(&block)
      each_node do |node|
	for exp in node.exports
	  exp.no = @no_of_exports
	  @no_of_exports += 1
	  block.call exp, node
	  exp.output_no_import = 1
	end
      end

    end

    def node_class_name
      "NSplitter"
    end
    
    def njob_creation_params
      [@no_split]
    end
  end
end

require "controller"
require "backend/binput"

module Fairy
  class BThere<BInput
    Controller.def_export self

    def initialize(controller, opts, enumerable)
      super
      @enumerable = enumerable
    end

    def node_class_name
      "NThere"
    end

    def njob_creation_params
      [@enumerable]
    end

    def create_and_start_nodes
      begin
	no = 0
	@create_node_mutex.synchronize do
	  nthere = nil
	  @controller.assign_new_processor(self) do |processor|
	    nthere = create_node(processor)
	  end
	  no += 1
	  nthere.start
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      ensure
	self.number_of_nodes = no
      end
    end
  end
end


      

require "backend/b-filter"
require "backend/b-inputtable"

module Fairy
  class BZipper<BFilter
    Controller.def_export self

    ZIP_BY_SUBSTREAM = :ZIP_BY_SUBSTREAM

    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL, VAL, REF)")

    def initialize(controller, opts, others, block_source)
      super
      @others = others
      @block_source = block_source
    end

    def opt_zip_by_substream?
      @opts[ZIP_BY_SUBSTREAM]
    end

    def node_class_name
      "NZipper"
    end

    def njob_creation_params
      [@block_source]
    end

    def start_create_nodes
      @other_export_queues = @others.collect{|other|
	exports = Queue.new
	Thread.start do
	  other.each_export do |export, node|
	    exports.push export
	  end
	end
	exports
      }
      super
    end

    def create_and_add_node(export, node)
      node = super
      if opt_zip_by_substream?
	others = @other_export_queues.collect{|queue| queue.pop	}
	node.zip_inputs = others
	others.zip(node.zip_imports){|other, import| other.output = import}
      else
	raise "まだできていません"
      end
    end

    def break_running
      super
      @others.each{|others| Thread.start{others.break_running}}
    end
  end
end
require "uri"

require "controller"
require "backend/binput"
require "share/vfile"

module Fairy
  class BFile<BInput
    Controller.def_export self

    def BFile.open(controller, opts, descripter)
      bfile = BFile.new(controller, opts)
      bfile.open(desctipter)
      bfile
    end
    DeepConnect.def_single_method_spec(self, "REF open(REF, VAL, VAL)")

    URI_REGEXP = /:\/\//

    def node_class_name
      "NFile"
    end

    def open(vf)
      @vfile = vf
      start
    end
    DeepConnect.def_method_spec(self, "REF open(DVAL)")

    def create_and_start_nodes
      begin
	no = 0
 Log::debug self, "VFile: #{@vfile}"
	for file in @vfile
 Log::debug self, "File: #{file}"
	  @create_node_mutex.synchronize do
	    no +=1

	    host = "localhost"
	    path = file
	    if URI_REGEXP =~ file
	      uri = URI(file)
	      host = uri.host
	      if /^\[([0-9a-f.:]*)\]$/ =~ host
		host = $1
	      end
	      path = uri.path
	    end
	    @controller.assign_input_processor(self, host) do |processor|
	      node = create_node(processor)
	      node.open(path)
	    end
	  end
	end
      rescue BreakCreateNode
	# do nothing
	Log::debug self, "BREAK CREATE NODE: #{self}" 
      rescue Exception
	p $!
	Log::debug_exception(self)
	raise
      ensure
	Log::debug self, "CREATE_NODES: #{self}.number_of_nodes=#{no}"
	self.number_of_nodes = no
      end
    end
  end
end

require "backend/b-filter"
require "backend/b-inputtable"

require "node/port"


module Fairy
  class BHere<BFilter
    Controller.def_export self

    def initialize(controller, opts=nil)
      
      @imports = Queue.new
      super
    end

    def create_nodes
      super

      @imports.push nil
    end

    def create_and_add_node(export, bjob)
      node = super(export, bjob)
      import = Import.new
      @imports.push import
      node.export.output = import
      import.no_import = 1
    end

    def node_class_name
      "NHere"
    end

    def each(&block)
      while import = @imports.pop
	import.each do |e|
	  block.call e
	end
      end
    end
  end
end



require "backend/bjob"

module Fairy
  class BInput<BJob
    def initialize(*rests)
      super
      
      @create_node_thread = nil
      @create_node_mutex = Mutex.new
    end

    def output=(output)
      @output = output
    end

    def start
      @create_node_thread = Thread.start {
	create_and_start_nodes
      }
    end
  end
end

require "controller"

module Fairy
  class BJob
    Controller.def_export self

    @@watch_status = false
    def self.watch_status
      @@watch_status
    end

    def self.watch_status=(val)
      @@watch_status=val
    end

    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL, *DEFAULT)")

    def initialize(controller, opts, *rests)
      Log::info self, "CREATE BJOB: #{self.class}"
      @controller = controller

      @opts = opts
      @opts = {} unless @opts

      @job_pool_dict = PoolDictionary.new

      @number_of_nodes = nil
#      @number_of_nodes_mutex = Mutex.new
#      @number_of_nodes_cv = ConditionVariable.new

      @nodes = []
      @nodes_mutex = Mutex.new
      @nodes_cv = ConditionVariable.new

      @nodes_status = {}
      @nodes_status_mutex = Mutex.new
      @nodes_status_cv = ConditionVariable.new

      @context = Context.new(self)

      start_watch_node_status if watch_status?
    end

    # プール変数
    def pool_dict
      @controller.pool_dict
    end

    def job_pool_dict
      @job_pool_dict
    end

    def def_job_pool_variable(vname, value = nil)
      @job_pool_dict.def_variable(vname, value)
    end

    def job_pool_variable(vname, *value)
      if value.empty?
	@job_pool_dict[vname]
      else
	@job_pool_dict[vname] = value
      end
    end

    #
    def create_node(processor, *params)
      if params.empty?
	params = njob_creation_params
      end
      njob = processor.create_njob(node_class_name, self, @opts, *params)
      add_node(njob)
      njob
    end
    
    def node_class_name
      raise "#{self.class}のNjobクラス名が登録されていません"
    end

    def njob_creation_params
      []
    end

    def number_of_nodes
#      @number_of_nodes_mutex.synchronize do
      @nodes_mutex.synchronize do
	while !@number_of_nodes
#	  @number_of_nodes_cv.wait(@number_of_nodes_mutex)
	  @nodes_mutex_cv.wait(@nodes_mutex)
	end
	@number_of_nodes
      end
    end

    def number_of_nodes=(no)
#puts "#{self}.number_of_nodes=#{no}"
#      @number_of_nodes_mutex.synchronize do
      @nodes_mutex.synchronize do
	@number_of_nodes = no
#	@number_of_nodes_cv.broadcast
	@nodes_cv.broadcast
	@nodes_status_cv.broadcast
      end
    end

    def nodes
      @nodes_mutex.synchronize do
	@nodes
      end
    end

    def add_node(node)
      @nodes_mutex.synchronize do
	node.no = @nodes.size
	@nodes.push node
	@nodes_cv.broadcast
      end
    end

    def each_node(flag = nil, &block)
      if flag == :exist_only
	return each_node_exist_only &block
      end
      @nodes_mutex.synchronize do
	idx = 0
	while !@number_of_nodes || idx < @number_of_nodes
	  unless @nodes[idx]
	    @nodes_cv.wait(@nodes_mutex)
	    next
	  end
	  block.call @nodes[idx] 
	  idx +=1
	end
      end
    end

    def each_node_exist_only(&block)
      nodes = @nodes_mutex.synchronize{@nodes.dup}
      nodes.each &block
    end

    def each_export(&block)
      each_node do |node|
	exp = node.export
	block.call exp, node
	node.export.output_no_import = 1
      end
    end

    def break_running(njob = nil)
      break_create_node
      
      each_node do |tasklet|
	tasklet.break_running unless tasklet.equal?(njob)
      end
    end

    def break_create_node
      # 作成中のものは完全に作成させるため
Log::debug self, "BREAK_CREATE_NODE: #1"
      @create_node_mutex.synchronize do
Log::debug self, "BREAK_CREATE_NODE: #2"
	@create_node_thread.raise BreakCreateNode
Log::debug self, "BREAK_CREATE_NODE: #3"
      end
Log::debug self, "BREAK_CREATE_NODE: #4"
    end

    def update_status(node, st)
      @nodes_status_mutex.synchronize do
	@nodes_status[node] = st
	@nodes_status_cv.broadcast
      end
    end

    def watch_status?
      @@watch_status
    end

    def start_watch_node_status
      Thread.start do

	all_finished = false
	while !@number_of_nodes || !all_finished
	  @nodes_status_mutex.synchronize do
	    @nodes_status_cv.wait(@nodes_status_mutex)
	  end

	  all_finished = @number_of_nodes
	  Log::info(self) do |sio|
	    sio.puts "Status Changed: BEGIN #{self}"
	    each_node(:exist_only) do |node|
	      st = @nodes_status[node]
	      sio.puts "  node: #{node} status: #{st.id2name}" if st
	      all_finished &&= st==:ST_FINISH
	    end
	    sio.puts "Status Changed: END #{self}"
	  end
	end
	Log::info self, "ALL NJOB finished"
      end
      nil
    end

    def handle_exception(exp)
      @controller.handle_exception(exp)
    end

    class Context
      def initialize(bjob)
	@Pool = bjob.instance_eval{pool_dict}
	@JobPool = bjob.instance_eval{job_pool_dict}
	@__context = context
      end

#      def create_proc(source)
#	eval("proc{#{source}}", binding)
#      end

      def context
	__binding
      end

      class GlobalBreak<Exception;end
      def global_break
	Thread.current.raise GlobalBreak
      end
      alias gbreak global_break

      alias __binding binding
      def binding
	@__context
      end
      alias bind binding
    end
  end
end

require "backend/bjob"
require "backend/b-inputtable"

module Fairy
  class BOutput<BJob
    include BInputtable

    def input=(input)
      @input = input
      input.output = @input
      super
    end

  end
end

require "backend/bfile"
require "backend/b-each-element-mapper"
require "backend/b-each-substream-mapper"
require "backend/b-each-element-selector"
require "backend/bhere"
require "backend/b-group-by"
require "backend/b-zipper"

module Fairy
  class JobInterpriter
    def initialize(controller)
      @controller = controller
    end

    def exec(atom)
      puts "SEND: #{atom.receiver}.#{atom.message}(#{atom.args.map{|e| e.to_s}.join(",")})"
      ret = atom.receiver.send(atom.message, *atom.args)
      # このあと何か必要か?
    end
  end
end


module Fairy
  class Scheduler

    def initialize(controller)
      # 取りあえず
      @controller = controller
      #@processors = [Processor.new]
    end
      

    def schedule(atom)
      # 取りあえず.
      # ここで, atomにはノード指定がすでにあるとしている.
      # 指定されたノードにスケジュールする.
      @processors[0].exec atom
    end
    
  end
end
#
#   accepter.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Laboratories Co.,Ltd)
#
# --
#
#   
#

require "socket"
require "ipaddr"

require "deep-connect/event"

module DeepConnect
  class Accepter
    def initialize(org)
      @organizer = org
      @probe = nil
    end

    def port_number
      @probe.addr[1]
    end

    def open(service = 0)
      @probe = TCPServer.open("", service)
    end

    def start
      @probe_thread = Thread.start {
	loop do
	  sock = @probe.accept
	  Thread.start do
	    port = Port.new(sock)
	    begin
	      unless (ev = port.import).kind_of?(Event::InitSessionEvent)
		puts "WARN: 接続初期化エラー: [#{port.peeraddr}]"
	      end
	      begin
		@organizer.connect_deep_space_with_port port, ev.local_id
	      rescue ConnectCancel
		puts "INFO: クライアント(#{ev.local_id}からの接続を拒否しました."
	      rescue ConnectionRefused
		puts "WARN: クライアント(#{ev.local_id}への接続が拒否されました"
	      rescue ProtocolError, IOError
		puts "WARN: 接続初期化エラー: [#{port.peeraddr}]"

	      end
	    rescue EOFError
	      puts "WARN: 接続初期化中に[#{port.peeraddr}]との接続が切れました"
	    end
	  end
	end
      }
    end

    def stop
      @probe_thread.exit
      @probe.close
    end
  end
end

    

require "thread"
require "e2mmap"

module DeepConnect

  class ClassSpecSpace
    NULL = :NULL

    def initialize(remote = :remote)
      case remote
      when :remote
	@class_specs = nil
      when :local
	@class_specs = {}
      end

      @class_specs_mutex = Mutex.new
      @class_specs_cv = ConditionVariable.new

      @method_spec_cache = {}
    end

    def class_spec_id_of(obj)
      ancestors = obj.class.ancestors
      begin
	single = (class<<obj;self;end)
	ancestors.unshift single
      rescue
      end
#p ancestors
#      p ancestors.collect{|e| e.object_id}
      klass = ancestors.find{|kls|
	@class_specs[kls.object_id]
      }
      if klass
	klass.object_id
      else
	nil
      end
    end

    def method_spec(ref_or_obj, method)
      puts "method_spec(#{ref_or_obj}, #{method})" if DISPLAY_METHOD_SPEC
      if ref_or_obj.__deep_connect_reference?
	csid = ref_or_obj.csid
      else
	csid = class_spec_id_of(ref_or_obj)
      end
      return nil unless csid

#      mid = [csid, method]
#      mid = sprintf("%X-%s", csid, method)
      mid = "#{csid}-#{method}"
      case mspec = @method_spec_cache[mid]
      when nil
	# pass
      when NULL
	return nil
      else
	return mspec
      end

      class_spec_ancestors(csid) do |cspec|
	if mspec = cspec.method_spec(method)
	  return mspec
	end
      end
      @method_spec_cache[mid] = NULL
      return nil
    end

    def def_method_spec(klass, *method_spec)
      csid = klass.object_id
      unless cspec = @class_specs[csid]
	cspec = ClassSpec.new(klass)
	@class_specs[csid] = cspec
      end
      
      if method_spec.size == 1 and method_spec.first.kind_of?(MethodSpec)
	mspec = method_spec.first
      else
	mspec = MethodSpec.spec(*method_spec)
      end
      cspec.add_method_spec(mspec)
    end

    def def_single_method_spec(obj, method_spec)
      klass = class<<obj;self;end
      def_method_spec(klass, method_spec)
    end

    def def_interface(klass, method)
      mspec = MethodSpec.new
      mspec.method = method
      mspec.interface = true
      def_method_spec(klass, mspec)
    end

    def def_single_interface(obj, method)
      klass = class<<obj;self;end
      def_interface(klass, method)
    end

    def class_specs=(cspecs)
      @class_specs_mutex.synchronize do
	@class_specs = cspecs
	@class_specs_cv.broadcast
      end
    end

    def class_specs
      @class_specs_mutex.synchronize do
	while !@class_specs
	  @class_specs_cv.wait(@class_specs_mutex)
	end
	@class_specs
      end
    end

    def class_spec_ancestors(csid, &block)
      @class_specs_mutex.synchronize do
	while !@class_specs
	  @class_specs_cv.wait(@class_specs_mutex)
	end
      end

      class_spec = @class_specs[csid]
      
      class_spec.ancestors.select{|anc| @class_specs[anc]}.each{|anc|
	yield @class_specs[anc]
      }
    end

  end

  class ClassSpec
    def initialize(klass)
      @name = klass.name
      @csid = klass.object_id
      ancestors = klass.ancestors
      ancestors.unshift klass
      @ancestors = ancestors.collect{|k| k.object_id}
      @method_specs = {}
    end

    attr_reader :name
    attr_reader :csid
    attr_reader :ancestors

    def add_method_spec(mspec)
      if sp = @method_specs[mspec.method]
	@method_specs[mspec.method].override(mspec)
      else
	@method_specs[mspec.method] = mspec
      end
    end

    def method_spec(method)
      @method_specs[method]
    end

  end

  class MethodSpec
    extend Exception2MessageMapper

    def_exception :UnrecognizedError, "パーズできません(%s)"

    # method(arg_spec, ..., *arg_spec)
    # ret_spec, ... method()
    # ret_spec, ... method(arg_spec, ..., *arg_spec)
    # ret_spec, ... method() block_ret, ... {}
    # ret_spec, ... method() {arg_spec, ...}
    # ret_spec, ... method() block_ret, ... {arg_spec, ...}
    # ret_spec, ... method(arg_spec, ..., *arg_spec) block_ret, ...  {arg_spec, ...}

    # *****method が記号の時できてない

    ARG_SPEC = ["DEFAULT", "REF", "VAL", "DVAL"]
    # VALができるのは, Array, Hash のみ, Structは相手にも同一クラスがあれば可能

    def self.spec(spec)
      mspec = MethodSpec.new
      case spec
      when String
	mspec.parse(spec)
      when Hash
	mspec.direct_setting(spec)
      else
	raise "スペック指定は文字列もしくはキーワード指定です"
      end
      mspec
    end

    def initialize
      @rets = nil
      @method = nil
      @args = nil
      @block_rets = nil
      @block_args = nil

      @interface = nil
    end

    attr_accessor :rets
    attr_accessor :method
    attr_accessor :args
    attr_accessor :block_rets
    attr_accessor :block_args
    attr_accessor :interface
    alias interface? interface

    def has_block? 
      @block_rets || @block_args 
    end

    def override(mspec)
      if mspec.rets
	@rets = mspec.rets
      end
      if mspec.args
	@args = mspec.args
      end
      if mspec.block_rets
	@block_rets = mspec.block.rets
      end
      if mspec.block_args
	@block_args = mspec.block_args
      end
      if mspec.interface
	@interface = mspec.interface
      end
    end

    class ArgSpecs
      include Enumerable
      def initialize(arg_specs)
	@arg_specs = arg_specs.dup
      end

      def each
	while arg_spec = @arg_specs.shift
	  if arg_spec.mult?
	    @arg_specs.unshift arg_spec
	  end
	  yield arg_spec
	end
      end

      def succ
	if (ret = @arg_specs.shift) && ret.mult?
	  @arg_specs.unshift ret
	end
	ret
      end

    end

    def rets_zip(rets, &block)
      retspecs = ArgSpecs.new(@rets)
      begin
	param_zip(retspecs, rets, &block)
      rescue ArgumentError
	raise ArgumentError,
	  "argument spec mismatch rets: #{@rets}"
      end
    end

    def arg_zip(args, &block)
      argspecs = ArgSpecs.new(@args)
      begin
	param_zip(argspecs, args, &block)
      rescue ArgumentError
	raise ArgumentError,
	  "argument spec mismatch args: #{@args}"
      end
    end

    def block_arg_zip(args, &block)
      argspecs = ArgSpecs.new(@block_args)
      begin
	param_zip(argspecs, args, &block)
      rescue ArgumentError
	raise ArgumentError,
	  "argument spec mismatch block args: #{@block_args}"
      end
    end

    def param_zip(arg_specs, args, &block)
      ary = []
      args.each do |arg|
	spec = arg_specs.succ
	unless spec
	  raise ArgumentError
	end
	ary.push yield(spec, arg)
      end
      ary
    end

    def to_s
      spec = ""
      case @rets
      when nil
      when Array
	spec.concat(@rets.join(", "))
	spec.concat(" ")
      when
	spec.concat(@rets.to_s)
	spec.concat(" ")
      end
      
      if @method
	spec.concat(@method.to_s)
      else
	spec.concat("(missing)")
      end
      if @args
	spec.concat("("+@args.join(", ")+")")
      end
      if has_block?
	if @block_rets
	  spec.concat(@block_rets.join(", "))
	end
	if @block_args
	  spec.concat("{"+@block_args.join(", ")+"}")
	else
	  spec.concat("{}")
	end
      end
      "#<#{self.class} #{spec} >"
    end

    class ParamSpec
      def self.identifier(token, *opts)
	case token
	when String
	  name = token
	  if /^\*(.*)/ =~ token
	    name = $1
	    opts.push :mult
	  end
	when Token
	  name = token.name
	end

	klass = Name2ParamSpec[name]
	unless klass
	  MethodSpec.Raise UnrecognizedError, name
	end
	pspec = klass.new(name)
	if opts.include?(:mult)
	  pspec.mult = true
	end
	pspec
      end

      def self.param_specs(string_ary)
	case string_ary
	when nil
	  nil
	when Array
	  string_ary.collect{|e| ParamSpec.identifier(e)}
	else
	  [ParamSpec.identifier(string_ary)]
	end
      end

      def initialize(name)
	@type = name

	@mult = nil
      end

      attr_reader :type
      attr_accessor :mult
      alias mult? mult

      def to_s
	if mult
	  "*"+@type
	else
	  @type
	end
      end
    end
    
    class DefaultParamSpec<ParamSpec;end
    class RefParamSpec<ParamSpec;end
    class ValParamSpec<ParamSpec;end
    class DValParamSpec<ParamSpec;end
    
    Name2ParamSpec = {
      "DEFAULT"=>DefaultParamSpec,
      "REF" => RefParamSpec,
      "VAL" => ValParamSpec,
      "DVAL" => DValParamSpec
    }

    def direct_setting(opts)
      if opts[:rets]
	@rets = ParamSpec.param_specs(opts[:rets])
	if @rets.size == 1
	  @rets = @rets.first
	end
      end

      @method = opts[:method]
      @method = @method.intern unless @method.kind_of?(Symbol)

      if opts[:args]
	@args = ParamSpec.param_specs(opts[:args])
      end

      if opts[:block_rets]
	@block_rets = ParamSpec.param_specs(opts[:block_rets])
	if @block_rets.size == 1
	  @block_rets = @block_rets.first
	end
      end
      if opts[:block_args]
	@block_args = ParamSpec.param_specs(opts[:block_args])
      end
    end

    # private method
    def parse(spec)
      tokener = Tokener.new(spec)
      
      tk1, tk2 = tokener.next, tokener.peek
      tokener.unget tk1
      case tk1
      when TkIdentifier
	case tk2
	when nil
	when TkIdentifier, TkCOMMA, TkMULT
	  parse_rets(tokener, spec)
	when TkLPAREN, TkLBRACE
	else
	  MethodSpec.Raise UnrecognizedError, spec
	end
      when TkMULTI
	parse_rets(tokener, spec)
      else
	MethodSpec.Raise UnrecognizedError, spec
      end
      
      parse_method(tokener, spec)
      parse_args(tokener, spec)
      parse_block(tokener, spec)
    end

    def parse_rets(tokener, spec)
      @rets = parse_params(tokener, spec)
      if @rets && @rets.size == 1
	@rets = @rets.first
      end
    end

    def parse_method(tokener, spec)
      tk = tokener.next
      case tk
      when TkIdentifier
	@method = tk.name.intern
      else
	MethodSpec.Raise UnrecognizedError, tk.to_s+ " in " +spec
      end
    end

    def parse_args(tokener, spec)
      tk = tokener.next
      case tk
      when TkLPAREN
	@args = parse_params(tokener, spec)
	tk2 = tokener.next
	unless tk2 == TkRPAREN
	  MethodSpec.Raise UnrecognizedError, tk2 + " in " +spec
	end
      else
	# パラメータなし
      end
    end

    def parse_block(tokener, spec)
      parse_block_rets(tokener, spec)
      tk = tokener.peek
      unless tk == TkLBRACE
	if @block_rets
	  MethodSpec.Raise UnrecognizedError, "ブロック定義では`{'が必要です(#{tk.to_s}, #{spec})"
	else
	  return
	end
      end
      parse_block_args(tokener, spec)
    end

    def parse_block_rets(tokner, spec)
      @block_rets = parse_params(tokner, spec)
      if @block_rets
	if @block_rets && @block_rets.size == 1
	  @block_rets = @block_rets.first
	end
      end
    end

    def parse_block_args(tokener, spec)
      tk = tokener.next
      case tk
      when TkLBRACE
	@block_args = parse_params(tokener, spec)
	@args = parse_params(tokener, spec)
	tk2 = tokener.next
	unless tk2 == TkRBRACE
	  MethodSpec.Raise UnrecognizedError, tk2 +" in " +spec
	end
      else
	# パラメータなし
      end
    end

    def parse_params(tokener, spec)
      args = []
      while token = tokener.next
	case token
	when TkIdentifier
	  case tk2 = tokener.peek
	  when nil
	    args.push ArgSpec.identifier(token)
	    break
	  when TkMULT
	    MethodSpec.Raise UnrecognizedError, token
	  when TkCOMMA
	    tokener.next
	    args.push ParamSpec.identifier(token)
	  when TkIdentifier, TkRPAREN, TkRBRACE
	    args.push  ParamSpec.identifier(token)
	    break
	  when TkLPAREN, TkLBRACE
	    args.push ParamSpec.identifier(token)
	    break
	  else
	    MethodSpec.Raise UnrecognizedError, "不正な文字#{tk2}が入っています"
	  end
	when TkMULT
	  case token2 = tokener.next
	  when nil
	    MethodSpec.Raise UnrecognizedError, "*で終わっています"
	  when TkIdentifier
	    args.push  ParamSpec.identifier(token2, :mult)
	    break
	  else
	    MethodSpec.Raise UnrecognizedError, "*の後に#{token2}が入っています"
	  end
	else # TkRPAREN, TkRBRACE
	  tokener.unget token
	  break
	end
      end
      if args.empty?
	nil
      else
	args
      end
    end

    class Token; end
    class TkIdentifier<Token
      def initialize(name)
	@name = name
      end
      attr_reader :name

      def to_s
	"#<#{self.class} #{@name}>"
      end
    end

    TkMULT = "*"
    TkLPAREN = "("
    TkLBRACE = "{"
    TkRPAREN = ")"
    TkRBRACE = "}"
    TkCOMMA = ","

    class Tokener
      def initialize(src)
	@src = src.split(//)
	@tokens = []
      end

      def next
	return @tokens.shift unless @tokens.empty?

	while /\s/ =~ @src[0]; @src.shift; end

	case @src[0]
	when nil
	  nil
	when ",", "(", ")", "{", "}", "*"
	  reading = @src.shift
	when /\w/
	  identify_identifier
	else
	  MethodSpec.Raise UnrecognizedError, @src.join("")
	end
      end

      def peek
	@tokens.first unless @tokens.empty?

	token = self.next
	@tokens.push(token) if token
	token
      end

      def unget(token)
	@tokens.unshift token
      end

      def identify_identifier
	toks = []
	while s = @src.shift
	  if /[\w]/ =~ s
	    toks.push s
	  else
	    @src.unshift s
	    break
	  end
	end
	reading = toks.join("")
	TkIdentifier.new(reading)
      end
    end

    def self.mkkey(receiver, method_name)
      if receiver.__deep_connect_reference?
	receiver.class.name+"#"+method_name.to_s
      elsif receiver.kind_of?(Class)
	receiver.name+"."+method_name.to_s
      else
	receiver.class.name+"#"+method_name.to_s
      end
    end
  end
end
#
#   cron.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

@RCS_ID='-$Id:  $-'

module DeepConnect

  KEEP_ALIVE_INTERVAL = 10

  class Cron

    TAB = [
      [10, proc{|org, cron, t| cron.mon_10sec}],
      [60, proc{|org, cron, t| cron.mon_min}],
      [3060, proc{|org, cron, t| cron.mon_hour}],
      [KEEP_ALIVE_INTERVAL, proc{|org, cron, t| org.keep_alive}],
    ]

    MON_INTERVAL = 10

    def initialize(organizer)
      @organizer = organizer

      @timer = 0
      @last_exec_times = {}

      @mon_mutex = Mutex.new

      @prev_message10s = nil
    end

    attr_reader :timer
    alias tick timer

    def start
      Thread.start do 
	loop do
	  sleep MON_INTERVAL
	  @timer += MON_INTERVAL
	  
	  Thread.start do
	    @mon_mutex.synchronize do
	      for tab in TAB
		last_time = @last_exec_times[tab]
		last_time = 0 unless last_time
		if @timer >= last_time + tab[0] 
		  @last_exec_times[tab] = @timer
		  tab[1].call @organizer, self, @timer
		end
	      end
	    end
	  end
	end
      end
    end

    def mon_10sec
      return if @organizer.deep_spaces.size == 0

      if DISPLAY_MONITOR_MESSAGE
	str = ""
	str.concat "Connect DeepSpaces: BEGIN\n"
	for peer_id, ds in @organizer.deep_spaces.dup
	  str.concat "#{peer_id.inspect} => \n"
	  str.concat "\t#{ds}\n"
	end
	str.concat "Connect DeepSpaces: END\n"

	if @prev_message10s != str
	  @prev_message10s = str
	  puts "MON 10SEC: #{@timer}\n", str
	end
      end
    end

    def mon_min
      if DISPLAY_MONITOR_MESSAGE
	puts "MON MIN: #{@timer}"
      end
    end

    def mon_hour
      if DISPLAY_MONITOR_MESSAGE
	puts "MON HOUR: #{@timer}"
      end
    end
  end
end



#
#   dist.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "forwardable"

require "deep-connect/organizer"

module DeepConnect
  @RCS_ID='-$Id:  $-'

  # DC is a internal using short cut of DeepConnect .
  DC = DeepConnect

  DISPLAY_MESSAGE_TRACE = false
  MESSAGE_DISPLAY = false
  DEBUG = false
  DISPLAY_METHOD_SPEC = false
  DISPLAY_MONITOR_MESSAGE = false
  DISPLAY_KEEP_ALIVE = false

  DEBUG_REFERENCE = false
  DISPLAY_GC = false

  DISABLE_INFO = true


#  KEEP_ALIVE_INTERVAL = 60

  class DeepConnect
    extend Forwardable

    def self.start(service=0)
      dc = new
      dc.start(service)
      dc
    end

    def initialize
      @organizer = Organizer.new
    end

    def_delegator :@organizer, :start
    def_delegator :@organizer, :stop

    def_delegator :@organizer, :open_deep_space
    def_delegator :@organizer, :open_deepspace
    def_delegator :@organizer, :close_deep_space
    def_delegator :@organizer, :close_deepspace
    def_delegator :@organizer, :when_connected
    def_delegator :@organizer, :when_disconnected

    def_delegator :@organizer, :export
    def_delegator :@organizer, :register_service
    def_delegator :@organizer, :release_object

    def_delegator :@organizer, :local_id
  end

  def DC.start(service = nil)
    DeepConnect.start(service)
  end

  def DC.def_method_spec(*opts)
    Organizer.def_method_spec(*opts)
  end

  def DC.def_single_method_spec(*opts)
    Organizer.def_single_method_spec(*opts)
  end

  def DC.def_interface(*opts)
    Organizer.def_interface(*opts)
  end

  def DC.def_single_interface(*opts)
    Organizer.def_single_interface(*opts)
  end

end

require "deep-connect/serialize"





#
#   deep-space.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "thread"
require "forwardable"

require "ipaddr"

require "deep-connect/session"
require "deep-connect/class-spec-space"

module DeepConnect
  class DeepSpace
    extend Forwardable

    def initialize(org, port, local_id = nil)
      @status = :INITIALIZE

      @organizer = org
      @session = Session.new(self, port, local_id)

      unless local_id
	local_id = port.peeraddr[1]
      end

      addr = port.peeraddr[3]
      ipaddr = IPAddr.new(addr)
      ipaddr = ipaddr.ipv4_mapped if ipaddr.ipv4?
      @peer_uuid = [ipaddr.to_s, local_id]

      init_class_spec_feature
      init_export_feature
      init_import_feature
    end

    attr_reader :status
    attr_reader :organizer
    attr_reader :session
    attr_reader :peer_uuid
    alias peer_id peer_uuid

    def close
      @organizer.close_deepspace(self)
    end

    def connect
      @session.start

      @deregister_reference_thread = start_deregister_reference

      @status = :SERVICING
    end

    def disconnect(*opts)
      org_status = @status
      @status = :SERVICE_STOP
      
      @session.stop_service(*opts)
      if !opts.include?(:SESSION_CLOSED) && !opts.include?(:REQUEST_FROM_PEER)
	@session.send_disconnect
	@session.stop
      end

      @deregister_reference_thread.exit if org_status == :SERVICING
      @import_reference = nil
      @export_roots = nil
    end

    def import(name)
      @session.get_service(name)
    end
    alias get_service import 

    #
    # class spec feature
    #
    def init_class_spec_feature
      # class spec
      @class_spec_space = ClassSpecSpace.new(:remote)
    end

    def_delegator :@class_spec_space, :class_specs=
    def_delegator :@class_spec_space, :method_spec
    def_delegator :@class_spec_space, :class_spec_id_of
    alias csid_of class_spec_id_of
    
    def my_method_spec(obj, method)
      Organizer::method_spec(obj, method)
    end

    def my_csid_of(obj)
      Organizer::class_spec_id_of(obj)
    end

    def recv_class_spec(cspecs)
      cspecs.each{|cspec| add_class_spec(cspec)}
      make_class_spec_cache(cspecs.first)
    end

    def make_class_spec_cache(cspec)
      cache = ClassSpec.new
    end

    #
    # export root 関連メソッド
    #
    def init_export_feature
      # exportしているオブジェクト
      @export_roots_mutex = Mutex.new
      @export_roots = {}
    end

    def release_object(obj)
      @export_roots_mutex.synchronize do
	@export_roots.delete(obj.object_id)
      end
    end

    def set_root(root)
      @export_roots_mutex.synchronize do
	@export_roots[root.object_id] = root
	root.object_id
      end
    end
    alias set_export_root set_root
    
    def root(id)
      @export_roots_mutex.synchronize do
	@export_roots.fetch(id){:__DEEPCONNECT_NO_VALUE__}
      end
    end
    alias export_root root

    def register_root_from_other_session(id)
      obj = @organizer.id2obj(id)
      @export_roots_mutex.synchronize do
	@export_roots[id] = obj
      end
      obj
    end

    def delete_roots(ids)
      puts "GC: delete root: #{ids.join(' ')}" if DISPLAY_GC
      @export_roots_mutex.synchronize do
	for id in ids
	  @export_roots.delete(id)
	end
      end
    end

    #
    # import 関連メソッド
    #
    DISABLE_GC = false

    def init_import_feature
      # importしているオブジェクト

      # peer_id => ref_id
      @import_reference = {}
      @rev_import_reference = {}

      @import_reference_mutex = Mutex.new
      @deregister_reference_queue = Queue.new
    end

    def import_reference(peer_id)
      @import_reference_mutex.synchronize do
	if rid = @import_reference[peer_id]
	  begin
	    ObjectSpace._id2ref(rid)
	  rescue
	    ref_id = @import_reference.delete(peer_id)
	    @rev_import_reference.delete(ref_id)
	    @deregister_reference_queue.push peer_id
	    nil
	  end
	else
	  nil
	end
      end
    end

    def import_reference_for_disable_gc(peer_id)
      @import_reference_mutex.synchronize do
	@import_reference[peer_id]
      end
    end


    def register_import_reference(ref)
      @import_reference_mutex.synchronize do
	@import_reference[ref.peer_id] = ref.object_id
	@rev_import_reference[ref.object_id] = ref.peer_id
      end
      ObjectSpace.define_finalizer(ref, deregister_import_reference_proc)
    end

    def register_import_reference_for_disable_gc(ref)
      @import_reference_mutex.synchronize do
	@import_reference[ref.peer_id] = ref
#	@rev_import_reference[ref.object_id] = ref
      end
    end

    if DISABLE_GC
      alias import_reference import_reference_for_disable_gc
      alias register_import_reference register_import_reference_for_disable_gc
    end

    def deregister_import_reference_id(peer_id)
      @import_reference_mutex.synchronize do
	ref_id = @import_reference.delete(peer_id)
	@rev_import_reference.delete(ref_id)
      end
      @deregister_reference_queue.push peer_id
    end

    def deregister_import_reference_proc
      proc do |ref_id|
	if @status == :SERVICING
	  @import_reference_mutex.synchronize do
	    puts "GC: gced id: #{ref_id}" if DISPLAY_GC
	    peer_id = @rev_import_reference.delete(ref_id)
	    @import_reference.delete(peer_id)
	  end
	  @deregister_reference_queue.push peer_id
	end
      end
    end

    def start_deregister_reference
      Thread.start do
	ids = []
	while ids.push @deregister_reference_queue.pop
	  begin
	    while ids.push @deregister_reference_queue.pop(true); end
	  rescue ThreadError
	    deregister_roots_to_peer(ids) if @status == :SERVICING
	  end
	end
      end
    end

    def register_root_to_peer(id)
      unless import_reference(id)
	@session.register_root_to_peer(id)
      end
    end

    def deregister_roots_to_peer(ids)
      puts "GC: send deregister id: #{ids.join(' ')}" if DISPLAY_GC
      @session.deregister_root_to_peer(ids)
    end
    
  end

  class IllegalObject
    def initialize(id)
      @id = id
    end

    def send(*opts)
      DC.Raise IllegalReference, @id, opts.first
    end
    alias __send__ send
    alias __public_send__ send
  end
end

#
#   evaluator.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#


require "deep-connect/event"
require "deep-connect/exceptions"

module DeepConnect
  class Evaluator
    def initialize(org)
      @organizer = org
    end

    def evaluate_request(session, event)
      begin
	if @organizer.shallow_connect?
	  if !(mspec = Organizer::method_spec(event.receiver, event.method)) or
	      !mspec.interface?
	    DC.Raise NoInterfaceMethod, event.receiver.class, event.method
	  end
	end
	ret = event.receiver.send(event.method, *event.args)
	unless event.kind_of?(Event::NoReply)
	  session.accept event.reply(ret)
	end
#      rescue SygnalException
#	puts "Info: catch"
#	
      rescue SystemExit
	raise
      rescue Exception
	unless event.kind_of?(Event::NoReply)
	  session.accept event.reply(ret, $!)
	end
      end
    end

    def evaluate_iterator_request(session, event)
      begin 
	if @organizer.shallow_connect?
	  if !(mspec = Organizer::method_spec(event.receiver, event.method)) or
	      !mspec.interface?
	    DC.Raise NoInterfaceMethod, event.receiver.class, event.method
	  end
	end
	fin = event.receiver.send(event.method, *event.args){|*args|
	  begin
#  	    if args.size == 1 && args.first.kind_of?(Array)
#  	      args = args.first
#  	    end
	    callback_req = session.block_yield(event, args)

	    case callback_req.result_event
	    when Event::IteratorCallBackReplyBreak
	      break callback_req.result
	    else
	      callback_req.result
	    end
	  rescue
	    # ここ内部エラーじゃないなぁ...
	    if DEBUG
	      puts "INFO: BLOCK YIELD EXCEPTION:"
	      puts  "\t#{$!}"
	      $@.each{|l| puts "\t#{l}"}
	    end
	    raise
	  end
	}
	session.accept event.reply(fin)
      rescue SystemExit
	raise
      rescue Exception
	session.accept event.reply(fin, $!)
      end
    end

    def evaluate_block_yield(session, ev)
      if @organizer.shallow_connect?
	# yield が許されているかチェック
      end
      begin
	args = ev.args

	if ev.block.arity > 1
	  begin
	    if args.size == 1 && args.first.__deep_connect_reference?
	      if args.first.kind_of?(Array)
		args = args.first.dc_dup
	      end
	    end
	  rescue
	    p $!, $!
	    raise
	  end
	end
	ret = ev.block.call(*args)
	session.accept ev.reply(ret)
      rescue LocalJumpError
	exp = $!
	case exp.reason
	when :break
	  session.accept ev.reply(ret, 
				  exp.exit_value, 
				  Event::IteratorCallBackReplyBreak)
	else
	  session.accept ev.reply(ret, exp)
	end
      rescue Exception
	exp = $!
	session.accept e = ev.reply(ret, exp)
      end
    end
  end
end
#!/usr/local/bin/ruby
#
#   event.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "deep-connect/class-spec-space"
require "deep-connect/reference"

module DeepConnect

  class PeerSideException<StandardError
    def initialize(exp)
      super(exp.message)
      @peer_exception = exp
    end

    attr_reader :peer_exception
  end

  module Event
    EV = Event

    def Event.materialize(session, type, *rest)
      type.materialize_sub(session, type, *rest)
    end

    class Event
      def initialize(session, receiver)
	@session = session
	@receiver = receiver
      end
      
      attr_reader :session
      attr :receiver
      attr :seq
      
      public :iterator?

      def inspect
	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq}, receiver=#{@receiver}>"
      end
    end

    module NoReply; end

    class Request < Event
      def Request.request(session, receiver, method, args)
	req = new(session, receiver, method, args)
	req.init_req
	req
      end
      
      def Request.receipt(session, seq, receiver, method, args)
	rec = new(session, receiver, method, args)
	rec.set_seq(seq)
	rec
      end
      
      def Request.materialize_sub(session, type, klass, seq, receiver_id, method, args)
	receiver = session.deep_space.root(receiver_id)

	type.receipt(session, seq,
		     receiver,
		     method,
		     args.collect{|elm| 
		       Reference.materialize(session.deep_space, *elm)})
      end

      def reply(ret, exp = nil, reply_class = reply_class)
	reply_class.reply(self.session, self, ret, exp)
      end

      def reply_class
	Reply
      end
      
      def initialize(session, receiver, method, args)
	super(session, receiver)
	@method = method
	@args = args
      end
      
      def init_req
	@seq = @session.next_request_event_id
	@result = :__DEEPCONNECT__NO_VALUE__
	@result_mutex = Mutex.new
	@result_cv = ConditionVariable.new
      end
      
      def set_seq(seq)
	@seq = seq
      end
      
      def serialize
	mspec = @session.deep_space.method_spec(@receiver, @method)
	if mspec && mspec.args
	  args = mspec.arg_zip(@args){|spec, arg|
	    Reference.serialize_with_spec(@session.deep_space, arg, spec)
	  }
	else
	  args = @args.collect{|elm| 
	    Reference.serialize(@session.deep_space, elm)
	  }
	end
	sel = [self.class, @seq, @receiver.peer_id, @method]
	sel.push args
	sel
      end
      
      def request?
	true
      end

      def result_event
	@result_mutex.synchronize do
	  while @result == :__DEEPCONNECT__NO_VALUE__
	    @result_cv.wait(@result_mutex)
	  end
	end
	@result
      end
      
      def result
	result_event
	if @result.exp
	  bt = @result.exp.backtrace
	  bt.push "-- peer side --"
	  bt.push *caller(0)
	  bt = bt.select{|e| /deep-connect/ !~ e} unless DC::DEBUG
	  
	  raise PeerSideException, @result.exp, bt
	end
	@result.result
      end
      
      def result=(ev)
	@result = ev
	@result_cv.broadcast
      end

      attr :method
      attr :args

      def inspect
	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq}, receiver=#{@receiver}, method=#{@method.id2name}, args=#{@args.collect{|e| e.to_s}.join(', ')}>"
      end
    end

    class RequestWithBlock < Request
      def self.materialize_sub(session, type, klass, seq, receiver_id, method, args, block)

	receiver = receiver(session, receiver_id)

	type.receipt(session, seq,
		     receiver,
		     method,
		     args.collect{|elm| 
		       Reference.materialize(session.deep_space, *elm)},
		     Reference.materialize(session.deep_space, *block))
      end

      def self.request(session, receiver, method, args, block)
	req = new(session, receiver, method, args, block)
	req.init_req
	req
      end
      
      def self.receipt(session, seq, receiver, method, args, block)
	rec = new(session, receiver, method, args, block)
	rec.set_seq(seq)
	rec
      end

      def initialize(session, receiver, method, args, block)
	super(session, receiver, method, args)
	@block = block
      end

      attr_reader :block

      def serialize
	mspec = method_spec(@receiver, @method)
	if mspec && mspec_args(mspec)
	  args = mspec_arg_zip(mspec){|spec, arg|
	    Reference.serialize_with_spec(@session.deep_space, arg, spec)
	  }
	else
	  args = @args.collect{|elm| 
	    Reference.serialize(@session.deep_space, elm)
	  }
	end
	receiver_id = receiver_id(@receiver)
	#	@receiver.peer_id
	sel = [self.class, @seq, receiver_id, @method]
	sel.push args
	sel.push Reference.serialize(@session.deep_space, @block)
	sel
      end
    end

    class IteratorRequest<RequestWithBlock

      def self.receiver(session, receiver_id)
	session.deep_space.root(receiver_id)
      end

      def method_spec(receiver, method)
	@session.deep_space.method_spec(receiver, method)
      end

      def receiver_id(receriver)
	receiver.peer_id
      end

      def mspec_args(mspec)
	mspec.args
      end

      def mspec_arg_zip(mspec, &block)
	mspec.arg_zip(@args, &block)
      end

      def reply_class
	IteratorReply
      end
    end
    
    class IteratorCallBackRequest<RequestWithBlock

      def self.receiver(session, receiver_id)
	Reference.materialize(session.deep_space, *receiver_id)
      end

      def method_spec(receiver, method)
	@session.deep_space.my_method_spec(receiver, method)
      end

      def receiver_id(receriver)
	Reference.serialize(@session.deep_space, @receiver)
      end

      def mspec_args(mspec)
	mspec.block_args
      end

      def mspec_arg_zip(mspec, &block)
	mspec.block_arg_zip(@args, &block)
      end

      def IteratorCallBackRequest.call_back_event(event, args)
	req = new(event.session, event.receiver, event.method, args, event.block)
	req.init_req
	req
      end

      def reply_class
	IteratorCallBackReply
      end
    end
    
    class SessionRequest < Request
      def SessionRequest.request(session, method, args=[])
	req = new(session, session, method, args)
	req.init_req
	req
      end

      def SessionRequest.receipt(session, seq, dummy, method, args=[])
	rec = new(session, session, method, args)
	rec.set_seq(seq)
	rec
      end

      def reply_class
	SessionReply
      end
      
      def serialize
	args = @args.collect{|elm| 
	  Reference.serialize(@session.deep_space, elm)
	}
	sel = [self.class, @seq, @receiver.peer_id, @method]
	sel.push args
	sel
      end

      def inspect
	#	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq}, method=#{@method.id2name}, args=#{@args.collect{|e| e.to_s}.join(', ')}>"
	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq}, method=#{@method.id2name}, args=...>"
      end
    end

    class SessionRequestNoReply<SessionRequest
      include NoReply
    end

    class Reply < Event
      def Reply.materialize_sub(session, type, klass, seq, receiver, method, ret, exp=nil)
	if exp
	  type.new(session, seq, 
		   session.deep_space.root(receiver), 
		   method,
		   Reference.materialize(session.deep_space, *ret),
		   Reference.materialize(session.deep_space, *exp))
	else
	  type.new(session, seq, 
		   session.deep_space.root(receiver), 
		   method,
		   Reference.materialize(session.deep_space, *ret))

	end
      end

      def self.reply(session, req, ret, exp=nil)
	new(session, req.seq, req.receiver, req.method, ret, exp)
      end
      
      def initialize(session, seq, receiver, method, ret, exp=nil)
	super(session, receiver)
	@seq = seq
	@method = method
	@result = ret
	@exp = exp
      end
      
      def serialize
	mspec = @session.deep_space.my_method_spec(@receiver, @method)
	if mspec && mspec.rets
	  if mspec.rets.kind_of?(Array)
	    rets = mspec.rets_zip(@result){|spec, ret|
	      Reference.serialize_with_spec(@session.deep_space, ret, spec)
	    }
	    sel_result = [:VAL, "Array", [Array, rets]]
	  else
	    sel_result = Reference.serialize(@session.deep_space, @result, mspec.rets)
	  end
	else
	  sel_result = Reference.serialize(@session.deep_space, @result)
	end
	
	if @exp
	  [self.class, @seq, 
	    Reference.serialize(@session.deep_space, @receiver),
	    @method,
	    sel_result,
	    Reference.serialize(@session.deep_space, @exp)]
	else
	  [self.class, @seq, 
	    Reference.serialize(@session.deep_space, @receiver),
	    @method,
	    sel_result]
	end
      end

      def request?
	false
      end
      
      attr_reader :result
      attr_reader :exp
      attr_reader :method

      def inspect
	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq}, receiver=#{@receiver}, method=#{@method} result=#{@result} exp=#{@exp}}>"
      end
    end

    class IteratorReply < Reply; end

    class IteratorCallBackReply<Reply
      def serialize
	mspec = @session.deep_space.method_spec(@receiver, @method)
	if mspec && mspec.rets
	  if mspec.rets.kind_of?(Array)
	    rets = mspec.rets_zip(@result){|spec, ret|
	      Reference.serialize_with_spec(@session.deep_space, ret, spec)
	    }
	    sel_result = [:VAL, "Array", [Array, rets]]
	  else
	    sel_result = Reference.serialize(@session.deep_space, @result, mspec.rets)
	  end
	else
	  sel_result = Reference.serialize(@session.deep_space, @result)
	end
	
	if @exp
	  [self.class, @seq, 
	    Reference.serialize(@session.deep_space, @receiver),
	    @method,
	    sel_result,
	    Reference.serialize(@session.deep_space, @exp)]
	else
	  [self.class, @seq, 
	    Reference.serialize(@session.deep_space, @receiver),
	    @method,
	    sel_result]
	end
      end
    end

    class IteratorCallBackReplyBreak<IteratorCallBackReply; end
    class IteratorReplyFinish < Reply; end

    class SessionReply < Reply
      def SessionReply.materialize_sub(session, type, klass, seq, receiver, method, ret, exp = nil)
	#	puts "SESSIONREPLY: #{type}, #{session}, #{ret.collect{|e| e.to_s}.join(',')}"	
	if exp
	  type.new(session, seq,
		   session,
		   method,
		   Reference.materialize(session.deep_space, *ret),
		   Reference.materialize(session.deep_space, *exp))
	else
	  type.new(session, seq,
		   session,
		   method,
		   Reference.materialize(session.deep_space, *ret))
	end
      end

      def inspect
	sprintf "#<#{self.class}, session=#{@session}, seq=#{@seq},  result=#{@result}}>"
      end
    end

    # session 確立時の特殊なイベント
    class InitSessionEvent<Event
      def self.materialize_sub(session, type, klass, local_id)
	new(local_id)
      end

      def initialize(local_id)
	@local_id=local_id
      end

      attr_reader :local_id

      def serialize
	[self.class, @local_id]
      end
    end

    class ConnectResult<Event
      def self.materialize_sub(session, type, klass, result)
	new(result)
      end

      def initialize(result)
	@result = result
      end

      attr_reader :result

      def serialize
	[self.class, @result]
      end
    end
  end
end


require "e2mmap"

module DeepConnect
  extend Exception2MessageMapper

  def_exception :IllegalReference, "不正なリファレンス参照です(id=%x, method=%s)"

  def_exception :NoInterfaceMethod, "No interface method(%s.%s)"

  def_exception :NoServiceError, "No such service(%s)"
  def_exception :CantSerializable, "%sはシリアライズできません"
  def_exception :CantDup, "%sはdupできません"
  def_exception :CantDeepCopy, "%sはdeep copyできません"

  def_exception :SessionServiceStopped, "Session service stopped"
  def_exception :DisconnectClient, "%sの接続が切れました"
  def_exception :ConnectCancel, "%sの接続を拒否しました"
  def_exception :ConnectionRefused, "%sへの接続が拒否されました"

  def_exception :InternalError, "DeepConnect internal error(%s)"
  def_exception :ProtocolError, "Protocol error!!"


  def self.InternalError(message)
    DC.Raise InternalError, message
  end
end

#
#   future.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   v = DeepConnect::future{exp}
#   v = DeepConnect::Future.future{exp}
#   
#

require "thread"
require "delegate"

module DeepConnect
  def future(&block)
    Future.new(&block)
  end
  module_function :future

  class Future < Delegator

    NULLVALUE = :__DEEPCONNECT_FUTURE_NULLVALUE__

    def self.future(&block)
      Futre.new(&block)
    end

    def initialize(&block)
      super(@value = NULLVALUE)
      @value_mutex = Mutex.new
      @value_cv = ConditionVariable.new
      Thread.start do
	@value = yield
	@value_cv.broadcast
      end
    end

    def __setobj__(dummy); end

    def value
      @value_mutex.synchronize do
	while @value == NULLVALUE
	  @value_cv.wait(@value_mutex)
	end
      end
      @value
    end
    alias __getobj__ value

    def value?
      @value != NULLVALUE
    end

    def inspect
      if @value == NULLVALUE
	"#<DeepConnect::Future: (NOT ARRIVED)>"
      else
	"#<DeepConnect::Future: #{@value.inspect}>"
      end
    end
  end
end

  
#
#   organizer.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#
require "forwardable"
require "monitor"

require "deep-connect/class-spec-space"

require "matrix"

module DeepConnect
  class Organizer
    @CLASS_SPEC_SPACE = ClassSpecSpace.new(:local)
    
    extend SingleForwardable

    def_delegator :@CLASS_SPEC_SPACE, :class_specs
    def_delegator :@CLASS_SPEC_SPACE, :def_method_spec
    def_delegator :@CLASS_SPEC_SPACE, :def_single_method_spec
    def_delegator :@CLASS_SPEC_SPACE, :def_interface
    def_delegator :@CLASS_SPEC_SPACE, :def_single_interface
    def_delegator :@CLASS_SPEC_SPACE, :method_spec
    def_delegator :@CLASS_SPEC_SPACE, :class_spec_id_of
  end
end

require "deep-connect/accepter"
require "deep-connect/evaluator"
require "deep-connect/deep-space"
require "deep-connect/port"
require "deep-connect/event"
require "deep-connect/cron"
require "deep-connect/exceptions"


trap("SIGPIPE", "IGNORE")

module DeepConnect

  class Organizer
    def initialize
      @shallow_connect = false

      @accepter = Accepter.new(self)
      @evaluator = Evaluator.new(self)

      @services = {}

      @deep_spaces = {}
      @deep_spaces_mon = Monitor.new
      @deep_spaces_cv = @deep_spaces_mon.new_cond

      @cron = Cron.new(self)

      @when_connect_proc = proc{true}
      @when_disconnect_proc = proc{}

      @local_id_mutex = Mutex.new
      @local_id_cv = ConditionVariable.new
      @local_id = nil
    end

    attr_accessor :shallow_connect
    alias shallow_connect? shallow_connect

    attr_reader :accepter
    attr_reader :evaluator

    def tick
      @cron.tick
    end

    def deep_spaces
      @deep_spaces
    end

    def local_id
      @local_id_mutex.synchronize do
	while !@local_id
	  @local_id_cv.wait(@local_id_mutex)
	end
      end
      @local_id
    end

    def start(service)
      @accepter.open(service)
      @local_id = @accepter.port_number
      @local_id_cv.broadcast

      @accepter.start
      @cron.start
    end

    def stop
      @accepter.stop
    end

    # client sesssion開始
    def open_deep_space(ipaddr, port)
      sock = TCPSocket.new(ipaddr, port)
      port = Port.new(sock)
      init_session_ev = Event::InitSessionEvent.new(local_id)
      port.export init_session_ev
      connect_deep_space_with_port(port)
    end
    alias open_deepspace open_deep_space

    def close_deep_space(deep_space)
      disconnect_deep_space(deep_space)
    end
    alias close_deepspace close_deep_space

    def deep_space(peer_id, &block)
      @deep_spaces_mon.synchronize do
	if deep_space = @deep_spaces[peer_id]
	  return deep_space
	end

	# セッションを自動的に開く
	begin
	  deep_space = open_deep_space(*peer_id)
	  block.call deep_space if block_given?
	  deep_space
	rescue ConnectionRefused
	  puts "WARN: クライアント(#{peer_id}への接続が拒否されました"
	  raise
	end
      end
    end
    alias deepspace deep_space

    # sessionサービス開始
    def connect_deep_space_with_port(port, local_id = nil)
      @deep_spaces_mon.synchronize do
	deep_space = DeepSpace.new(self, port, local_id)
	port.attach(deep_space.session)
#      uuid = session.peer_id unless uuid
	if @deep_spaces[deep_space.peer_uuid]
	# ポート番号が再利用されているときは, 既存の方はすでにおなくな
	# りになっている
	  old = @deep_spaces[deep_space.peer_uuid]
	  puts "INFO: port no recyicled"
	  puts "INFO: disconnect recycled deep_space: #{old}"

	  disconnect_deep_space(old, :SESSION_CLOSED)
	end
	unless @when_connect_proc.call deep_space, port
	  puts "CONNECT Canceld DeepSpace: #{deep_space.peer_uuid}" if $DEBUG
	  connect_ev = Event::ConnectResult.new(false)
	  port.export connect_ev

	  disconnect_deep_space(deep_space)
	  DC::Raise ConnectCancel, deep_space
	end

	connect_ev = Event::ConnectResult.new(true)
	port.export connect_ev

	ev = port.import
	if ev.kind_of?(Event::ConnectResult)
	  unless ev.result
	    DC::Raise ConnectionRefused, deep_space
	  end
	else
	  DC::Raise ProtocolError, deep_space
	end

	@deep_spaces[deep_space.peer_uuid] = deep_space

	puts "CONNECT DeepSpace: #{deep_space.peer_uuid}" if $DEBUG
	deep_space.connect
	deep_space
      end
    end
    alias connect_deepspace_with_port connect_deep_space_with_port

    def disconnect_deep_space(deep_space, *opts)
      @deep_spaces_mon.synchronize do
	@deep_spaces.delete(deep_space.peer_uuid)
      end
      deep_space.disconnect(*opts)
      @when_disconnect_proc.call(deep_space, opts)
    end

    def when_connected(&block)
      @when_connect_proc = block
    end

    def when_disconnected(&block)
      @when_disconnect_proc = block
    end

    #
    def keep_alive
      puts "KEEP ALIVE: Start" if DISPLAY_KEEP_ALIVE
      for uuid, deep_space in @deep_spaces.dup
	unless deep_space.session.keep_alive
	  disconnect_deep_space(deep_space, :SESSION_CLOSED)
	end
      end
    end


    # services
    def register_service(name, obj)
      @services[name] = obj
    end
    alias export register_service

    def service(name)
      unless @services.key?(name)
	return :DEEPCONNECT_NO_SUCH_SERVICE
      end
      @services[name]
    end
    alias import service

    def release_object(obj)
      for id, dspace in @deep_spaces.dup
	dspace.release_object(obj)
      end
    end

    def id2obj(id)
      @deep_spaces_mon.synchronize do
	for peer_id, s in @deep_spaces
#	if o = s.root(id) and !o.kind_of?(IllegalObject)
	  if o = s.root(id) and o != :__DEEPCONNECT_NO_VALUE__
#	  puts "ZZZZZ: #{o}"
	    return o
	  end
	end
# 	begin
# 	  ObjectSpace._id2ref(id)
# 	rescue
# 	end
# 	sleep 5
	IllegalObject.new(id)
      end
#      DC::InternalError "deep_spaceにid(=#{id})をobject_idとするオブジェクトが登録されていません.)"
    end

    @@ABSOLUTE_IMMUTABLE_CLASSES = [
      NilClass,
      TrueClass,
      FalseClass,
      Symbol,
      Fixnum,
    ]

    @@DEFAULT_IMMUTABLE_CLASSES = [
      Numeric,
      String,
      Regexp,
      MatchData,
      Range,
      Time,
      File::Stat,
      Matrix,
      Vector,
      Matrix::Scalar
    ]
    
    @@IMMUTABLE_CLASSES = @@ABSOLUTE_IMMUTABLE_CLASSES + 
      @@DEFAULT_IMMUTABLE_CLASSES

    def self.absolute_immutable_classes
      @@ABSOLUTE_IMMUTABLE_CLASSES
    end
    def self.default_immutable_classes
      @@DEFAULT_IMMUTABLE_CLASSES
    end
    def self.immutable_classes
      @@IMMUTABLE_CLASSES
    end

    def_interface(Exception, :message)

    def_method_spec(Exception, "VAL backtrace()")
    def_interface(Exception, :backtrace)

    def_method_spec(Exception, "REF set_backtrace(VAL)")

    def_method_spec(Object, "VAL to_a()")
    #def_method_spec(Object, "VAL to_s()")
    def_method_spec(Object, "VAL to_ary()")
    def_method_spec(Object, "VAL to_str()")
    def_method_spec(Object, "VAL to_int()")
    def_method_spec(Object, "VAL to_regexp()")
    def_method_spec(Object, "VAL to_splat()")

    def_method_spec(Array, :method=> :-, :args=> "VAL")
    def_method_spec(Array, :method=> :&, :args=> "VAL")
    def_method_spec(Array, :method=> :|, :args=> "VAL")
    def_method_spec(Array, :method=> :<=>, :args=> "VAL")
    def_method_spec(Array, :method=> :==, :args=> "VAL")

    #def_single_method_spec(Regexp, :method=> :union, :args=> "*DVAL")

    def_method_spec(Hash, "merge(VAL)")
    def_method_spec(Hash, :method=> :merge!, :args=> "VAL")
    def_method_spec(Hash, "replace(VAL)")
    def_method_spec(Hash, "update(VAL)")

  end
end
#
#   port.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "deep-connect/event"

module DeepConnect
  class Port

    PACK_n_SIZE = [1].pack("n").size
    PACK_N_SIZE = [1].pack("N").size

    def initialize(sock)
      @io = sock
      @peeraddr = @io.peeraddr
      @session = nil
    end

    def close
      @io.close
    end

    def shutdown_reading
      @io.shutdown(Socket::SHUT_RD)
    end

    def addr
      @io.addr
    end

    def peeraddr
      @peeraddr
    end

    def attach(session)
      @session = session
    end

    def import
#      puts "IMPORT: start0" 
      sz = read(PACK_N_SIZE).unpack("N").first
      bin = read(sz)
      a = Marshal.load(bin)
      begin
	# ここで, ネットワーク通信発生する可能性あり.
	ev = Event.materialize(@session, a.first, *a)
      rescue
	p $!, $@
	raise
      end
      puts "IMPORT: #{ev.inspect}" if DC::MESSAGE_DISPLAY
      ev
    end

    def export(ev)
      puts "EXPORT: #{ev.inspect}" if DC::MESSAGE_DISPLAY
      bin = Marshal.dump(ev.serialize)
      size = bin.size

      packet = [size].pack("N")+bin
      write(packet)
      puts "EXPORT: finsh" if DC::MESSAGE_DISPLAY
    end

    def read(n)
      begin
	packet = @io.read(n)
	fail EOFError, "socket closed" unless packet
#	DC::Raise ProtocolError unless packet.size == n
	packet
      rescue Errno::ECONNRESET
	puts "WARN: read中に[#{peeraddr.join(', ')}]の接続が切れました"
	DC::Raise DisconnectClient, peeraddr
      end
    end
    
    def write(packet)
      begin
	@io.write(packet)
#	@io.flush
      rescue Errno::ECONNRESET
	puts "WARN: write中に[#{peeraddr.join(', ')}]の接続が切れました"
	DC::Raise DisconnectClient, peeraddr
      end
    end
  end
end

#
#   reference.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "deep-connect/class-spec-space"

module DeepConnect
  class Reference

    preserved = [
      :__id__, :object_id, :__send__, :public_send, :respond_to?, :send,
      :instance_eval, :instance_exec, :extend, "!".intern
    ]
    instance_methods.each do |m|
      next if preserved.include?(m.intern)
      alias_method "__deep_connect_org_#{m}", m
      undef_method m
    end

    # session ローカルなプロキシを生成
    #	[クラス名, 値]
    #	[クラス名, ローカルSESSION, 値]
    def Reference.serialize(deep_space, value, spec = nil)
      if spec
	return Reference.serialize_with_spec(deep_space, value, spec)
      end

      if value.__deep_connect_reference?
	if deep_space == value.deep_space
	  [value.__deep_connect_real_class, value.csid, value.peer_id, :PEER_OBJECT]
	else
	  uuid = value.deep_space.peer_uuid.dup
	  if uuid[0] == "::ffff:127.0.0.1"
	    uuid[0] = :SAME_UUIDADDR
	  end
	    
	  [value.__deep_connect_real_class, value.csid, value.peer_id, uuid]
	end
      else
	case value
	when *Organizer::immutable_classes
	  [value.__deep_connect_real_class, value.__deep_connect_real_class.name, value]
	else
	  object_id = deep_space.set_root(value)
	  csid = deep_space.my_csid_of(value)
	  [Reference,  csid, object_id]
	end
      end
    end

    def Reference.serialize_with_spec(deep_space, value, spec)
      if value.__deep_connect_reference?
	if deep_space == value.deep_space
	  [value.__deep_connect_real_class, value.csid, value.peer_id, :PEER_OBJECT]
	else
	  uuid = value.deep_space.peer_uuid.dup
	  if uuid[0] == "::ffff:127.0.0.1"
	    uuid[0] = :SAME_UUIDADDR
	  end
	    
	  [value.__deep_connect_real_class, value.csid, value.peer_id, uuid]
	end
      elsif Organizer::absolute_immutable_classes.include?(value)
	[value.__deep_connect_real_class, value.__deep_connect_real_class.name, value]
      else 
	case spec
	when MethodSpec::DefaultParamSpec
	  Reference.serialize(deep_space, value)
	when MethodSpec::RefParamSpec
	  object_id = deep_space.set_root(value)
	  csid = deep_space.my_csid_of(value)
	  [Reference,  csid, object_id]
	when MethodSpec::ValParamSpec
	  serialize_val(deep_space, value, spec)
	when MethodSpec::DValParamSpec
	  # 第2引数意味なし
	  [value.__deep_connect_real_class, value.__deep_connect_real_class.name, value]
	else
	  raise ArgumentError,
	    "argument is only specified(#{MethodSpec::ARG_SPEC.join(', ')})(#{spec})"
	end
      end
    end

    def Reference.serialize_val(deep_space, value, spec)
      case value
      when *Organizer::immutable_classes
	[value.__deep_connect_real_class, value.__deep_connect_real_class.name, value]
      else 
	[:VAL, value.__deep_connect_real_class.name, 
	  [value.__deep_connect_real_class, value.deep_connect_serialize_val(deep_space)]]
      end
    end
    
    def Reference.materialize(deep_space, type, csid, object_id, uuid=nil)
      if type == Reference
	if uuid
	  if uuid == :PEER_OBJECT
	    deep_space.root(object_id)
	  else
	    if uuid[0] == :SAME_UUIDADDR
	      uuid[0] = deep_space.peer_uuid[0].dup
	    end
	    peer_deep_space = deep_space.organizer.deep_space(uuid)
	    peer_deep_space.register_root_to_peer(object_id)
	    type.new(peer_deep_space, csid, object_id)
	  end
	else
	    type.new(deep_space, csid, object_id)
	end
      else
	if type == :VAL
	  materialize_val(deep_space, type, 
			  csid, object_id[0], object_id[1])
	else
	  # 即値
	  object_id
	end
      end
    end

    def Reference.materialize_val(deep_space, type, csid, klass, value)
      klass.deep_connect_materialize_val(deep_space, value)
    end

#     def Reference.register(deep_space, o)
#       deep_space.peer.set_root(o)
#       Reference.new(session, o.id)
#     end

    def Reference.new(deep_space, csid, peer_id)
      if r = deep_space.import_reference(peer_id)
	return r
      end
      r = super
      deep_space.register_import_reference(r)
      r
    end
    
    def initialize(deep_space, csid, peer_id)
      @deep_space = deep_space
      @csid = csid
      @peer_id = peer_id
    end
    
    attr_reader :deep_space
    attr_reader :csid
    attr_reader :peer_id
     
    def peer
      @deep_space.root(@peer_id)
    end

    def release
      peer_id = @peer_id
#      @peer_id = :__DEEPCONNECT__RELEASED__
      @deep_space.deregister_import_reference_id(peer_id)
    end

#    TO_METHODS = [:to_ary, :to_str, :to_int, :to_regexp]
#    TO_METHODS = [:to_ary, :to_str, :to_int, :to_regexp, :to_splat]
    
    def method_missing(method, *args, &block)
      puts "SEND MESSAGE: #{self.inspect} #{method.id2name}" if DISPLAY_MESSAGE_TRACE


#       if TO_METHODS.include?(method)
# 	return self.dc_dup.send(method)
#       end
      if iterator?
	@deep_space.session.send_to(self, method, args, &block)
      else
	@deep_space.session.send_to(self, method, args)
      end
    end
    
#     def peer_to_s
#       @deep_space.session.send_to(self, :to_s)
#     end

#     def peer_inspect
#       @deep_space.session.send_to(self, :inspect)
#     end

#     def peer_class
#       @deep_space.session.send_to(self, :class)
#     end

#     def to_s
#       @deep_space.session.send_to(self, :to_s)
#     end
    
#     def to_a
#       a = []
#       @deep_space.session.send_to(self, :to_a).each{|e| a.push e}
#       a
#     end

#     def =~(other)
#       @deep_space.session.send_to(self, :=~, other)
#     end

#     def ===(other)
#       @deep_space.session.send_to(self, :===, other)
#     end

#     def id
#       @deep_space.session.send_to(self, :id)
#     end
    
#     def coerce(other)
#       return  other, peer
#     end

    def __deep_connect_reference?
      true
    end
    alias dc_reference? __deep_connect_reference?

    def __deep_connect_real_class
      Reference
    end
    
    class UndefinedClass;end

    def peer_class
      return @peer_class if @peer_class
      begin
	@peer_class = self.class.dc_deep_copy
      rescue
	@peer_class = UndefinedClass
      end
      @peer_class
    end


    def respond_to?(m, include_private = false)
      return true if super
      return @deep_space.session.send_to(self, :respond_to?, [m, include_private])
    end

    # ここは, オブジェクトの同値性を用いていない
    def ==(obj)
      obj.__deep_connect_reference? &&
	@deep_space == obj.deep_space && 
	@peer_id == obj.peer_id
    end

    def equal?(obj)
      self.object_id == obj.object_id
    end

    def hash
      @deep_space.object_id ^ @peer_id
    end

    def kind_of?(klass)
      if klass.__deep_connect_reference?
	@deep_space.session.send_to(self, :kind_of?, klass)
      else
	self.peer_class <= klass
      end
    end

    def nil?
      false
    end

#     def ===(other)
#       if other.__deep_connect_reference?
# 	@deep_space.session.send_to(self, :===, other)
#       else
# 	case other
# 	when Class
# 	  self.peer_class <= klass
# 	end
#       end
#     end

#     def marshal_dump
#       Reference.serialize(@deep_space, self)
#     end
    
#     def marshal_load(obj)
#       Reference.materialize(
#     end

#     def marshal_load(obj)
#       Reference.materialize(
#     end

#     def to_ary
#       if respond_to?(:to_ary)
# 	self.dc_dup.to_ary
#       end
#     end

#     def to_str
#       if respond_to?(:to_str)
# 	self.dc_dup.to_str
#       end
#     end

#     def to_a
#       self.dc_dup.to_a
#     end

    def to_s(force = false)
      if !force && /deep-connect/ =~ caller(1).first
	unless /deep-connect\/test/ =~ caller(1).first
	  return __deep_connect_org_to_s
	end
      end

      if @deep_space.status == :SERVICING
	@deep_space.session.send_to(self, :to_s)
      else
	"(no service)"
      end
    end

    def inspect(force = false)
      if !force && /deep-connect/ =~ caller(1).first
	unless /deep-connect\/test/ =~ caller(1).first
	  return sprintf("<DC::Ref: deep_space=%s csid=%s id=%x>", 
		@deep_space.to_s, 
		@csid, 
		@peer_id)
	end
      end

      if DC::DEBUG_REFERENCE
	sprintf("<DC::Ref[deep_space=%s csid=%s id=%x]: %s>", 
		@deep_space.to_s, 
		@csid, 
		@peer_id,
		to_s) 
      else
	sprintf("<DC::Ref: %s>", to_s(true)) 
      end
    end

    def peer_inspect
      @deep_space.session.send_to(self, :inspect)
    end

    def my_inspect
      __deep_connect_org_inspect
    end

    def deep_connect_dup
      @deep_space.session.send_to(self, :deep_connect_dup)
    end
    alias dc_dup deep_connect_dup

    def deep_connect_deep_copy
      @deep_space.session.send_to(self, :deep_connect_deep_copy)
    end
    alias dc_deep_copy deep_connect_deep_copy

  end

end

class Object
  def __deep_connect_reference?
    false
  end
  alias dc_reference? __deep_connect_reference?

  def __deep_connect_real_class
    self.class
  end
end

class Module
  def ===(other)
    other.kind_of?(self)
  end
end

		  

  
#
#   serialize.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "deep-connect/reference"

module DeepConnect
  UNSERIALIZABLE_CLASSES = [
    Binding,
    UnboundMethod,
    Method,
    Proc,
    Dir,
    File,
    IO,
    ThreadGroup,
    Thread,
    Data,
#    Class,
#    Module,
  ]
  if defined?(Continuation)
    UNSERIALIZABLE_CLASSES.push Continuation
  end
  if defined?(StopIteration)
    UNSERIALIZABLE_CLASSES.push StopIteration
  end
  if defined?(Enumerable::Enumerator)
    UNSERIALIZABLE_CLASSES.push Enumerable::Enumerator
  end

  UNSERIALIZABLE_CLASS_SET = {}
  UNSERIALIZABLE_CLASSES.each do|k|
    UNSERIALIZABLE_CLASS_SET[k] = k
  end
end

class Object 
  def self.deep_connect_materialize_val(deep_space, value)
    obj = allocate
    value.each do |v, o|
      obj.instance_variable_set(v, DeepConnect::Reference.materialize(deep_space, *o))
    end
    obj
  end

  def deep_connect_serialize_val(deep_space)
    if DeepConnect::UNSERIALIZABLE_CLASS_SET.include?(self.class)
      DeepConnect.Raise CantSerializable, self.class.name
    end
    vnames = instance_variables
    vnames.collect{|v| 
      [v, 
	DeepConnect::Reference.serialize(deep_space, instance_variable_get(v))]}
  end

  def deep_connect_dup
    if DeepConnect::UNSERIALIZABLE_CLASS_SET.include?(self.class)
      DeepConnect.Raise CantDup, self.class.name
    end
    self
  end
  alias dc_dup deep_connect_dup
  DeepConnect.def_method_spec(self, :rets=>"VAL", :method=>:deep_connect_dup)
  DeepConnect.def_method_spec(self, :rets=>"VAL", :method=>:dc_dup)

  def deep_connect_deep_copy
    if DeepConnect::UNSERIALIZABLE_CLASS_SET.include?(self.class)
      DeepConnect.Raise CantDeepCopy, self.class.name
    end
    self
  end
  alias dc_deep_copy deep_connect_deep_copy
  DeepConnect.def_method_spec(self, :rets=>"DVAL", :method=>:deep_connect_deep_copy)
  DeepConnect.def_method_spec(self, :rets=>"DVAL", :method=>:dc_deep_copy)
end

class Array
  def self.deep_connect_materialize_val(deep_space, value)
    ary = new
    value.each{|e| ary.push DeepConnect::Reference.materialize(deep_space, *e)}
    ary
  end

  def deep_connect_serialize_val(deep_space)
    collect{|e| DeepConnect::Reference.serialize(deep_space, e)}
  end

end

class Hash
  def self.deep_connect_materialize_val(deep_space, value)
    hash = new
    value.each do |k, v| 
      key = DeepConnect::Reference.materialize(deep_space, *k)
      value = DeepConnect::Reference.materialize(deep_space, *v)
      hash[key] = value
    end
    hash
  end

  def deep_connect_serialize_val(deep_space)
    collect{|k, v| 
      [DeepConnect::Reference.serialize(deep_space, k), 
	DeepConnect::Reference.serialize(deep_space, v)]}
  end

end

class Struct
  def self.deep_connect_materialize_val(deep_space, value)
    new(*value.collect{|e| DeepConnect::Reference.materialize(deep_space, *e)})
  end

  def deep_connect_serialize_val(deep_space)
    to_a.collect{|e| DeepConnect::Reference.serialize(deep_space, e)}
  end
end


#
#   session.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA(Penta Advanced Labrabries, Co.,Ltd)
#
# --
#
#   
#

require "thread"
#require "mutex_m"
require "weakref"

require "ipaddr"

require "deep-connect/exceptions"

module DeepConnect
  class Session

    def initialize(deep_space, port, local_id = nil)
      @status = :INITIALIZE

      @organizer = deep_space.organizer
      @deep_space = deep_space
      @port = port

      @export_queue = Queue.new

      @waiting = Hash.new
      @waiting_mutex = Mutex.new

      @next_request_event_id = 0
      @next_request_event_id_mutex = Mutex.new

      @last_keep_alive = nil
    end

    attr_reader :organizer
    attr_reader :deep_space

    def peer_uuid
      @deep_space.peer_uuid
    end
    alias peer_id peer_uuid

    def start
      @last_keep_alive = @organizer.tick

      @status = :SERVICING
      send_class_specs

      @import_thread = Thread.start {
	loop do
	  begin
	    ev = @port.import
	    @last_keep_alive = @organizer.tick
	  rescue EOFError, DC::DisconnectClient
	    # EOFError: クライアントが閉じていた場合
	    # DisconnectClient: 通信中にクライアント接続が切れた
	    Thread.start do
	      @organizer.disconnect_deep_space(@deep_space, :SESSION_CLOSED)
	    end
	    Thread.stop
	  rescue DC::ProtocolError
	    # 何らかの障害のためにプロトコルが正常じゃなくなった
	  end
	  if @status == :SERVICING
	    receive(ev)
	  else
	    puts "INFO: service is stoped, imported event abandoned(#{ev.inspect})" 
	  end
	end
      }

      @export_thread = Thread.start {
	loop do
	  ev = @export_queue.pop
	  if @status == :SERVICING
	    begin
	      # export中にexportが発生するとデッドロックになる
	      # threadが欲しいか?
#	      Thread.start do
		@port.export(ev)
#	      end
	    rescue Errno::EPIPE, DC::DisconnectClient
	      # EPIPE: クライアントが終了している
	      # DisconnectClient: 通信中にクライアント接続が切れた
	      Thread.start do
		@organizer.disconnect_deep_space(@deep_space, :SESSION_CLOSED)
	      end
	      Thread.stop
	    end
	  else
	    puts "INFO: service is stoped, export event abandoned(#{ev.inspect})" 
	  end
	end
      }
      self
    end

    def stop_service(*opts)
      unless DISABLE_INFO
	puts "INFO: STOP_SERVICE: Session: #{self.peer_uuid} #{opts.join(' ')} "
      end
      org_status = @status
      @status = :SERVICE_STOP
      
      if !opts.include?(:SESSION_CLOSED)
	@port.shutdown_reading
      end

      if org_status == :SERVICING
	@import_thread.exit
	@export_thread.exit
      
	@waiting_mutex.synchronize do
	  waiting_events = @waiting.sort{|s1, s2| s1[0] <=> s2[0]}
	  for seq, ev in waiting_events
	    begin
	      p ev
	      DC.Raise SessionServiceStopped
	    rescue
	      ev.result = ev.reply(nil, $!)
	    end
	  end
	  @waiting.clear
	end
      end

    end

    def stop(*opts)
      @port.close
    end

    # peerからの受取り
    def receive(ev)
      #Thread.start do
      if ev.request?
	Thread.start do
	  case ev
 	  when Event::IteratorCallBackRequest
	    @organizer.evaluator.evaluate_block_yield(self, ev)
 	  when Event::IteratorRequest
 	    @organizer.evaluator.evaluate_iterator_request(self, ev)
	  else
	    @organizer.evaluator.evaluate_request(self, ev)
	  end
	end
      else
	req = nil
	@waiting_mutex.synchronize do
	  req = @waiting.delete(ev.seq)
	end
	unless req
	  DC.InternalError "対応する request eventがありません(#{ev.inspect})"
	end
	req.result = ev
      end
      #end
    end

    # イベントの受け取り
    def accept(ev)
      @export_queue.push ev
    end

    # イベントの生成/送信
    def send_to(ref, method, args=[], &block)
      unless @status == :SERVICING
	DC.Raise SessionServiceStopped
      end
      if iterator?
	ev = Event::IteratorRequest.request(self, ref, method, args, block)
      else
	ev = Event::Request.request(self, ref, method, args)
      end
      @waiting_mutex.synchronize do
	@waiting[ev.seq] = ev
      end
      @export_queue.push ev
      ev.result
    end

    def block_yield(event, args)
      ev = Event::IteratorCallBackRequest.call_back_event(event, args)
      @waiting_mutex.synchronize do
	@waiting[ev.seq] = ev
      end
      @export_queue.push ev
      ev
    end

    # イベントID取得
    def next_request_event_id
      @next_request_event_id_mutex.synchronize do
	@next_request_event_id += 1
      end
    end

    def send_peer_session(req, *args)
      ev = Event::SessionRequest.request(self, (req.id2name+"_impl").intern, args)
      @waiting_mutex.synchronize do
	@waiting[ev.seq] = ev
      end
      @export_queue.push ev
      ev.result
    end

    def send_peer_session_no_recv(req, *args)
      ev = Event::SessionRequestNoReply.request(self, (req.id2name+"_impl").intern, args)
      @export_queue.push ev
    end

    def send_disconnect
      return unless  @status == :SERVICING

      ev = Event::SessionRequestNoReply.request(self, :recv_disconnect)
      @port.export(ev)
    end

    def recv_disconnect
      @organizer.disconnect_deep_space(@deep_space, :REQUEST_FROM_PEER)
    end
    Organizer.def_interface(self, :recv_disconnect)


    def get_service(name)
      if (sv = send_peer_session(:get_service, name)) == :DEEPCONNECT_NO_SUCH_SERVICE
	DC.Raise NoServiceError, name
      end
      sv
    end

    def get_service_impl(name)
      @organizer.service(name)
    end
    Organizer.def_interface(self, :get_service_impl)

    def register_root_to_peer(id)
      # 同期を取るためにno_recvはNG
      send_peer_session(:register_root, id)
    end

    def register_root_impl(id)
      @deep_space.register_root_from_other_session(id)
    end
    Organizer.def_interface(self, :register_root_impl)

    def deregister_root_to_peer(ids)
      idsdump = Marshal.dump(ids)
      send_peer_session_no_recv(:deregister_root, idsdump)
    end

    def deregister_root_impl(idsdump)
      ids = Marshal.load(idsdump)
      @deep_space.delete_roots(ids)
      nil
    end
    Organizer.def_interface(self, :deregister_root_impl)

    def send_class_specs
      specs_dump = Marshal.dump(Organizer::class_specs)
      send_peer_session_no_recv(:recv_class_specs, specs_dump)
    end

    def recv_class_specs_impl(specs_dump)
      specs = Marshal.load(specs_dump)
      @deep_space.class_specs = specs
#p specs
    end
    Organizer.def_interface(self, :recv_class_specs_impl)


#     def send_class_specs(cspecs)
#       specs_dump = Marshal.dump(cspecs)
#       ret = send_peer_session(:send_class_specs_impl, cspecs)
#     end

#     def send_class_specs_impl(spec_dump)
#       specs = Marshal.load(spec_dump)
#       @object_space.recv_class_specs(specs)
#     end

    def keep_alive
      now = @organizer.tick
      if now > @last_keep_alive + KEEP_ALIVE_INTERVAL*2
	puts "KEEP ALIVE: session #{self} is dead." if DISPLAY_KEEP_ALIVE
	false
      else
	puts "KEEP ALIVE: send #{self} to keep alive." if DISPLAY_KEEP_ALIVE
	send_peer_session_no_recv(:recv_keep_alive)
	true
      end
    end

    def recv_keep_alive_impl
      puts "RECV_KEEP_ALIVE"  if DISPLAY_KEEP_ALIVE
      @last_keep_alive = @organizer.tick
    end
    Organizer.def_interface(self, :recv_keep_alive_impl)
  end
end


job_dir = File.dirname(__FILE__)
for job in Dir.glob("#{job_dir}/*.rb")
  next if job == __FILE__

#  puts "require #{job}"

  require job
end

require "job/filter"

require "share/block-source"

module Fairy
    module Interface
      def barrier(opts = nil)
	if opts[:cond].kind_of?(String)
	  opts[:cond] = BlockSource.new(opts[:cond])
	end
	barrier = Barrier.new(@fairy, opts)
	barrier.input = self
	barrier
      end
    end
    Fairy::def_job_interface Interface


  class Barrier<Filter
    def backend_class_name
      "BBarrier"
    end
  end
end

require "job/filter"
require "share/block-source"

module Fairy

  class EachElementMapper<Filter
    module Interface
      def map(block_source, opts = nil)
	raise "ブロックは受け付けられません" if block_given?
	block_source = BlockSource.new(block_source) 
	mapper = EachElementMapper.new(@fairy, opts, block_source)
	mapper.input=self
	mapper
      end
      alias collect map
     
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BEachElementMapper"
    end
  end
end

require "job/filter"

module Fairy

  class EachElementSelector<Filter
    module Interface
      def select(block_source, opts = nil)
	raise "ブロックは受け付けられません" if block_given?
	block_source = BlockSource.new(block_source) 
	mapper = EachElementSelector.new(@fairy, opts, block_source)
	mapper.input=self
	mapper
      end

      alias find_all select

      def grep(regexp, opts = nil)
	select(%{|e| /#{regexp.source}/ === e}, opts)
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BEachElementSelector"
    end
  end

end

require "job/filter"

module Fairy

  class EachSubStreamMapper<Filter
    module Interface
      def smap(block_source, opts = nil)
	raise "ブロックは受け付けられません" if block_given?
	block_source = BlockSource.new(block_source) 
	mapper = EachSubStreamMapper.new(@fairy, opts, block_source)
	mapper.input=self
	mapper
      end

      # emap(%{|enum| enum.collect{..})
      def emap(block_source, opts = nil)
	raise "ブロックは受け付けられません" if block_given?
	map_source = %{|i, o| proc{#{block_source}}.call(i).each{|e| o.push e}}
	smap(map_source, opts)
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BEachSubStreamMapper"
    end
  end
end

require "job/job"
require "share/vfile"

module Fairy
  class FFileOutput < Job

    @backend_class = nil

    def FFileOutput.output(fairy, opts, vfn)
      ffile = new(fairy, opts)
      ffile.output(vfn)
      ffile
    end

    def initialize(fairy, opts=nil)
      super

      @vfile = nil
    end

    def backend_class_name
      "BFileOutput"
    end

    def output(vfn)
      @descripter = vfn
      @vfile = VFile.new
      @vfile.vfile_name = vfn
      backend.output(@vfile)

#      vf.create_vfile(vfn)
    end

    def input=(job)
      @input = job
      backend.input=job.backend

      backend.wait_all_output_finished
      @vfile.create_vfile
    end
  end

end

require "job/job"
require "share/vfile"

module Fairy
  class FFile < Job

    @backend_class = nil

    def FFile.open(fairy, opts, ffile_descripter)
      ffile = new(fairy, opts)
      ffile.open(ffile_descripter)
      ffile
    end

    def FFile.input(fairy, opts, ffile_descripter)
      FFile.open(fairy, opts, ffile_descripter)
    end

    def initialize(fairy, opts=nil)
      super
    end

    def backend_class_name
      "BFile"
    end

    def open(ffile_descripter)
      @descripter = ffile_descripter
      case ffile_descripter
      when Array
	vf = VFile.real_files(ffile_descripter)
      when VFile
	vf = ffile_descripter
      when String
	if VFile.vfile?(ffile_descripter)
	  vf = VFile.vfile(ffile_descripter)
	else
	  vf = VFile.real_files([ffile_descripter])
	end
      else
	raise "指定が間違っています"
      end
      backend.open(vf)
      self
    end

  end

#  class BFile;end
end

require "job/job"

module Fairy
  class Filter < Job

    def initialize(fairy, *rests)
      super
    end

    def backend_class_name
      raise "backend_classの名前を定義してください"
    end

    def input=(job)
      @input=job
#      atom = Atom.new(backend, :input=, job.backend)
#      @fairy.send_atom(atom)
      backend.input=job.backend
    end
  end
end

require "job/filter"

module Fairy
  class Find<Filter

    module Interface
      # filter.find(%{...})
      def find(block_source, opts = nil)
	block_source = BlockSource.new(block_source) 
	find = Find.new(@fairy, opts, block_source)
	find.input = self
	find
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BFind"
    end

    def value
      backend.value
    end
  end
end

require "job/filter"

module Fairy
  class GroupBy<Filter

    module Interface
      def group_by(hash_block, opts = nil)
	hash_block = BlockSource.new(hash_block) 
	group_by = GroupBy.new(@fairy, opts, hash_block)
	group_by.input = self
	group_by
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BGroupBy"
    end
  end

  class MGroupBy<Filter

    module Interface
      def mgroup_by(hash_block, opts = nil)
	hash_block = BlockSource.new(hash_block) 
	mgroup_by = MGroupBy.new(@fairy, opts, hash_block)
	mgroup_by.input = self
	mgroup_by
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BMGroupBy"
    end
  end
end
require "job/filter"

module Fairy
  class Here<Filter
    include Enumerable

    module Interface
      def here(opts = nil)
	here = Here.new(@fairy, opts)
	here.input= self
	here
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts = nil)
      super
    end

    def backend_class_name
      "BHere"
    end

    def each(&block)
      backend.each{|e| block.call e}
    end

    def to_a
      ary = []
      backend.each{|e| ary.push e}
      ary
    end

  end

#  class BHere;end
end

require "job/filter"

module Fairy
  class Inject<Filter

    module Interface
      # filter.inject(%{...}, :init_value = val)
      def inject(block_source, opts = nil)
	block_source = BlockSource.new(block_source) 
	inject = Inject.new(@fairy, opts, block_source)
	inject.input = self
	#DeepConnect::future{inject.value}
	inject
      end

      def min(block_source=nil, opts = nil)
	unless block_source
	  block_source = %{|e1, e2| e1 <=> e2}
	end
	
	inject(%{|r, v| (proc{#{block_source}}.call(r, v) < 0) ? r : v})
      end

      def min_by(block_source, opts = nil)
	pair = map(%{|v| [proc{#{block_source}}.call(v), v]})
	min_by = pair.inject(%{|r, v| ((r[0] <=> v[0]) < 0) ? r : v})
	def min_by.value
	  super[1]
	end
	min_by
      end

      def max(block_source=nil, opts = nil)
	unless block_source
	  block_source = %{|e1, e2| e1 <=> e2}
	end
	
	inject(%{|r, v| (proc{#{block_source}}.call(r, v) < 0) ? v : r})
      end

      def max_by(block_source, opts = nil)
	pair = map(%{|v| [proc{#{block_source}}.call(v), v]})
	max_by = pair.inject(%{|r, v| ((r[0] <=> v[0]) < 0) ? v : r})
	def max_by.value
	  super[1]
	end
	max_by
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
    end

    def backend_class_name
      "BInject"
    end

    def value
      backend.value
    end
  end
end
module Fairy

  DEFAULT_SPLIT_NO = 4

  class Iota < Job
    module Interface

      # Usage:
      # fairy.iota(no)....
      #
      def iota(times, opts={})
	Iota.input(self, opts, times)
      end
      alias times iota
      
    end
    Fairy::def_fairy_interface Interface

    def self.input(fairy, opts, n)
      unless opts[:SPLIT_NO]
	opts[:SPLIT_NO] = DEFAULT_SPLIT_NO
      end
      iota = new(fairy, opts, n)
      iota.start
      iota
    end
    
    
    def backend_class_name
      "BIota"
    end

    def start
      backend.start
    end
  end
end


    
      
      
module Fairy

  class InputVArray < Job

    def self.input(fairy, opts, varray)
      input_va = new(fairy, opts, varray)
      input_va.start
      input_va
    end
    
    
    def backend_class_name
      "BInputVArray"
    end

    def start
      backend.start
    end
  end
end


    
      
      

require "share/varray"

module Fairy
  module InputInterface
    def input(desc, *opts)
      if opts.last.kind_of?(Hash)
	opts_h = opts.pop
      else
	opts_h = {}
      end

      case desc
#      when Enumerable
#	There.input(self, opts_h, desc, *opts)
      when VArray
	  InputVArray.input(self, opts_h, desc)
      when DeepConnect::Reference
	if desc.peer_class.name == "Fairy::VArray"
	  InputVArray.input(self, opts_h, desc)
	else
	  raise "まだサポートしていません(#{desc}, #{desc.peer_class})"
	end
      when Class
	desc.input(self, opts_h, *opts)
      else
	if !desc.kind_of?(String) || VFile.vfile?(desc)
	  FFile.input(self, opts_h, desc)
	else
	  LFileInput.input(self, opts_h, desc)
	end
      end
    end
  end
  def_fairy_interface InputInterface
end




module Fairy

  def self.def_job_interface(mod)
    Job.instance_eval{include mod}
  end

  def Fairy.def_job_interface(mod)
    Job.instance_eval{include mod}
  end

  class Job
    def initialize(fairy, opts, *rests)
      @fairy = fairy
      @opts = opts
      @opts = {} unless @opts
      if @opts[:BEGIN]
	@opts[:BEGIN] = BlockSource.new(@opts[:BEGIN])
      end
      if @opts[:END]
	@opts[:END] = BlockSource.new(@opts[:END])
      end
      @ref = backend_class.new(fairy.controller, opts, *rests)
    end

    def backend_class
      unless klass = @fairy.name2backend_class(backend_class_name)
	raise "バックエンドクラス#{backend_class_name}が分かりません"
      end
      klass
    end

    def backend
      @ref
    end

    def backend=(v)
      @ref=v
    end

    def def_pool_variable(vname, value = nil)
      backend.def_pool_variable(vname, value)
    end

  end
end

require "job/job"
require "share/vfile"

module Fairy
  class LFileInput < Job

    def self.input(fairy, opts, filename)
      self.start(fairy, opts, filename)
    end

    def self.start(fairy, opts, filename)
      lfile = new(fairy, opts)
      lfile.start(filename)
      lfile
    end

    def initialize(fairy, opts=nil)
      super
      @io = nil
    end

    attr_reader :io

    def backend_class_name
      "BLFileInput"
    end

    def start(filename)
      @filename = filename
      backend.start(self)
    end

    def open
      if block_given?
	io = File.open(@filename)
	begin
	  yield io
	ensure
	  io.close
	end
      else
	File.open(@filename)
      end
    end

    def split_opens(split_size, &block)
      begin
	seek = 0
	size = File.stat(@filename).size
	while seek < size
	  io = SplittedFile.open(@filename, seek, seek += split_size)
	  yield io
	end
      rescue
	Log::warn_exception(self)
	raise
      end
    end

    class SplittedFile
      def self.open(fd, seek_start, seek_end, &block)
	sf = new(fd, seek_start, seek_end)
	if block_given?
	  begin
	    yield sf
	  ensure
	    sf.close
	  end
	else
	  sf
	end
      end

      def initialize(fd, seek_start, seek_end)

	@io = File.open(fd)
	@seek_start = seek_start
	@seek_end = seek_end

	if seek_start > 0
	  @io.seek(seek_start-1)
	  if /^$/ !~ @io.read(1)
	    # 一行空読みする
	    @io.gets
	  end
	end
	@io
      end

      def close
	@io.close
	@io = nil
      end

      def each(&block)
	begin
	  while @io.pos < @seek_end && l = @io.gets
	    yield l
	  end
	rescue
	  Log::warn_exception(self)
	  raise
	end
      end
    end
  end
end

require "job/job"
require "share/vfile"

module Fairy
  class LFileOutput < Job

    @backend_class = nil

    def LFileOutput.output(fairy, opts, filename)
      ffile = new(fairy, opts)
      ffile.output(filename)
      ffile
    end

    def initialize(fairy, opts=nil)
      super
      @opts = opts
      
      @filename = nil      
    end

    def backend_class_name
      "BLFileOutput"
    end

    def output(filename)
      @filename = filename
      backend.output(self)

    end

    def input=(job)
      @input = job
      backend.input=job.backend
      
      File.open(@filename, "w") do |io|
	for l in backend
	  io.puts l
	end
      end
    end
  end
end

require "job/job"
require "share/varray"

module Fairy
  class OutputVArray<Job
    module Interface
      # Usage:
      # ... .to_va
      #
      def to_va
	output_va = OutputVArray.output(@fairy, opts=nil)
	output_va.input = self
	output_va.varray
      end
    end
    Fairy::def_job_interface Interface
    
    def self.output(fairy, opts)
      output = new(fairy, opts)
      output
    end

    def initialize(fairy, opts=nil)
      super

      @varray = backend.varray
    end

    attr_reader :varray

    def backend_class_name
      "BOutputVArray"
    end

    def output
      backend.output
    end

    def input=(job)
      @input = job
      backend.input=job.backend
#      backend.wait_all_output_finished
    end
  end
end
module Fairy
  
  module OutputInterface
    def output(vfn, opts = nil)
      if vfn.kind_of?(Class)
	outputter = vfn.output(@fairy, opts)
      elsif !vfn.kind_of?(String) || VFile.vfile?(vfn)
	outputter = FFileOutput.output(@fairy, opts, vfn)
      else
	outputter = LFileOutput.output(@fairy, opts, vfn)
      end
      outputter.input = self
      outputter

    end
  end
  def_job_interface OutputInterface

end

require "job/ffile-output"
require "job/local-file-output"



require "job/filter"

module Fairy
  class Shuffle<Filter
    module Interface
      def shuffle(block_source, opts = nil)
	block_source = BlockSource.new(block_source) 
	shuffle = Shuffle.new(@fairy, opts, block_source)
	shuffle.input = self
	shuffle
      end
      alias sshuffle shuffle

      def eshuffle(block_source, opts = nil)
	map_source = %{|i, o| proc{#{block_source}}.call(i).each{|e| o.push e}}
	shuffle(map_source, opts)
      end
    end
    Fairy::def_job_interface Interface

    def initialize(fairy, opts, block_source)
      super
      @block_source = block_source
      @opts = opts
    end

    def backend_class_name
      "BShuffle"
    end
  end
end

require "job/filter"

module Fairy
  class Splitter<Filter
    module Interface
      def split(n, opts=nil)
	splitter = Splitter.new(@fairy, opts, n)
	splitter.input = self
	splitter
      end
    end
    Fairy::def_job_interface Interface


    def initialize(fairy, opts, n)
      super
      @no_split = n
      @opts = opts
    end

    def backend_class_name
      "BSplitter"
    end
  end
end

module Fairy
  class There < Job
    module Interface

      # Usage:
      # ○ fairy.there(enumeratable)....
      # ○ enumerable.there(fairy)....
      #    enumerable | fairy.there
      def there(enumerable = nil, opts={})
	There.input(self, opts, enumerable)
      end
    end
    Fairy::def_fairy_interface Interface

    Enumerable.module_eval %{def there(fairy); fairy.there(self); end}

    def self.input(fairy, opts, enumerable)
      self.start(fairy, opts, enumerable)
    end

    def self.start(fairy, opts, enumerable)
      there = new(fairy, opts, enumerable)
      there.start
      there
    end

    def initialize(fairy, opts, enumerable)
      super
      @enumerable = enumerable
    end

    def backend_class_name
      "BThere"
    end

    def start
      backend.start
    end
  end
end

require "job/filter"

module Fairy
  class Zipper<Filter

    module Interface
      # jpb.zip(opts,...,filter,...,block_source, opts,...)
      def zip(*others)
	block_source = nil
	if others.last.kind_of?(String)
	  block_source = others.pop
	end
	others, opts = others.partition{|e| e.kind_of?(Job)}
	if opts.last.kind_of?(Hash)
	  h = opts.pop
	else
	  h = {}
	end
	opts.each{|e| h[e] = true}

	block_source = BlockSource.new(block_source) 
	zip = Zipper.new(@fairy, h, others, block_source)
	zip.input = self
	zip
      end
    end
    Fairy::def_job_interface Interface

    ZIP_BY_SUBSTREAM = :ZIP_BY_SUBSTREAM

    def initialize(fairy, opts, others, block_source)
      super(fairy, opts, others.collect{|o| o.backend}, block_source)
      @others = others
      @block_source
      @opts = opts
    end

    def backend_class_name
      "BZipper"
    end
  end
end


njob_dir = File.dirname(__FILE__)
for njob in Dir.glob("#{njob_dir}/*.rb")
  next if njob == __FILE__

#  puts "require #{job}"

  require njob
end

require "node/njob"
require "node/n-single-exportable"

module Fairy
  class NBarrierMemoryBuffer<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts=nil)
      @export = Export.new(Queue.new)
      super
    end

    def input=(input)
      unless @import
	@import = Import.new(Queue.new)
	@import.no=input.no
	@import.add_key(input.key)
	start
      end
      self
    end

    def start
      super do
	@bjob.wait_export
	@import.each{|e| @export.push e}
      end
    end
  end

end

require "node/n-filter"
require "node/n-single-exportable"

module Fairy
  class NEachElementMapper<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @map_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @map_proc = @context.create_proc(@block_source)
    end

    def start
      super do
	@map_proc = BBlock.new(@block_source, @context, self)
	@import.each do |e|
	  @export.push @map_proc.yield(e)
	end
      end
    end
  end
end

require "node/n-filter"

module Fairy
  class NEachElementSelector<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @map_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @map_proc = @context.create_proc(@block_source)
    end

    def start
      super do
	@map_proc = BBlock.new(@block_source, @context, self)
	@import.each do |e|
	  if @map_proc.yield(e)
	    @export.push e
	  end
	end
      end
    end
  end
end

require "node/njob"
require "node/n-single-exportable"

module Fairy
  class NEachSubStreamMapper<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @map_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @map_proc = @context.create_proc(@block_source)
    end

    def start
      super do
	@map_proc = BBlock.new(@block_source, @context, self)
	@map_proc.yield(@import, @export)
      end
    end
  end

end

require "uri"

require "node/n-filter"

module Fairy
  class NFileOutput<NFilter
    Processor.def_export self
    
    ST_OUTPUT_FINISH = :ST_OUTPUT_FINISH

    def initialize(processor, bjob, opt, vf)
      super
      @vfile = vf

      @imports = Queue.new
    end

    def input=(input)
      super
      @imports.push @import
    end

    def add_input(input)
      unless input
	@imports.push nil
	return self
      end
      import = Import.new
      import.add_key(input.key)
      input.output = import
      @imports.push import
      self
    end

    def start
      output_uri = @vfile.gen_real_file_name(@processor.addr)
      output_file = URI.parse(output_uri).path

      super do
	File.open(output_file, "w") do |io|
	  while import = @imports.pop
	    for l in import
	      io.puts l
	    end
	  end
	end
	self.status = ST_OUTPUT_FINISH
      end
    end
  end
end

require "node/njob"
require "node/port"

module Fairy
  class NFilter<NJob
    Processor.def_export self

    ST_WAIT_IMPORT = :ST_WAIT_IMPORT

    def initialize(processor, bjob, opts=nil, *rests)
      super
      @import = nil

      self.status=ST_WAIT_IMPORT
    end

    attr_reader :import

    def input=(input)
      unless @import
	self.no = input.no
	@import = Import.new
	@import.no=input.no
	@import.add_key(input.key)
	start
      end
      self
    end
  end
end

require "node/n-filter"

module Fairy
  class NLocalFind<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
      @map_proc = BBlock.new(@block_source, @context, self)

      @find = false
      @find_mutex = Mutex.new
    end

    def start
      super do
	@import.each do |e|
	  # 見つかっていたら空読み
	  @find_mutex.synchronize do
	    next if @find 
	    next unless find = @map_proc.yield(e)
	    @export.push e
	  end
	end
      end
    end

    def find_break
      @find_mutex.synchronize do
	@find = true
      end
    end
  end


  class NFindResult<NSingleExportFilter
    Processor.def_export self

    def initialize(*args)
      super

      @value = :__FAIRY_NO_VALUE__
      @value_mutex = Mutex.new
      @value_cv = ConditionVariable.new
    end

    def value
      @value_mutex.synchronize do
	while @value == :__FAIRY_NO_VALUE__
	  @value_cv.wait(@value_mutex)
	end
	@value
      end
    end

    def start
      super do
	find = false
	@import.each do |e|
	  # 最初の要素以外空読み
	  next if find 
	  find = e

	  @value = find
	  @value_cv.broadcast 
	  @export.push find
	  # ちょっと気になる...
	  @export.push 

	  @bjob.update_find
	end
      end
    end
  end
end

require "node/n-filter"

module Fairy
  class NGroupBy<NFilter
    Processor.def_export self

    ST_WAIT_EXPORT_FINISH = :ST_WAIT_EXPORT_FINISH
    ST_EXPORT_FINISH = :ST_EXPORT_FINISH

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @hash_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @hash_proc = @context.create_proc(@block_source)

      @exports = {}
      @exports_queue = Queue.new

      start_watch_exports
    end

    def add_export(key, export)
      @exports[key] = export
      @exports_queue.push [key, export]
    end

    def start
      super do
	@hash_proc = BBlock.new(@block_source, @context, self)
	begin
	  @import.each do |e|
	    key = @hash_proc.yield(e)
	    export = @exports[key]
	    unless export
	      export = Export.new
	      export.add_key(key)
	      add_export(key, export)
	    end
	    export.push e
	  end
	ensure
	  @exports.each{|key, export| export.push END_OF_STREAM}
	  wait_export_finish
	end
      end
    end

    def wait_export_finish

      # すべての, exportのoutputが設定されるまで待っている
      # かなりイマイチ
      for key, export in @exports
	export.output
      end

      # ここの位置が重要
      self.status = ST_WAIT_EXPORT_FINISH
      # ここもいまいち
      for key,  export in @exports
	export.wait_finish
      end
      self.status = ST_EXPORT_FINISH
    end

    def start_watch_exports
      Thread.start do
	loop do
	  key, export = @exports_queue.pop
	  notice_exports(key, export)
	end
      end
      nil
    end

    def notice_exports(key, export)
      @bjob.update_exports(key, export, self)
    end
  end

  class NMGroupBy<NFilter
    Processor.def_export self

    ST_WAIT_EXPORT_FINISH = :ST_WAIT_EXPORT_FINISH
    ST_EXPORT_FINISH = :ST_EXPORT_FINISH

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @hash_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @hash_proc = @context.create_proc(@block_source)
      @hash_proc = BBlock.new(@block_source, @context, self)

      @exports = {}
      @exports_queue = Queue.new

      start_watch_exports
    end

    def add_export(key, export)
      @exports[key] = export
      @exports_queue.push [key, export]
    end

    def start
      super do
	@import.each do |e|
	  keys = @hash_proc.yield(e)
	  keys = [keys] unless keys.kind_of?(Array)
	  
	  for key in keys 
	    export = @exports[key]
	    unless export
	      export = Export.new
	      export.add_key(key)
	      add_export(key, export)
	    end
	    export.push e
	  end
	end
	@exports.each{|key, export| export.push END_OF_STREAM}
	wait_export_finish
      end
    end

    def wait_export_finish

      # すべての, exportのoutputが設定されるまで待っている
      # かなりイマイチ
      for key, export in @exports
	export.output
      end

      # ここの位置が重要
      self.status = ST_WAIT_EXPORT_FINISH
      # ここもいまいち
      for key,  export in @exports
	export.wait_finish
      end
      self.status = ST_EXPORT_FINISH
    end

    def start_watch_exports
      Thread.start do
	loop do
	  key, export = @exports_queue.pop
	  notice_exports(key, export)
	end
      end
      nil
    end

    def notice_exports(key, export)
      @bjob.update_exports(key, export, self)
    end
  end
end



require "node/njob"
require "node/n-single-exportable"

module Fairy
  class NIdentity<NSingleExportFilter
    Processor.def_export self

    def initialize(processor, bjob, opts=nil)
      super
    end

    def start
      super do
	@import.each{|e| @export.push e}
      end
    end
  end

end

require "node/njob"
require "node/n-single-exportable"

module Fairy

  class NInject<NSingleExportFilter
    def initialize(processor, bjob, opts, block_source)
      super

      @init_value = :__FAIRY_NO_VALUE__
      if @opts.key?(:init_value)
	@init_value = @opts[:init_value]
      end
      @block_source = block_source
#      @inject_proc = @context.create_proc(@block_source)
    end

    def start
      super do
	@inject_proc = BBlock.new(@block_source, @context, self)
	sum = @init_value
	@import.each do |e|
	  if sum == :__FAIRY_NO_VALUE__
	    sum = e
	  else
	    sum = @inject_proc.yield(sum, e)
	  end
	end
	finish(sum)
      end
    end
  end

  class NLocalInject<NInject
    Processor.def_export self
    
    def finish(sum)
      @export.push sum
    end

  end

  class NWideInject<NInject
    Processor.def_export self

    def initialize(*args)
      super

      @value = :__FAIRY_NO_VALUE__
      @value_mutex = Mutex.new
      @value_cv = ConditionVariable.new
    end

    def value
      @value_mutex.synchronize do
	while @value == :__FAIRY_NO_VALUE__
	  @value_cv.wait(@value_mutex)
	end
	@value
      end
    end

    def finish(sum)
      @value = sum
      @value_cv.broadcast 
      if @export
	@export.push sum
      end
    end
  end
end

module Fairy
  class NIota<NSingleExportInput
    Processor.def_export self

    def initialize(processor, bjob, opts, first, last)
      super
      @first = first
      @last = last
    end

    def start
      super do
	for i in @first..@last
	  @export.push i
	end
      end
    end

  end
end


module Fairy
  class NInputVArray<NSingleExportInput
    Processor.def_export self

    def initialize(processor, bjob, opts, array)
      super
      @array = array
    end

    def start
      super do
	for i in @array
	  @export.push i
	end
      end
    end

  end
end


require "node/njob"
require "node/n-single-exportable"

module Fairy
  class NLFileInput<NSingleExportInput
    Processor.def_export self

    def self.open(processor, bjob, io, opts=nil)
      nlfileinput = self.new(processor, bjob, opts)
      nlfileinput.open(job)
    end

    def initialize(processor, bjob, opts=nil)
      super
    end

    def open(io)
      @io = io
      start
      self
    end

    def start
      super do
	for l in @io
	  @export.push l
	end
      end
    end
  end
end

require "uri"

require "node/n-filter"

module Fairy
  class NLFileOutput<NSingleExportFilter
    Processor.def_export self

    ST_OUTPUT_FINISH = :ST_OUTPUT_FINISH

    def initialize(processor, bjob, opts=nil)
      super

      @imports = Queue.new
    end

    def input=(input)
      super
      @imports.push @import
    end

    def add_input(input)
      unless input
	@imports.push nil
	return self
      end
      import = Import.new
      import.no=(input.no)
      import.add_key(input.key)
      input.output = import
      @imports.push import
      self
    end

    def start
      super do
	while import = @imports.pop
	  for l in import
	    @export.push l
	  end
	end
      end
    end
  end
end

require "node/n-filter"

require "share/varray"

module Fairy
  class NOutputVArray<NFilter
    Processor.def_export self
    
    ST_OUTPUT_FINISH = :ST_OUTPUT_FINISH

#    DeepConnect.def_single_method_spec(self, "REF new(REF, REF, VAL, REF)")

#    def initialize(processor, bjob, opt, varray, idx)
    def initialize(processor, bjob, opt, idx)
      super
      @no_in_bjob = idx
    end

    def start
      super do
	array = []
	for l in @import
	  array.push l
	end
	
	@processor.register_varray_element(array)
	@bjob.varray.arrays_put(@no_in_bjob, array)
	self.status = ST_OUTPUT_FINISH
      end
    end
  end
end

require "node/n-filter"
 
module Fairy
  module NSingleExportable
    END_OF_STREAM = NJob::END_OF_STREAM

    ST_WAIT_EXPORT_FINISH = :ST_WAIT_EXPORT_FINISH
    ST_EXPORT_FINISH = :ST_EXPORT_FINISH

    def initialize(processor, bjob, opts=nil, *rests)
      super
      @export = Export.new unless @export
    end

    attr_reader :export

    def no=(no)
      super
      @export.no = no
    end

    def start(&block)
      super do
	begin
	  if @import
	    @export.add_key(@import.key)
	  end
	  block.call
	ensure
	  @export.push END_OF_STREAM
	  wait_export_finish
	end
      end
    end

    def wait_export_finish
      self.status = ST_WAIT_EXPORT_FINISH
      @export.wait_finish
      self.status = ST_EXPORT_FINISH
    end
  end

  class NSingleExportFilter<NFilter
    include NSingleExportable
  end


  class NSingleExportInput<NFilter
    include NSingleExportable
  end

end

require "node/n-filter"

module Fairy
  class NSplitter<NFilter
    Processor.def_export self

    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL, VAL)")

    def initialize(processor, bjob, opts, n)
      super
      @no_split = n

      @exports = @no_split.times.collect{Export.new}
    end

    attr_reader :exports

    def start
      super do
	begin
	  @import.each_slice(@no_split) do |ll|
	    if ll.size < @no_split
	      ll.fill(0, @no_split){|idx| ll[idx] ||= END_OF_STREAM}
	    end
	    @exports.zip(ll) do |exp, l|
	      exp.push l
	    end
	  end
	ensure
	  @exports.each{|exp| exp.push END_OF_STREAM}
	end
      end
    end
  end
end

require "node/njob"
require "node/port"
require "node/n-single-exportable"

module Fairy
  class NThere<NJob
    Processor.def_export self

    include NSingleExportable


    def initialize(processor, bjob, opts, enumerable)
      super
      @enumerable = enumerable
    end

    def start
      super do
	@enumerable.each{|e| @export.push e}
      end
    end
  end
end

require "node/n-filter"
require "node/n-single-exportable"

module Fairy
  class NZipper<NSingleExportFilter
    Processor.def_export self

    DeepConnect.def_single_method_spec(self, "REF new(REF, VAL, VAL, VAL)")

    def initialize(processor, bjob, opts, block_source)
      super
      @block_source = block_source
#      @map_proc = eval("proc{#{@block_source}}", TOPLEVEL_BINDING)
#      @map_proc = @context.create_proc(@block_source)

      @zip_imports = nil
      @zip_imports_mutex = Mutex.new
      @zip_imports_cv = ConditionVariable.new
    end

    def zip_imports
      @zip_imports_mutex.synchronize do
	while !@zip_imports
	  @zip_imports_cv.wait(@zip_imports_mutex)
	end
      end
      @zip_imports
    end

    DeepConnect.def_method_spec(self, "VAL zip_imports")

    def zip_inputs=(zinputs)
      # 仮
      @zip_imports_mutex.synchronize do
	@zip_imports = zinputs.collect{|zinput| 
	  import = Import.new
	  import.no = zinput.no
	  import.add_key(zinput.key)
	  import
	}
	@zip_imports_cv.broadcast
      end
      @zip_imports
    end
    DeepConnect.def_method_spec(self, :rets => "VAL", :method => :zip_inputs=, :args => "VAL")

    def start
      super do
	@map_proc = BBlock.new(@block_source, @context, self)
	@import.each do |e|
	  zips = zip_imports.collect{|import| import.pop}
	  @export.push @map_proc.yield(e, *zips)
	end
      end
    end
  end
end

require "node/njob"
require "node/port"
require "node/n-single-exportable"

module Fairy
  class NFile<NSingleExportInput
    Processor.def_export self

    def NFile.open(processor, bjob, opts, fn)
      nfile = NFile.new(processor, bjob, opts)
      nfile.open(fn)
    end

    def initialize(processor, bjob, opts=nil)
      super
      @file = nil
    end

    def open(file_name)
      @file_name = file_name
      @file = File.open(file_name)
      start
      self
    end

    def start
      super do
	for l in @file
	  @export.push l
	end
	@file.close
	@file = nil # FileオブジェクトをGCの対象にするため
      end
    end
  end
end

require "node/n-filter"
require "node/n-single-exportable"

module Fairy
  class NHere<NFilter
    Processor.def_export self

    include NSingleExportable

    def start
      super do
	@import.each do |e|
# 	  if e.__deep_connect_reference? && e.kind_of?(Array)
# 	    e = e.to_a
# 	  end
	  @export.push e
	end
      end
    end
  end
end

require "thread"

require "processor"
require "share/block-source"

module Fairy

  class NJob
    Processor.def_export self

    END_OF_STREAM = :END_OF_STREAM

    ST_INIT = :ST_INIT
    ST_ACTIVATE = :ST_ACTIVATE
    ST_FINISH = :ST_FINISH

    def initialize(processor, bjob, opts={}, *rests)
      Log::info self, "CREATE NJOB: #{self.class}"
      @processor = processor
      @bjob = bjob
      @opts = opts

      @main_thread = nil

      @context = Context.new(self)
#       @begin_block = nil
#       if @opts[:BEGIN]
# 	@begin_block = BBlock.new(@opts[:BEGIN], @context, self)
#       end
#       @end_block = nil
#       if @opts[:END]
# 	@end_block = BBlock.new(@opts[:END], @context, self)
#       end

      @begin_block_source = nil
      if @opts[:BEGIN]
	@begin_block_source = @opts[:BEGIN]
      end
      @end_block_source = nil
      if @opts[:END]
	@end_block_source = @opts[:END]
      end

      @no = nil
      @no_mutex = Mutex.new
      @no_cv = ConditionVariable.new

      @status = ST_INIT
      @status_mutex = Mutex.new
      @status_cv = ConditionVariable.new

      start_watch_status
    end

    attr_reader :processor
    
    def no=(no)
      @no = no
      @no_cv.broadcast
      @no
    end

    def no
      @no_mutex.synchronize do
	while !@no
	  @no_cv.wait(@no_mutex)
	end
	no
      end
    end

    def start(&block)
#      puts "START NJOB: #{self.class}"
      @main_thread = Thread.start{
	self.status = ST_ACTIVATE
	if @begin_block_source
	  bsource = BSource.new(@begin_block_source, @context, self)
	  bsource.evaluate
	end
	begin
	  block.call
	ensure
	  if @end_block_source
	    bsource = BSource.new(@end_block_source, @context, self)
	    bsource.evaluate
	  end
	  self.status = ST_FINISH
	end
      }
      nil
    end

    def global_break
      Thread.start{@bjob.break_running(self)}
      Thread.current.exit
      self.status = ST_FINISH
      # 他のスレッドはとめていない
    end

    def break_running
      @main_thread.exit
      self.status = ST_FINISH
      # 他のスレッドはとめていない
    end

    def status=(val)
      @status_mutex.synchronize do
	@status = val
	@status_cv.broadcast
      end
    end

    def start_watch_status
      # 初期状態通知
      notice_status(@status)

      Thread.start do
	old_status = nil
	loop do
	  @status_mutex.synchronize do
	    while old_status == @status
	      @status_cv.wait(@status_mutex)
	    end
	    old_status = @status
# puts "STATUS CHANGED: #{self} #{@status}"
	    notice_status(@status)
	  end
	end
      end
      nil
    end

    def start_watch_status0
      Thread.start do
	old_status = nil
	@status_mutex.synchronize do
	  loop do
	    while old_status == @status
	      @status_cv.wait(@status_mutex)
	    end
	    old_status = @status
	    notice_status(@status)
	  end
	end
      end
      nil
    end

    def notice_status(st)
      @bjob.update_status(self, st)
      @processor.update_status(self, st)
    end

#     # block create
#     def create_block(source)
#       unless Fairy.const_defined?(:Pool)
# 	pool_dict = @bjob.pool_dict
# 	Fairy.const_set(:Pool, pool_dict)
#       end
#       eval("def Pool = Fairy::Pool", TOPLEVEL_BINDING)

#       binding = eval("def fairy_binding; binding; end; fairy_binding",
# 		      TOPLEVEL_BINDING, 
# 		      __FILE__,
# 		      __LINE__ - 3)
#     end

    def handle_exception(exp)
      @bjob.handle_exception(exp)
    end

    class Context
      def initialize(njob)
	@Pool = njob.instance_eval{@bjob.pool_dict}
	@JobPool = njob.instance_eval{@bjob.job_pool_dict}
	#      @Import = njob.instance_eval{@import}
	#      @Export = njob.instance_eval{@export}
	@__context = context
      end

      def context
	__binding
      end

      class GlobalBreak<Exception;end
#      class LocalBreak<Exception;end
      def global_break
	Thread.current.raise GlobalBreak
      end
      alias gbreak global_break

#       def local_break
# 	Thread.current.raise LocalBreak
#       end

      alias __binding binding
      def binding
	@__context
      end
      alias bind binding
    end
  end
end

module Fairy

  PORT_BUFFER_SIZE = 10

  class Import
    include Enumerable

    END_OF_STREAM = :END_OF_STREAM

    class CTLTOKEN;end
    SET_NO_IMPORT = CTLTOKEN.new

    def initialize(queue = nil)
      if queue
	@queue = queue
      else
	@queue = SizedQueue.new(PORT_BUFFER_SIZE)
      end

      @no = nil
      @no_mutex = Mutex.new
      @no_cv = ConditionVariable.new

      @key = nil

      @no_import = nil

      @no_eos = 0
    end

    def no
      @no_mutex.synchronize do
	while !@no
	  @no_cv.wait(@no_mutex)
	end
	@no
      end
    end

    def no=(no)
      @no_mutex.synchronize do
	@no=no
	@no_cv.broadcast
      end
    end

    attr_reader :key
    def add_key(key)
      @key = key
    end

    def no_import=(n)
      @no_import = n
      @queue.push SET_NO_IMPORT
    end

    def push(e)
      @queue.push e
    end
    # 取りあえず
#    DeepConnect.def_method_spec(self, "REF push(DVAL)")

    def pop
      while !@no_import or @no_import > @no_eos
	case e = @queue.pop
	when SET_NO_IMPORT
	  # do nothing
	when END_OF_STREAM
	  @no_eos += 1
	else
	  return e
	end
      end
      return nil
    end

    def each(&block)
      while !@no_import or @no_import > @no_eos
	case e = @queue.pop
	when SET_NO_IMPORT
	  # do nothing
	when END_OF_STREAM
	  @no_eos += 1
	else
	  block.call(e)
	end
      end
    end

    def size
      size = 0
      each{size += 1}
      size
    end

  end

  class Export
    END_OF_STREAM = :END_OF_STREAM

    def initialize(queue = nil)
      @output = nil
      @output_mutex = Mutex.new
      @output_cv = ConditionVariable.new

      if queue
	@queue = queue
      else
	@queue = SizedQueue.new(PORT_BUFFER_SIZE)
      end

      @no = nil
      @no_mutex = Mutex.new
      @no_cv = ConditionVariable.new

      @key = nil

      @status = nil
      @status_mutex = Mutex.new
      @status_cv = ConditionVariable.new
    end

    def no
      @no_mutex.synchronize do
	while !@no
	  @no_cv.wait(@no_mutex)
	end
	@no
      end
    end

    def no=(no)
      @no_mutex.synchronize do
	@no=no
	@no_cv.broadcast
      end
    end

    attr_reader :key
    def add_key(key)
      @key = key
    end

    def output?
      @output_mutex.synchronize do
	@output
      end
    end

    def output
      @output_mutex.synchronize do
	while !@output
	  @output_cv.wait(@output_mutex)
	end
	@output
      end
    end

    def output=(output)
      @output_mutex.synchronize do
	@output = output
	@output_cv.broadcast
      end

      start_export
      nil
    end

    def output_no_import=(n)
      if output?
	@output.no_import = n
      else
	# 遅延設定(shuffleのため)
	Thread.start do
	  output.no_import = n
	end
	n
      end
    end

    def push(e)
      @queue.push e
    end

    def start_export
      Thread.start do
	self.status = :EXPORT
	while (e = @queue.pop) != END_OF_STREAM
	  @output.push e
	end
	@output.push END_OF_STREAM
	self.status = END_OF_STREAM
      end
      nil
    end

    def status=(val)
      @status_mutex.synchronize do
	@status = val
	@status_cv.broadcast
      end
    end

    def wait_finish
      @status_mutex.synchronize do
	while @status != END_OF_STREAM
	  @status_cv.wait(@status_mutex)
	end
	@status = :EXPORT_FINISH
      end
    end
  end
end

module Fairy
  class BlockSource
    def initialize(source)
      @source = source
      @backtrace = caller(1).select{|l| /fairy.*(share|job)/ !~ l}
      l = caller(1)[caller(1).index(backtrace.first)-1]
      @caller_method = (/in `(.*)'/.match(l))[1]
    end

    attr_reader :source
    attr_reader :backtrace
    attr_reader :caller_method
  end

  class BScript
    def initialize(block_source, context, exception_handler)
      @block_source = block_source.dc_deep_copy
      @context = context
      @exception_handler = exception_handler
    end

    def evaluate
      match = /^(.*):([0-9]+)/.match(@block_source.backtrace.first)

      begin
	$stdout.replace_stdout do
	  eval(@block_source.source, @context.bind, match[1], match[2].to_i)
	end
      rescue Exception
	Log::warn(self) do |sio|
	  sio.puts "Warn: Exception raised:"
	  sio.puts $!
	  for l in $@
	    sio.puts "\t#{l}"
	  end
	end
	bt = $!.backtrace.select{|l| /fairy.*(share|job|backend|node|processor|controller)|deep-connect|__FORWARDABLE__|bin.*processor/ !~ l}
	if bt.first
	  bt.first.sub!("bind", @block_source.caller_method)
	end
	bt.push *@block_source.backtrace.dc_deep_copy
	$!.set_backtrace(bt)
	@exception_handler.handle_exception($!)
      end
    end
  end
  BSource = BScript

  class BBlock
    def initialize(block_source, context, exception_handler)
      @block_source = block_source.dc_deep_copy
      @context = context
      @exception_handler = exception_handler

      match = /^(.*):([0-9]+)/.match(@block_source.backtrace.first)
      begin
	@block = eval("proc{#{@block_source.source}}", context.binding, match[1], match[2].to_i)
      rescue ScriptError
	Log::warn(self) do |sio|
	  sio.puts "Warn: Exception raised:"
	  sio.puts $!
	  for l in $@
	    sio.puts "\t#{l}"
	  end
	end
	bt = @block_source.backtrace.dc_deep_copy
	$!.set_backtrace(bt)
	@njob.handle_exception($!)
	# ここの処理がイマイチ
      end
    end

    def yield(*args)
      begin
	if @block.respond_to?(:yield)
	  $stdout.replace_stdout do
	    @block.yield(*args)
	  end
	else
	  if args.size == 1 && args.first.kind_of?(Array)
	    args = args.first.to_a
	  end
	  $stdout.replace_stdout do
	    @block.call(*args)
	  end
	end
#       rescue @context.class::LocalBreak
# 	Log::debug(self, "CAUGHT LocalBreak")

      rescue LocalJumpError, @context.class::GlobalBreak
	Log::debug(self, "CAUGHT GlobalBreak")
	@exception_handler.global_break

      rescue Exception
	Log::warn(self) do |sio|
	  sio.puts "Warn: Exception raised:"
	  sio.puts $!
	  for l in $@
	    sio.puts "\t#{l}"
	  end
	end
	bt = $!.backtrace.select{|l| /fairy.*(share|job|backend|node|processor|controller)|deep-connect|__FORWARDABLE__|bin.*processor/ !~ l}
	bt.first.sub!("bind", @block_source.caller_method)
	bt.push *@block_source.backtrace.dc_deep_copy
	$!.set_backtrace(bt)
	@exception_handler.handle_exception($!)
      end
    end
    alias call yield
  end
end


module Fairy

  CONF_PATH = [
    "/etc/fairy.conf",
    ENV["HOME"]+"/.fairyrc",
    ENV["FAIRY_CONF"],
    "etc/fairy.conf"
  ]
    

  class Conf
    class DefaultConf<Conf;end

    def initialize
      @values = {}
    end

    class<<Conf
      def def_prop(prop)
	module_eval "def #{prop}(value); @values[:#{prop}]; end"
	module_eval "def #{prop}=(value); @values[:#{prop}] = value; end"
	DefaultConf.module_eval "def #{prop}; value(:#{prop}); end"
      end
    end

    def value(prop)
      @values[prop]
    end

    def_prop :RUBY_BIN
    def_prop :MASTER_HOST
    def_prop :MASTER_PORT
    def_prop :HOME
    def_prop :BIN
    def_prop :CONTROLLER_BIN
    def_prop :PROCESSOR_BIN
    def_prop :LIB

    def_prop :LOG_FILE
    def_prop :LOG_LEVEL
    def_prop :LOG_FLUSH_INTERVAL

    def_prop :VF_ROOT

    class DefaultConf

      def initialize
	super

	@default_host = `hostname`.chomp
	@hosts = {}
      end

      def [](host)
	unless @hosts[host]
	  @hosts[host] = Conf.new
	end
	@hosts[host]
      end

      def value(prop)
	conf = @hosts[@default_host]
	v = conf && conf.value(prop)
	return v if v
	@values[prop]
      end

      def load_conf
	for path in CONF_PATH
	  if path
	    if File.exist?(path)
	      load path
	    end
	  end
	end
      end
    end
  end

  CONF = Conf::DefaultConf.new
  CONF.load_conf

end

module Fairy
  module Debug
    def njob_status_monitor_on(fairy)
#      require "backend/bjob"
      
      bjob = fairy.name2backend_class("BJob")
      bjob.watch_status = true
    end

    for method in self.instance_methods
      module_function method
    end

  end
end


require "e2mmap"

module Fairy
  extend Exception2MessageMapper

  class BreakCreateNode<Exception;end

end

require "deep-connect/future"

require "forwardable"
require "thread"


module Fairy
  class Log

    LEVELS = [:FATAL, :ERROR, :WARN, :INFO, :DEBUG]
    MESSAGE_LEVEL = CONF.LOG_LEVEL
    
    PRINT_STDOUT = true

    def initialize
      @logger = nil
      @host = `hostname`.chomp
      @type = $0
      @pid = nil

      @mutex = Mutex.new
    end

    @the_log = Log.new

    class<<self
      extend Forwardable

      def method_added(method)
	(class<<self;self;end).def_delegator :@the_log, method
      end
    end

    attr_accessor :logger
    attr_accessor :type
    attr_accessor :pid

    # Log::log(sender, format, args...)
    # Log::log(format, args,...)
    def log(sender, format=nil, *args, &block)
      bt = caller(0).select{|l| /fairy.*(share\/log)|__FORWARDABLE__/ !~ l}
      bt.first =~ /\/([^\/]*\.rb):([0-9]+):in `(.*)'$/
      file_name = $1
      line_no = $2
      method = $3

      if sender.kind_of?(String)
	format = sender
	sender_type = "[UNDEF]"
      else
	sender_type = sender.class.name.sub(/Fairy::/, "")
      end

      time = Time.now
      prefix = time.strftime("%Y/%m/%d %H:%M:%S")
      prefix.concat sprintf(".%06d %s ", time.usec, @host)
      mes = sprintf("%s%s%s %s[%s] %s#%s: ", 
		    @type, 
		    @pid ? "\##{@pid}": "", 
		    Thread.current["name"] ? Thread.current["name"]: "",
		    file_name, line_no,
		    sender_type, method)
      if block_given?
	sio = StringIO.new(mes, "a+")
	yield sio
      else
	mes.concat sprintf(format, *args)
      end
      mes.chomp!
      stdout_puts mes if PRINT_STDOUT

      if @logger
	DeepConnect.future{@mutex.synchronize{@logger.message(prefix+mes)}} 
      else
	stdout_puts "****Loggerが設定されていません****"
      end
    end
    alias stdout_puts puts
    alias puts log

    # Log::log_exception(sender, exception, level = :WARN)
    # Log::log_exception(exception, level = :WARN)
    def log_exception(sender = $!, exception=$!)
      if sender.kind_of?(Exception)
	exception = sender
	sender = "UNDEF"
      end
      log(sender) do |sio|
	sio.puts exception
	for l in exception.back_trace
	  sio.puts l
	end
      end
    end

    def nop(*args); end

    range = LEVELS[0..LEVELS.index(MESSAGE_LEVEL)]
    if range
      for level in range
	method = level.id2name.downcase
	alias_method method, :log
	alias_method method+"_exception", :log
      end
    end

    range = LEVELS[LEVELS.index(MESSAGE_LEVEL)+1.. -1]
    if range
      for level in range
	method = level.id2name.downcase
	alias_method method, :nop
	alias_method method+"_exception", :nop
      end
    end

    if MESSAGE_LEVEL == :DEBUG
      def debug_p(*objs)
	for o in objs
	  log(o.inspect)
	end
      end
    else
      def debug_p(*args);end      
    end
  end
end

module Fairy
  class PoolDictionary
    
    def initialize
      @pool = {}
      @pool_mutex = Mutex.new
      @pool_cv = ConditionVariable.new
    end

    attr_reader :pool_mutex
    attr_reader :pool_cv

    def def_variable(vname, value = nil)
      @pool_mutex.synchronize do
	if @pool.key?(vname)
	  raise "すでに変数#{vname}は登録されています"
	end
	case value
	when DeepConnect::Reference
	  @pool[vname] = value.dc_deep_copy
	else
	  @pool[vname] = value
	end
	
	instance_eval "def #{vname}; self[:#{vname}]; end"
	instance_eval "def #{vname}=(v); self[:#{vname}]=v; end"
      end
    end
    def [](name)
      @pool_mutex.synchronize do
	raise "変数#{name}は登録されていません" unless @pool.key?(name)
	@pool[name]
      end
    end

    def []=(name, value)
      @pool_mutex.synchronize do
	raise "変数#{name}は登録されていません" unless @pool.key?(name)
	case value
	when DeepConnect::Reference
	  @pool[name] = value.dc_deep_copy
	else
	  @pool[name] = value
	end
      end
    end
  end
end


require "thread"
module Fairy
  class Reference
    class NullValue;end
    NULL_VALUE = NullValue.new

    def initialize
      @value = NULL_VALUE
      @value_mutex = Mutex.new
      @value_cv = ConditionVariable.new
    end

    def value
      @value_mutex.synchronize do
	while @value == NULL_VALUE
	  @value_cv.wait(@value_mutex)
	end
      end
      @value
    end

    def value=(v)
      @value_mutex.synchronize do
	@value = v
	@value_cv.broadcast
      end
    end

    def arrived?
      @value_mutex.synchronize do
	@value != NULL_VALUE
      end
    end

    def wait_arrived
      value
    end
  end
end

require "thread"

module Fairy

  class Stdout
    def initialize(peer)
      @local_stdout = $stdout
      @peer = peer
      @threads = {}
      
      @mutex = Mutex.new
    end

    def write(str)
      @mutex.synchronize do
	if @threads[Thread.current]
	  @peer.stdout_write(str)
	else
	  @local_stdout.write(str)
	end
      end
    end

    def replace_stdout(&block)
      @mutex.synchronize do
	@threads[Thread.current] = 0 unless @threads[Thread.current] 
	@threads[Thread.current] += 1
      end
      begin
	yield
      ensure
	@mutex.synchronize do
	  @threads[Thread.current] -= 1
	  @threads.delete(Thread.current) if @threads[Thread.current] == 0
	end
      end
    end
  end
end

#def puts(str)
#  $stdout.write(str+"\n")
#end

require "tracer"
Tracer.add_filter do |event, file, line, id, binding, klass|
  file =~ /^\./ && file !~ /deep-connect/
end

Tracer.display_process_id = true
Tracer.display_thread_id = true
Tracer.display_c_call = false
	  
Tracer.on


module Fairy
  class VArray
    include Enumerable

    def self.output(fairy, opts)
      OutputVArray.output(fairy, opts)
    end

    def initialize
      @arrays = nil
      @arrays_mutex = Mutex.new
      @arrays_cv = ConditionVariable.new
    end

    def [](idx)
      case idx
      when Integer
	ary_idx, idx = index_on_arrays(idx)
	return arrays[ary_idx][idx]
      when Range
	raise TypeError, "そのクラスはサポートしていません(#{idx})"
      else
	raise TypeError, "そのクラスはサポートしていません(#{idx})"
      end
    end

    def []=(idx, val)
      case idx
      when Integer
	ary_idx, idx = index_on_arrays(idx)
	return arrays[ary_idx][idx]=val
      else
	raise TypeError, "そのクラスはサポートしていません(#{idx})"
      end
    end

    def each(&block)
      # set_arrayされるまでまっている.
      arrays.size.times do |idx|
	ary = nil
	@arrays_mutex.synchronize do
	  while @arrays[idx].nil?
	    @arrays_cv.wait(@arrays_mutex)
	  end
	  ary = @arrays[idx]
	end
	ary.each(&block)
      end
    end

    # arrays 操作
    def arrays
      @arrays_mutex.synchronize do
	while @arrays.nil?
	  @arrays_cv.wait(@arrays_mutex)
	end
	@arrays
      end
    end

    def set_arrays(array)
      @arrays_mutex.synchronize do
	@arrays = array
	@arrays_cv.broadcast
      end
    end

    def arrays_size
      self.arrays.size
    end

    def arrays_put(idx, array)
      @arrays_mutex.synchronize do
	while @arrays.nil?
	  @arrays_cv.wait(@arrays_mutex)
	end
	@arrays[idx] = array
	@arrays_cv.broadcast
      end
    end

    def arrays_at(idx)
      @arrays_mutex.synchronize do
	while @arrays.nil? or @arrays[idx].nil?
	  @arrays_cv.wait(@arrays_mutex)
	end
	@arrays[idx]
      end
    end

    def index_on_arrays(idx)
      arrays.each_index do |ary_idx|
	ary_size = arrays[ary_idx].size
	if idx < ary_size
	  return ary_idx, idx
	end
	idx -= ary_size
      end
    end

  end
end

require "e2mmap"

module Fairy
  class VFile
    extend Exception2MessageMapper

    def_exception :UnrecognizedFile, "%sがvfileかどうか分かりません"

    VFILE_EXT = ".vf"
    VFILE_HEADER = "#!fairy vfile"
    VFILE_MAGIC = /^#{Regexp.escape(VFILE_HEADER)}/

    def VFile.vfile?(path)
      if File.extname(path) == VFILE_EXT
	return true
      end
      if !File.exist?(path)
	return false
      end
	
      File.open(path) do |io|
	l = io.gets
	return VFILE_MAGIC =~ l
      end
    end

    def VFile.vfile(path)
      vfile = new
      vfile.vfile(path)
      vfile
    end

    def VFile.real_files(real_files)
      vfile = new
      vfile.real_file_names = real_files
      vfile
    end
    
    def initialize
      @vfile_name = nil

      @real_file_names = []
      @real_file_names_mutex = Mutex.new
      @real_file_names_cv = ConditionVariable.new
    end

    attr_reader :vfile_name
    
    def vfile_name=(path)
      @vfile_name = path
      @base_name = path.gsub(/\//, "-")
    end

    def real_file_names
      @real_file_names_mutex.synchronize do
	@real_file_names
      end
    end


    def real_file_names=(val)
      @real_file_names_mutex.synchronize do
	@real_file_names=val
      end
    end

    def vfile(path)
      File.open(path) do |io|
	l = io.gets
	unless VFILE_MAGIC =~ l
	  raise "VFileではありません(#{path})"
	end

	files = []
	for l in io
	  next if l =~ /^\s*$/
	  next if l =~ /^\s*#.*$/
	  files.push l
	end
	
	@real_file_names_mutex.synchronize do
	  @real_file_names = files
	end
      end
    end

    def each_real_file_name(&block)
      real_file_names.dup.each &block
    end
    alias each each_real_file_name

    def create_vfile
      File.open(@vfile_name, "w") do |io|
	io.puts VFILE_HEADER
	io.puts
	@real_file_names_mutex.synchronize do
	  @real_file_names.each do |fn|
	    io.puts fn
	  end
	end
      end
    end

    TOP = "/tmp/fairy"

    IPADDR_REGEXP = /::ffff:([0-9]+\.){3}[0-9]+|[0-9a-f]+:([0-9a-f]*:)[0-9a-f]*/

    # file name: #{base}-NNN
    def gen_real_file_name(host)

      if IPADDR_REGEXP =~ host
	begin
	  host = Resolv.getname(host)
	rescue
	  # ホスト名が分からない場合 は そのまま ipv6 アドレスにする
	  host = "[#{host}]"
	end
      end

      base = "file://#{host}#{TOP}/#{@base_name}"
      base_regexp = /^#{Regexp.escape(base)}/
      fn = nil
      @real_file_names_mutex.synchronize do
	ary = @real_file_names.select{|e| base_regexp =~ e}.sort
	if ary.empty?
	  fn = "#{base}-000"
	else
	  fn = ary.last.succ
	end
	@real_file_names.push fn
      end
      fn
    end

    # Ruby 1.9 mershal 対応
    #  - Ruby 1.9 では mutex を dump できない
    def marshal_dump
      [@vfile_name, @real_file_names]
    end

    def marshal_load(ary)
      @vfile_name = ary[0]
      @real_file_names = ary[1]
      @real_file_names_mutex = Mutex.new
      @real_file_names_cv = ConditionVariable.new
    end

  end
end

require "delegate"

d1 = SimpleDelegator.new([1,2])
d2 = SimpleDelegator.new([3,4])


[d1, d2].each{|a, b| p a, b}
#!/usr/local/bin/ruby
#
#   test-mutex.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA
#
# --
#
#   
#

@RCS_ID='-$Id:  $-'

require "thread"

Thread.abort_on_exception=true

$v = 0
$m = Mutex.new
$cv = ConditionVariable.new

def foo(val)
  Thread.start do
    $m.synchronize do
      puts "T IN:#{val}"
      $v = val
      $cv.signal
      puts "T OUT:#{val}"
    end
  end
end

Thread.start do
  $m.synchronize do
    loop do
      puts "WAIT IN"
      $cv.wait($m)
      puts "WAIT OUT"
      puts $v
    end
  end
end
sleep 1

100.times do |i|
  foo i
end

sleep 2



    


#!/usr/local/bin/ruby
#
#   test-th-pf.rb - 
#   	$Release Version: $
#   	$Revision: 1.1 $
#   	$Date: 1997/08/08 00:57:08 $
#   	by Keiju ISHITSUKA
#
# --
#
#   
#

require "benchmark"

def bm(n, &block)
  Benchmark.bm do |bm|
    bm.report("th: 1") do
      n.times(&block)
    end

    bm0(bm, 2, n, &block)
    bm0(bm, 4, n, &block)
    bm0(bm, 8, n, &block)
    bm0(bm, 16, n, &block)
  end
end

def bm0(bm, th, n, &block)

  bm.report("th: #{th}") do
    ths = []
    th.times{|i| ths[i] = Thread.start{(n/th).times(&block)}}
    ths.map{|th| th.join}
  end
end

case ARGV[0]
when "1"

  N = 10000000
  ary = Array.new(1000)
  bm(N){ary.each()}

when "2"

  io = File.open("/dev/null", "a+")
  ary = Array.new(1000)
  c = "a"*100
  bm(1000){ary.each{|e| io.puts c}}
end


  

require "front/fairy"

Thread.abort_on_exception=true

if ARGV[0] == "-njob-monitor"
  require "front/debug"
  ARGV.shift
  Fairy::Debug::njob_status_monitor_on
  $sleep = 1
end

fairy = Fairy::Fairy.new

case ARGV[0]
when "1", "input"
  p fairy.input(["/etc/passwd", "/etc/group"])
  sleep $sleep if $sleep 

when "2", "grep"
  p f = fairy.input(["/etc/passwd", "/etc/group"]).grep(/#{ARGV[1]}/)
  sleep $sleep if $sleep 

when "3", "here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.0", "here"
  here = fairy.input(["/etc/passwd"]).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.1", "grep.here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).grep(/#{ARGV[1]}/).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.2", "map.here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| l.chomp.split(/:/)}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep $sleep if $sleep 

when "3.3", "smap"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.3a", "smap"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here


when "3.3.1"
  10000.times do |i|
    puts "LOOP: #{i}"
    fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here.to_a
    c = 0
    ObjectSpace.each_object{|obj| c+=1}
    puts "NUMBER OF OBJECT: #{c}"
  end

when "3.3.2"
  1000.times do |i|
    here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).here
  end


when "3.3.3"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).here


when "3.4", "njob-monitor"
  require "front/debug"
  Fairy::Debug::njob_status_monitor_on
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here
  for l in here
    puts l
  end

when "3.5"
  puts "nodeの非同期追加のテストはなし"

when "3.6"
  puts "port指定のの非同期追加のテストはなし"

when "4", "group_by"
  here = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split{/\s+/}[0]}).here
  for l in here
    puts l
  end

when "4.0", "group_by"
  here = fairy.input(["test/test-4-data1"]).group_by(%{|w| w.chomp.split{/\s+/}[0]}).here
  for l in here
    puts l
  end

when "4.5", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push([i.key, i.size])})
  wc.here.each{|w, n| puts "word: #{w}, count: #{n}"}
  sleep $sleep if $sleep 


when "5", "zip"
  zip = fairy.input("/etc/passwd")
  main = fairy.input("/etc/passwd").zip(zip, :ZIP_BY_SUBSTREAM, %{|e1, e2| e1.chomp+"+"+e2}).here
  for l in main
    puts l
  end


when "5.1", "zip2"
  zip = fairy.input(["/etc/passwd", "/etc/group"])
  main = fairy.input(["/etc/passwd", "/etc/group"]).zip(zip, :ZIP_BY_SUBSTREAM, %{|e1, e2| e1.chomp+"+"+e2}).here
  for l in main
    puts l
  end


when "5.2", "zip3"
  zip1 = fairy.input(["/etc/passwd", "/etc/group"])
  zip2 = fairy.input(["/etc/passwd", "/etc/group"])
  main = fairy.input(["/etc/passwd", "/etc/group"]).zip(zip1, zip2, :ZIP_BY_SUBSTREAM, %{|e1, e2, e3| e1.chomp+"+"+e2.chomp+"-"+e3}).here
  for l in main
    puts l
  end

when "6", "sort"
  LOCAL_SORT_SIZE = 10
  input_files = ["/etc/passwd", "/etc/group"]
  
  size = fairy.input(input_files).smap(%{|i, o| o.push i.size}).here.inject(0){|c, n| c += n}

  prob = 10.0/size
  subst = fairy.input(input_files).select(%{|e| 
  


end

require "fairy"

Thread.abort_on_exception=true

if ARGV[0] == "-njob-monitor"
  require "share/debug"
  ARGV.shift
  $monitor_on = true
  $sleep = 1
end

#fairy = Fairy::Fairy.new("localhost", "19999")
fairy = Fairy::Fairy.new
if $monitor_on
  Fairy::Debug::njob_status_monitor_on(fairy)
end

case ARGV[0]
when "0", "service get"
  p fairy.controller

when "1", "input"
  p fairy.input(["file://localhost/etc/passwd", "file://localhost/etc/group"])
  sleep $sleep if $sleep 


when "1.5", "input"
  p fairy.input("test/vf")
  sleep $sleep if $sleep 

when "1.7", "input"
  p fairy.input(["file://gentoo/etc/passwd", "file://gentoo/etc/group"])
  sleep $sleep if $sleep 


when "2", "grep"
  p f = fairy.input(["file://localhost/etc/passwd", "file://localhost/etc/group"]).grep(/#{ARGV[1]}/)
  sleep $sleep if $sleep 

when "3", "here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 


when "3.vf", "here"
  here = fairy.input("test/vf").here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.0", "here"
  here = fairy.input(["/etc/passwd"]).here
  for l in here
    puts l
  end
  sleep $sleep if $sleep 

when "3.1", "grep.here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).grep(/#{ARGV[1]}/).here
  for l in here
    puts l.inspect
  end
  sleep $sleep if $sleep 

when "3.1.1", "grep.here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).grep(/#{ARGV[1]}/).here
  here.each{|l|
    puts l.inspect
  }
  sleep $sleep if $sleep 

when "3.2", "map.here"
  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| l.chomp.split(/:/)}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep $sleep if $sleep 

when "3.3", "smap"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here
  for l in here
    puts l.inspect
  end
  sleep $sleep if $sleep 

when "3.3a", "smap"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here


when "3.3.1"
  10000.times do |i|
    puts "LOOP: #{i}"
    fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here.to_a
    c = 0
    ObjectSpace.each_object{|obj| c+=1}
    puts "NUMBER OF OBJECT: #{c}"
  end

when "3.3.2"
  1000.times do |i|
    puts "LOOP: #{i}"
    here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).here
    here.to_a
  end


when "3.3.3"
  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).map(%{|e| e}).here
  for l in here
    puts l
  end

when "3.4", "njob-monitor"
  require "share/debug"
  Fairy::Debug::njob_status_monitor_on(fairy)

  here = fairy.input(["/etc/passwd", "/etc/group"]).smap(%{|i,o| i.sort.each{|e|o.push e}}).here
  for l in here
    puts l
  end

when "3.5"
  puts "nodeの非同期追加のテストはなし"

when "3.6"
  puts "port指定のの非同期追加のテストはなし"

when "4", "group_by"
  here = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split{/\s+/}[0]}).here
  for l in here
    puts l
  end

when "4.0", "group_by"
  here = fairy.input(["test/test-4-data1"]).group_by(%{|w| w.chomp.split{/\s+/}[0]}).here
  for l in here
    puts l
  end

when "4.5", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push(sprintf("%s=>%d", i.key, i.size))})
  wc.here.each{|w| puts "word=>count: #{w}"}

  sleep $sleep if $sleep 


when "4.5.1", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push([i.key, i.size])})
  wc.here.each{|w, n| puts "word: #{w}, count: #{n}"}

  sleep $sleep if $sleep 

when "4.5.t", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push([i.key, i.size])})
  wc.here.each{|r| r = r.dc_dup; w, n = r[0], r[1]; puts "word: #{w}, count: #{n.inspect}"}


when "4.5.x", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push([i.key, i.size])})
  wc.here.each{|r| w, n = r[0], r[1]; puts "word: #{w}, count: #{n.inspect}"}

when "5", "zip"
  zip = fairy.input("/etc/passwd")
  main = fairy.input("/etc/passwd").zip(zip, :ZIP_BY_SUBSTREAM, %{|e1, e2| e1.chomp+"+"+e2}).here
  for l in main
    puts l
  end


when "5.1", "zip2"
  zip = fairy.input(["/etc/passwd", "/etc/group"])
  main = fairy.input(["/etc/passwd", "/etc/group"]).zip(zip, :ZIP_BY_SUBSTREAM, %{|e1, e2| e1.chomp+"+"+e2}).here
  for l in main
    puts l
  end


when "5.2", "zip3"
  zip1 = fairy.input(["/etc/passwd", "/etc/group"])
  zip2 = fairy.input(["/etc/passwd", "/etc/group"])
  main = fairy.input(["/etc/passwd", "/etc/group"]).zip(zip1, zip2, :ZIP_BY_SUBSTREAM, %{|e1, e2, e3| e1.chomp+"+"+e2.chomp+"-"+e3}).here
  for l in main
    puts l
  end

when "6", "output"

#  DeepConnect::MESSAGE_DISPLAY=true

  fairy.input(["file://localhost/etc/passwd", "file://localhost/etc/group"]).output("test/test-output")
  sleep $sleep if $sleep 

when "6.1"

  here = fairy.input("test/test-output").here
  for l in here
    puts l
  end

when "6.2", "gentoo"
  
  fairy.input("test/test-6.2-input").output("test/test-6.2-output")
  sleep $sleep if $sleep 

when "6.3", "wc"
  wc = fairy.input(["test/test-4-data1", "test/test-4-data2"]).group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push(sprintf("%s=>%d", i.key, i.size))})
#  p wc.here.to_a
  wc.output("test/test-6.3-output")
  
  for l in fairy.input("test/test-6.3-output").here
    puts l
  end

when "6.4", "wc"
  wc = fairy.input("test/test-6.2-input").group_by(%{|w| w.chomp.split(/\s+/)[0]}).smap(%{|i, o| o.push(sprintf("%s=>%d", i.key, i.size))})
#  p wc.here.to_a
  wc.output("test/test-6.4-output")

  for l in fairy.input("test/test-6.4-output").here
    puts l
  end


when "7", "split"
  fairy.input(["file://localhost/etc/passwd"]).split(4).output("test/test-7-output")
  sleep $sleep if $sleep 

when "7.1", "split"
  sp = fairy.input(["file://localhost/etc/passwd"]).split(4).here
  for l in sp
    puts l
  end
  
  sleep $sleep if $sleep 

when "8", "lfile"
  lf = fairy.input("/etc/passwd").here
  for l in lf
    puts l
  end

when "8.1"
  lf = fairy.input("/etc/passwd").output("test/test-8.1-output")

when "8.2"
  lf = fairy.input("/etc/passwd").split(4).output("test/test-8.2-output")

when "9"
  lf = fairy.input("test/test-8.2-output").output("test/test-9.output")

when "9.1"
  lf = fairy.input("test/test-8.2-output").here
  for l in lf
    puts l
  end

when "10"
  lf = fairy.input("/etc/passwd", :split_size=>256).here
  for l in lf
    puts l
  end

when "10.1"
  fairy.input("/etc/passwd", :split_size=>256).output("test/test-10.output.vf")

when "11"
  fairy.def_pool_variable(:ver, "1")
  lf = fairy.input("/etc/passwd").map(%{|e| e.chomp+"+"+@Pool[:ver]}).here
  for l in lf
    puts l
  end

when "11.1"
  fairy.def_pool_variable(:ver, "1")
  lf = fairy.input("/etc/passwd").map(%{|e| e.chomp+"+"+@Pool.ver}).here
  for l in lf
    puts l
  end


when "11.2"
  fairy.def_pool_variable(:ver, "1")
  lf = fairy.input("/etc/passwd").map(%{|e| @Pool.ver = @Pool.ver.succ; e.chomp+"+"+@Pool.ver}).here
  for l in lf
    puts l
  end

when "11.2.1"
  fairy.def_pool_variable(:ver, "1")
  lf = fairy.input("/etc/passwd").map(%{|e| @Pool.ver = @Pool.ver.succ; e.chomp+"+"+@Pool.ver}).map(%{|e| @Pool.ver = @Pool.ver.succ; e.chomp+"-"+@Pool.ver}).here
  for l in lf
    puts l
  end

when "11.3"
  fairy.def_pool_variable(:var, :block => %{Mutex.new})
  p fairy.pool_variable(:var).__deep_connect_reference?
  puts fairy.pool_variable(:var).inspect

when "12"

  # いかは NG
#  lf = fairy.input("/etc/passwd").map(%{|e| @Pool.ver = @Pool.ver.succ; e.chomp+"+"+@Pool.ver})
#  lf.def_job_pool_variable....

when "13", "shuffle"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files)
  f2 = f1.shuffle(%{|i, o| i.each{|s| o.push s}})
  for l in f2.here
    puts l
  end

when "13.1"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files)
  f2 = f1.shuffle(%{|i, o| i.to_a.reverse.each{|s| o.push s}})
  for l in f2.here
    puts l
  end

when "13.2"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files)
  f2 = f1.shuffle(%{|i, o| 
    begin 
     i.to_a.each{|s| o.push s}
    rescue
     p $!, $@
     raise
    end
    })
  for l in f2.here
    puts l
  end

when "13.3", "reverse"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files)
  f2 = f1.shuffle(%{|i, o| i.to_a.reverse.each{|s| o.push s}})
  f3 = f2.smap(%{|i, o| i.to_a.reverse.each{|e| o.push e}})
  for l in f3.here
    puts l
  end


when "14", "sort"

  input_files = ["/etc/passwd", "/etc/group"]
  
  f1 = fairy.input(input_files).group_by(%{|e| e[0]})
  f2 = f1.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f2.here
    puts l
  end


when "14.0", "sort"

  input_files = ["/etc/passwd", "/etc/group"]
  
  f1 = fairy.input(input_files).group_by(%{|e| e[0]})
  for l in f1.here
    puts l
  end

when "14.0.1", "sort"

  input_files = ["/etc/passwd", "/etc/group"]
  
  f1 = fairy.input(input_files).split(26)
  for l in f1.here
    puts l
  end


when "14.1", "sort"

  input_files = ["/etc/passwd", "/etc/group"]

  pv = "l"
  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| e > @Pool.pv})
  f2 = f1.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f2.here
    puts l
  end

when "14.2"

  # NG
  puts "これは動きません. デッドロックします"

  input_files = ["/etc/passwd", "/etc/group"]

  pv = "l"
  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| e <=> @Pool.pv})
  f2 = f1.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  f3 = f2.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f3.here
    puts l
  end


when "14.3"

  input_files = ["/etc/passwd", "/etc/group"]

  f1 = fairy.input(input_files).group_by(%{|e| e[0]})
  f2 = f1.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  f3 = f2.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  for l in f3.here
    puts l
  end



when "14.4"

  input_files = ["/etc/passwd", "/etc/group"]

  p = "a"
  pv = []
  26.times{pv.push p; p = p.succ}

  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| @Pool.pv.find(proc{"z"}){|p| e < p}})
  f2 = f1.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  f3 = f2.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  for l in f3.here
    puts l
  end

when "15.1" , "barrier", "node_arrived"
  
  input_files = ["/etc/passwd", "/etc/group"]

  f1 = fairy.input(input_files).barrier(:mode=>:NODE_CREATION, :cond=>:NODE_ARRIVED, :buffer=>:MEMORY)
  for l in f1.here
    puts l
  end

when "15.1.1"
  
  input_files = ["/etc/passwd", "/etc/group"]

  pv = "l"
  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| e <=> @Pool.pv})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:NODE_ARRIVED, :buffer=>:MEMORY)
  f3 = f2.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  f4 = f3.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f4.here
    puts l
  end

when "15.1.2"

  # NODE の生成のされ方が気になっている

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).smap(%{|i,o| puts "SLEEPIN"; sleep 5; puts "WAKEUP"; i.each{|e| o.push e}})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:NODE_ARRIVED, :buffer=>:MEMORY)
  for l in f2.here
    puts l
  end

when "15.1.2.1"

  # NODE の生成のされ方が気になっている 根本はこちらにあるらしい

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).smap(%{|i,o| puts "SLEEPIN"; sleep 5; puts "WAKEUP"; i.each{|e| o.push e}})
  for l in f1.here
    puts l
  end


when "15.2", "data_arrived"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).barrier(:mode=>:NODE_CREATION, :cond=>:DATA_ARRIVED, :buffer=>:MEMORY)
  for l in f1.here
    puts l
  end

when "15.2.1"

  input_files = ["/etc/passwd", "/etc/group"]

  pv = "l"
  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| e <=> @Pool.pv})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:DATA_ARRIVED, :buffer=>:MEMORY)
  f3 = f2.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  f4 = f3.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f4.here
    puts l
  end

when "15.2.2"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).smap(%{|i,o| puts "SLEEPIN"; sleep 5; puts "WAKEUP"; i.each{|e| o.push e}})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:DATA_ARRIVED, :buffer=>:MEMORY)
  for l in f2.here
    puts l
  end

when "15.3", "all_data_imported"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).barrier(:mode=>:NODE_CREATION, :cond=>:ALL_DATA, :buffer=>:MEMORY)
  for l in f1.here
    puts l
  end

when "15.3.1"

  input_files = ["/etc/passwd", "/etc/group"]

  pv = "l"
  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| e <=> @Pool.pv})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:ALL_DATA, :buffer=>:MEMORY)
  f3 = f2.shuffle(%{|i, o| i.sort{|s1, s2| s1.key <=> s2.key}.each{|s| o.push s}})
  f4 = f3.smap(%{|i, o|
	  ary = i.to_a.sort
	  ary.each{|e| o.push e}})
  for l in f4.here
    puts l
  end

when "15.3.2"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).smap(%{|i,o| i.each{|e| o.push e; sleep 1}})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:ALL_DATA, :buffer=>:MEMORY)
  for l in f2.here
    puts l
  end


when "15.3.2.1"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).map(%{|e| sleep 1; e})
  f2 = f1.barrier(:mode=>:NODE_CREATION, :cond=>:ALL_DATA, :buffer=>:MEMORY)
  for l in f2.here
    puts l
  end

when "15.3.2.2"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).map(%{|e| sleep 1; e})
  for l in f1.here
    puts l
  end

when "15.4", "block_cond"

  input_files = ["/etc/passwd", "/etc/group"]

  fairy.def_pool_variable(:mutex, Mutex.new)

  f0 = fairy.input(input_files).smap(%{|i,o| @Pool.mutex.synchronize{puts "LOCK"; sleep 5; puts "LOCK OUT"}})

  sleep 2

  f1 = fairy.input(input_files).barrier(:mode=>:NODE_CREATION, :cond=>%{puts "COND:"; @Pool.mutex.lock}, :buffer=>:MEMORY, :BEGIN=>%{puts "AAAAAAAAAAAA"})
  for l in f1.here
    puts l
  end

when "15.5", "stream"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).barrier(:mode=>:STREAM, :cond=>:DATA_ARRIVED, :buffer=>:MEMORY)
  for l in f1.here
    puts l
  end

when "15.5.1"

  input_files = ["/etc/passwd", "/etc/group"]
  f1 = fairy.input(input_files).smap(%{|i,o| puts "SLEEPIN"; sleep 5; puts "WAKEUP"; i.each{|e| o.push e}})
  f2 = f1.barrier(:mode=>:STREAM, :cond=>:DATA_ARRIVED, :buffer=>:MEMORY)
  for l in f2.here
    puts l
  end

when "16", "begin", "end"

  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| l.chomp.split(/:/)}, :BEGIN=>%{puts "BEGIN"}, :END=>%{puts "END"}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep $sleep if $sleep 


when "17", "iota"

  iota = fairy.input(Fairy::Iota, 1000)
  for l in iota.here
    puts l
  end
  sleep $sleep if $sleep 

when "17.1"

  f0 = fairy.input(Fairy::Iota, 1000)
  f1 = f0.map(%{|e| @sum += e}, :BEGIN=>%{@sum = 0})
  for l in f1.here
    puts l
  end
  sleep $sleep if $sleep 

when "17.2"

  f0 = fairy.input(Fairy::Iota, 1000)
  f1 = fairy.input(Fairy::Iota, 1000)
  f2 = f0.zip(f1, :ZIP_BY_SUBSTREAM, %{|e1, e2| e1+e2})
  for l in f2.here
    puts l
  end
  sleep $sleep if $sleep 

when "17.3"

  iota = fairy.times(100, :SPLIT_NO=>10)
  for l in iota.here
    puts l
  end


when "18", "emap"

  # ref 14.4

  input_files = ["/etc/passwd", "/etc/group"]

  p = "a"
  pv = []
  26.times{pv.push p; p = p.succ}

  fairy.def_pool_variable(:pv, pv)

  f1 = fairy.input(input_files).group_by(%{|e| @Pool.pv.find(proc{"z"}){|p| e < p}})
  f2 = f1.emap(%{|i| i.to_a.sort})
  f3 = f2.eshuffle(%{|i| i.sort{|s1, s2| s1.key <=> s2.key}})
  for l in f3.here
    puts l.inspect
  end

when "19", "there"

  f1 = 100.times.collect{|e| e}.there(fairy).split(2).split(4).map(%{|i| i})
  for l in f1.here
    puts l
  end

when "19.1", "there"

  f1 = fairy.there(100.times).split(2).split(4).map(%{|i| i})
  for l in f1.here
    puts l
  end

when "20", "break"

  # これはどうさしない

  iota = fairy.input(Fairy::Iota, 1000)
  f = iota.map(%{|i| 
    if i == 50
       break 1000
    end
    i
  })
  for l in f.here
    puts l
  end
  sleep $sleep if $sleep 

when "21", "exception"

  iota = fairy.input(Fairy::Iota, 1000)
  f = iota.map(%{|i| 
    if i == 50
       fugegeu
    end
    i
  })
  for l in f.here
    puts l
  end

when "21.1"
  fairy.def_pool_variable(:foo, 1)
  fairy.def_pool_variable(:foo, 2)

when "22", "output varray"

  output_varray = fairy.input(Fairy::Iota, 1000).output(Fairy::VArray)
puts "X"
  puts output_varray.varray.peer_inspect
  for e in output_varray.varray
    p e
  end


when "22.1", "output varray"

  input_files = ["/etc/passwd", "/etc/group"]
  output_varray = fairy.input(input_files).output(Fairy::VArray)
puts "X"
  puts output_varray.varray.peer_inspect
  for e in output_varray.varray
    p e
  end

when "23", "input varray"

  va = fairy.input(Fairy::Iota, 1000).to_va

  for l in fairy.input(va).here
    puts l
  end

when "23.1", "input varray"

  va = fairy.input(Fairy::Iota, 1000).to_va
  10.times do |i|
    puts "itr#{i}"
    va = fairy.input(va).map(%{|i| i*2}).to_va
  end
  for l in fairy.input(va).here
    puts l
  end

when "23.2"

  va = fairy.input(Fairy::Iota, 100).to_va
  puts "va[10]: "
  p va[10]  
  puts "va[20]=500 "
  va[20]= 500
  p va[20]
  puts "EACH:"
  for l in va
    puts l
  end

when "24", "k-means"

  puts "これは動作しません"

  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| Vector[*data]}, 
				      :BEGIN=>%{require "matrix"}).to_va

  while measure > Threshold
    cvpair = fairy.input(va).map(%{|v|
      [@Pool.centers.min_by{|c| (v - c).r}, v]})
    gpair = cvpair.group_by(%{|cv| cv[0]})
    cpair = gpair.emap(%{|i|
      n = 0
      [i.inject(0){|nc, c, v| n += 1; nc += v}/n, i.key]}).here
    measure = cpair.inject(0){|m, n, o| m += (n - i).r}
    fairy.pool_variable(:centers, cpair.map{|n, o| n})
  end

when "24.1", "k-means"

  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0.0, 0.0], [0.0, 0.5], [1.0, 1.0], [1.0, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  p fairy.pool_variable(:centers)

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| data = data.dc_deep_copy;Vector[*data]}, 
	 			      :BEGIN=>%{require "matrix"}).to_va

  va.each{|e| puts e.inspect}

  loop = 0
  while measure > Threshold
    puts "ITR: START LOOP: #{loop += 1}"

    cvpair = fairy.input(va).map(%{|v|
      v = v.dc_deep_copy
      [@Pool.centers.min_by{|c| c = c.dc_deep_copy; (v - c).r}, v]})

    puts "ITR: ph#1"
    gpair = cvpair.group_by(%{|c| c[0]})

    puts "ITR: ph#2"
    cpair = gpair.smap(%{|i, o|
      n = 0
      o.push [i.inject(Vector[0.0,0.0]){|nc, cv| 
                       c = cv[0].dc_deep_copy
                       v = cv[1].dc_deep_copy
                       n += 1
                       nc += v} * (1.0/n), i.key]}, 
		       :BEGIN=>%{require "matrix"}).here.to_a

    puts "ITR: ph#3"
    measure = cpair.inject(0){|m, no| 
      n = no[0].dc_deep_copy
      o = no[1].dc_deep_copy
      m += (n - o).r}
    puts "ITR: ph#4"
    fairy.pool_variable(:centers, cpair.map{|no| no[0].dc_deep_copy})

    puts "FINISH:"
    fairy.pool_variable(:centers).each{|e| puts e.inspect}
  end

when "24.2", "k-means-02"

  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  puts "Init Centers:"
  fairy.pool_variable(:centers).each{|e| puts e.inspect}

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| Vector[*data]}, 
				      :BEGIN=>%{require "matrix"}).to_va

  loop = 0
  while measure > Threshold
    puts "ITR: START LOOP: #{loop += 1}"

    cvpair = fairy.input(va).map(%{|v|
      [@Pool.centers.min_by{|c| (v - c).r}, v]})
    gpair = cvpair.group_by(%{|cv| cv[0]})
    cpair = gpair.smap(%{|i, o|
      n = 0
      o.push [i.inject(Vector[0.0,0.0]){|nc, cv| n += 1; nc += cv[1]}*(1.0/n), i.key.dc_dup]},
		       :BEGIN=>%{require "matrix"}).here.to_a
    
#    p cpair
    cpair.map{|n, o| n}.each{|e| p e}

    measure = cpair.inject(0){|m, no| m += (no[0] - no[1]).r}
    fairy.pool_variable(:centers, cpair.map{|no| no[0]})

    puts "ITR FINISH:"
    fairy.pool_variable(:centers).each{|e| puts e.inspect}
 end

when "24.3", "k-means-03"

  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  puts "Init Centers:"
  fairy.pool_variable(:centers).each{|e| puts e.inspect}

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| Vector[*data]}, 
				      :BEGIN=>%{require "matrix"}).to_va

  loop = 0
  while measure > Threshold
    puts "ITR: START LOOP: #{loop += 1}"

    cvpair = fairy.input(va).map(%{|v|
      [@Pool.centers.min_by{|c| (v - c).r}, v]})
    gpair = cvpair.group_by(%{|cv| cv[0]})
    cpair = gpair.emap(%{|i|
      n = 0
      new_c = i.inject(Vector[0.0,0.0]){|nc, cv| n += 1; nc += cv[1]}*(1.0/n)
      [[new_c, i.key]]},
		       :BEGIN=>%{require "matrix"}).here.to_a
    
#    p cpair

    cpair.map{|n, o| n}.each{|e| p e}
    measure = cpair.inject(0){|m, no| m += (no[0] - no[1]).r}
    fairy.pool_variable(:centers, cpair.map{|no| no[0]})

    puts "ITR FINISH:"
    fairy.pool_variable(:centers).each{|e| puts e.inspect}
 end

when "24.4", "k-means-04"
  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  puts "Init Centers:"
  fairy.pool_variable(:centers).each{|e| puts e.inspect}

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| Vector[*data]}, 
				      :BEGIN=>%{require "matrix"}).to_va

  loop = 0
  while measure > Threshold
    puts "ITR: START LOOP: #{loop += 1}"

    cvpair = fairy.input(va).map(%{|v|
      [@Pool.centers.min_by{|c| (v - c).r}, v]})
    gpair = cvpair.group_by(%{|c, v| c})
    cpair = gpair.emap(%{|i|
      n = 0
      new_c = i.inject(Vector[0.0,0.0]){|nc, (c, v)| n += 1; nc += v}*(1.0/n)
      [[new_c, i.key]]},
		       :BEGIN=>%{require "matrix"}).here.to_a
    
    measure = cpair.inject(0){|m, (n, o)| m += (n - o).r}

    fairy.pool_variable(:centers, cpair.map{|(n, o)| n})

    puts "ITR FINISH:"
    fairy.pool_variable(:centers).each{|e| puts e.inspect}
 end

when "24.5", "k-means-05"
  require "matrix"

  NoKluster = 2
  Threshold = 0.1

  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]

  initial_centers = fairy.def_pool_variable(:NoKluster, NoKluster)

  fairy.def_pool_variable(:centers, 
			  :block=>%{require "matrix"
                                    @Pool.NoKluster.times.collect{Vector[rand, rand]}})

  puts "Init Centers:"
  fairy.pool_variable(:centers).each{|e| puts e.inspect}

  measure = 100000

  va = Data.there(fairy).split(2).map(%{|data| Vector[*data]}, 
				      :BEGIN=>%{require "matrix"}).to_va
  loop = 0
  while measure > Threshold
    puts "ITR: START LOOP: #{loop += 1}"

    cvpair = fairy.input(va).map(%{|v| [@Pool.centers.min_by{|c| (v - c).r}, v]})
    gpair = cvpair.group_by(%{|c, v| c})
    cpair = gpair.emap(%{|i|
      n = 0
      new_c = i.inject(Vector[0.0,0.0]){|nc, (c, v)| n += 1; nc += v}*(1.0/n)
      [[new_c, i.key]]},
		       :BEGIN=>%{require "matrix"}).here.to_a
    
    measure = cpair.inject(0){|m, (n, o)| m += (n - o).r}

    fairy.pool_variable(:centers, cpair.map{|n, o| n})

    puts "ITR FINISH:"
    fairy.pool_variable(:centers).each{|e| puts e.inspect}
 end

  sleep 100

when "25.1", "block"
  
  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]
  
  here = Data.there(fairy).map(%{|e1, e2| e1}).here
  for l in here
    p l
  end

when "25.2", "block"
  
  Data = [[0, 0], [0, 0.5], [1, 1], [1, 0.5]]
  
  here = Data.there(fairy).map(%{|e1| e1}).here
  for l1, l2 in here
    p l1, l2
  end

when "26", "inject"

  iota = fairy.input(Fairy::Iota, 101, :SPLIT_NO=>10)
  inject = iota.inject(%{|sum, value| sum + value})
  p inject.value

when "26.1", "inject"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10)
  inject = iota.inject(%{|sum, value| sum + value})
  p inject.value

when "26.2", "min"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  min = iota.min(%{|x, y| -(x<=>y)})
  p min.value

when "26.3", "max"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  max = iota.max
  p max.value

when "26.4", "min_by"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  minby = iota.min_by(%{|x| -x})
  p minby.value

when "26.5", "max_by"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  maxby = iota.max_by(%{|x| x})
  p maxby.value

when "26.6", "inject"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10)
  inject = iota.inject(%{|sum, value| sum + value})
  for l in inject.here
    p l
  end

when "27", "terminate"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  maxby = iota.max_by(%{|x| x})
  p maxby.value
  # 途中で^C


when "27.1", "terminate"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  maxby = iota.max_by(%{|x| x})
  p maxby.value
  sleep 100

when "28", "mgroup_by"
  
  iota = fairy.input(Fairy::Iota, 101, :SPLIT_NO=>10, :offset=>10)
  f3 = iota.mgroup_by(%{|e| [e-1, e, e+1]}).emap(%{|i| [i.to_a]})
  for l in f3.here
    puts "#[#{l.inspect}]"
  end

when "29", "lifegame"
  require "matrix"

  Offsets =  [
    [-1, -1], [-1, 0], [-1, 1], 
    [0, -1],  [0, 0],  [0, 1], 
    [1, -1],  [1, 0],  [1, 1]
  ]
  InitialPositions = [
             [-1, 0], [-1, 1],
    [0, -1], [0, 0],
             [1, 0],
  ]

puts "X:1"
  va = InitialPositions.there(fairy).split(2).map(%{|p| Vector[*p.to_a]},
						  :BEGIN=>%{require "matrix"}).to_va

puts "X:2"

  fairy.def_pool_variable(:offsets, Offsets.map{|p| Vector[*p.to_a]})
puts "X:3"

  loop = 0
  loop do
    puts "ITR: #{loop+=1}"
    
    f1 = fairy.input(va).mgroup_by(%{|v| @Pool.offsets.collect{|o| v + o}},
		      :BEGIN=>%{require "matrix"})
    va = f1.smap(%{|i, o| 
      lives = i.to_a
      if lives.include?(i.key) && (lives.size == 3 or lives.size == 4)
        o.push i.key
      elsif lives.size == 3
        o.push i.key
      end
    }, :BEGIN=>%{require "matrix"}).to_va
    
    puts va.to_a.each{|v| puts v}
  end

when "30", "handle_exeption"
  puts "例外なし"
  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| l.chomp.split(/:/)}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep $sleep if $sleep 

when "30.1", "handle_exeption"
  puts "例外あり"

#   module Forwardable
#     @debug = true
#   end

  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| 
     l.chombo.split(/:/)
  }).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep $sleep if $sleep 

when "31", "stdout"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  minby = iota.min_by(%{|x| puts x; -x})
  p minby.value


when "31.1", "stdout"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  minby = iota.min_by(%{|x| p x; -x})
  p minby.value

when "32", "find"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  find = iota.find(%{|x| x == 10})
  p find.value

when "32.1", "find"

  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  find = iota.find(%{|x| x == 500})
  p find.value

when "33", "gbreak"
  
  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  here = iota.map(%{|x| if x == 500; gbreak; else x; end}).here
  for l in here
    puts l
  end

  sleep 2


when "33.1"
  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| 
    l0 = l.chomp.split(/:/)
    if l0[0] == "keiju"
      gbreak
    else
      l0
    end}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep 2

when "33.2", "gbreak"
  
  iota = fairy.input(Fairy::Iota, 1001, :SPLIT_NO=>10, :offset=>10)
  here = iota.map(%{|x| if x == 500; break; else x; end}).here
  for l in here
    puts l
  end

  sleep 2

when "33.3"
  here = fairy.input(["/etc/passwd", "/etc/group"]).map(%{|l| 
    l0 = l.chomp.split(/:/)
    if l0[0] == "keiju"
      break
    else
      l0
    end}).here
  for l in here
    print l.join("-"), "\n"
  end
  sleep 2

when "34", "serialize msort"

  va = fairy.input(["/etc/passwd", "/etc/group"]).emap(%{|i| i.to_a.sort}).to_va

  sampling = fairy.input(va).select(%{|e| (i += 1) % 10 == 0}, :BEGIN=>%{i = 0}).here.sort
  
  puts "SAMPLING:"
  p sampling
  
  puts "PIVOTS:" 
  pvs = sampling.values_at(sampling.size.div(3), (sampling.size*2).div(3), -1)
  fairy.def_pool_variable(:pvs, pvs)
  p pvs

  div = fairy.input(va).group_by(%{|e| 
   key = @Pool.pvs.find{|pv| e <= pv}
   key ? key : @Pool.pvs.last})

  msort = div.emap(%{|i| 
    buf = []
    i.each{|e|
       idx = buf.rindex{|b| b < e}
       if idx 
         buf.insert(idx+1, e)
       else
         buf.unshift e
       end}
    buf})
  shuffle = msort.eshuffle(%{|i| i.sort{|s1, s2| s1.key <=> s2.key}})
  puts "RESULT:"
  for l in shuffle.here
    puts l
  end

when "34.1", "serialize msort"

  SAMPLING_RATIO_1_TO = 10
  PVN = 4

  va = fairy.input(["/etc/passwd", "/etc/group"]).emap(%{|i| i.to_a.sort}).to_va

  puts "SAMPLING: RATIO: 1/#{SAMPLING_RATIO_1_TO}"
  sample = fairy.input(va).select(%{|e| (i += 1) % #{SAMPLING_RATIO_1_TO} == 0},
				    :BEGIN=>%{i = 0}).here.sort
  p sample
  
  puts "PIVOTS:" 
  idxes = (1...PVN).collect{|i| (sample.size*i).div(PVN)}
  idxes.push -1
  pvs = sample.values_at(*idxes)
  fairy.def_pool_variable(:pvs, pvs)
  p pvs

  div = fairy.input(va).group_by(%{|e| 
   key = @Pool.pvs.find{|pv| e <= pv}
   key ? key : @Pool.pvs.last})

  msort = div.emap(%{|i| 
    buf = []
    i.each{|e|
       idx = buf.rindex{|b| b < e}
       if idx 
         buf.insert(idx+1, e)
       else
         buf.unshift e
       end}
    buf})
  shuffle = msort.eshuffle(%{|i| i.sort{|s1, s2| s1.key <=> s2.key}})
  puts "RESULT:"
  for l in shuffle.here
    puts l
  end
end

#!/usr/bin/env ruby

require "optparse"

require "deep-connect/deep-connect"

require "processor"

Thread.abort_on_exception=true


controller_port = nil
id = nil
opt = OptionParser.new do |opt|
  opt.on("--controller=VAL"){|val| controller_port = val}
  opt.on("--id=VAL"){|val| id = val}
end
opt.parse!(ARGV)

Fairy::Processor.start(id.to_i, controller_port)

puts "Processor Service Start"

sleep

require "controller"

Thread.abort_on_exception=true

Fairy::Controller.start("19999")

puts "Service Start"

sleep
